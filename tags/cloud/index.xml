<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloud on re-imagine</title>
    <link>http://torumakabe.github.io/tags/cloud/</link>
    <description>Recent content in Cloud on re-imagine</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 24 Jan 2016 00:19:00 +0900</lastBuildDate>
    
	<atom:link href="http://torumakabe.github.io/tags/cloud/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>クラウドは本当に性能不足なのか</title>
      <link>http://torumakabe.github.io/post/doubt_lackofperf_oncloud/</link>
      <pubDate>Sun, 24 Jan 2016 00:19:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/doubt_lackofperf_oncloud/</guid>
      <description>このエントリは2016/1/24に書きました。使えるリソースはどんどん増えていくので、適宜その時点で情報をとってください。
具体的な数値で、正しい理解を &amp;ldquo;クラウドは性能不足、企業システムが重すぎる&amp;rdquo;という記事が身の回りで話題になりました。公開から4日たっても「いま読まれている記事」の上位にあり、注目されているようです。
記事で訴えたかったことは、クラウドを過信しないように、そして、クラウドはクラウドらしい使い方をしよう、ということでしょう。ユーザの声は貴重ですし、同意できるところも多い。でも、「企業システム」とひとくくりにしてしまったこと。タイトルのバイアスが強いこと。そして、具体的な根拠に欠けることから、誤解を招いている印象です。
どんな技術、製品、サービスにも限界や制約はあります。具体的な数値や仕様で語らないと、そこから都市伝説が生まれます。
いい機会なので、わたしの主戦場であるAzureを例に、クラウドでどのくらいの性能を期待できるか、まとめてみようと思います。
シングルVMでどれだけ 話題となった記事でも触れられているように、クラウドはその生まれから、分散、スケールアウトな作りのアプリに向いています。ですが世の中には「そうできない」「そうするのが妥当ではない」システムもあります。記事ではそれを「企業システム」とくくっているようです。
わたしは原理主義者ではないので「クラウドに載せたかったら、そのシステムを作り直せ」とは思いません。作りを大きく変えなくても載せられる、それでクラウドの特徴を活かして幸せになれるのであれば、それでいいです。もちろん最適化するにこしたことはありませんが。
となると、クラウド活用の検討を進めるか、あきらめるか、判断材料のひとつは「スケールアウトできなくても、性能足りるか?」です。
この場合、1サーバ、VMあたりの性能上限が制約です。なので、AzureのシングルVM性能が鍵になります。
では、Azureの仮想マシンの提供リソースを確認しましょう。
&amp;ldquo;仮想マシンのサイズ&amp;rdquo;
ざっくりA、D、Gシリーズに分けられます。Aは初期からあるタイプ。ＤはSSDを採用した現行の主力。Gは昨年後半からUSリージョンで導入がはじまった、大物です。ガンダムだと後半、宇宙に出てから登場するモビルアーマー的な存在。現在、GシリーズがもっともVMあたり多くのリソースを提供できます。
企業システムではOLTPやIOバウンドなバッチ処理が多いと仮定します。では、Gシリーズ最大サイズ、Standard_GS5の主な仕様から、OLTPやバッチ処理性能の支配要素となるCPU、メモリ、IOPSを見てみましょう。
 Standard_GS5の主な仕様  32仮想CPUコア 448GBメモリ 80,000IOPS   メモリはクラウドだからといって特記事項はありません。クラウドの特徴が出るCPUとIOPSについて深掘りしていきます。
なお、現時点でまだ日本リージョンにはGシリーズが投入されていません。必要に応じ、公開スペックと後述のACUなどを使ってA、Dシリーズと相対評価してください。
32仮想CPUコアの規模感 クラウドのCPU性能表記は、なかなか悩ましいです。仮想化していますし、CPUは世代交代していきます。ちなみにAzureでは、ACU(Azure Compute Unit)という単位を使っています。
&amp;ldquo;パフォーマンスに関する考慮事項&amp;rdquo;
ACUはAzure内で相対評価をする場合にはいいのですが、「じゃあAzureの外からシステムもってきたとき、実際どのくらいさばけるのよ。いま持ってる/買えるサーバ製品でいうと、どのくらいよ」という問いには向きません。
クラウドや仮想化に関わらず、アプリの作りと処理するデータ、ハードの組み合わせで性能は変わります。動かしてみるのが一番です。せっかくイニシャルコストのかからないクラウドです。試しましょう。でもその前に、試す価値があるか判断しなければいけない。なにかしらの参考値が欲しい。予算と組織で動いてますから。わかります。
では例をあげましょう。俺のベンチマークを出したいところですが、「それじゃない」と突っ込まれそうです。ここはぐっと我慢して、企業でよく使われているERP、SAPのSAP SDベンチマークにしましょう。
&amp;ldquo;SAP Standard Application Benchmarks in Cloud Environments&amp;rdquo;
&amp;ldquo;SAP Standard Application Benchmarks&amp;rdquo;
SAPSという値が出てきます。販売管理アプリケーションがその基盤上でどれだけ仕事ができるかという指標です。
比較のため、3年ほど前の2ソケットマシン、現行2ソケットマシン、現行4ソケットマシンを選びました。単体サーバ性能をみるため、APとDBを1台のサーバにまとめた、2-Tierの値をとります。
    DELL R720 Azure VM GS5 NEC R120f-2M FUJITSU RX4770 M2     Date 2012&amp;frasl;4 2015&amp;frasl;9 2015&amp;frasl;7 2015&amp;frasl;7   CPU Type Intel Xeon Processor E5-2690 Intel Xeon Processor E5-2698B v3 Intel Xeon Processor E5-2699 v3 Intel Xeon Processor E7-8890 v3   CPU Sockets 2 2 2 4   CPU Cores 16 32 (Virtual) 36 72   SD Benchmark Users 6,500 7,600 14,440 29,750   SAPS 35,970 41,670 79,880 162,500    3年前の2ソケットマシンより性能はいい。現行2ソケットマシンの半分程度が期待値でしょうか。ざっくりE5-2699 v3の物理18コアくらい。4ソケットは無理め。</description>
    </item>
    
    <item>
      <title>うちのクラウド、空いてます</title>
      <link>http://torumakabe.github.io/post/cloud-vacancy/</link>
      <pubDate>Sun, 13 Apr 2014 00:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/cloud-vacancy/</guid>
      <description>無限なんてあり得ない 「お客様はキャパシティのことを気にすることはありません。事実上無限、それがクラウドのメリットです！！」なんていうクラウドサービスのうたい文句、けっこう目にします。
そのいっぽうで、「1000台のサーバーを1時間だけ使って、料金は数万円で済みました」という事例をアピールしているサービスの、別ユーザーが「この前、数10台のサーバー追加を依頼したら、在庫切れって言われてねぇ」と言っていたり。
クラウドコンピューティングの概念は雲かもしれませんが、その向こうには物理リソースがあるわけで、無限というのは、残念ながら無理があります。
空いているときもあれば、空いていない時もあります。また、事業者によって、キャパシティプランニングのスタンスは違います。規模も違います。
空き状況を公開すると面白いかも知れない 駐車場の空き状況がわかる街があります。便利です。最近はWebでレストランの空きがわかるサービスもあります。これまた便利。
また、震災以降、電力の需給状況が可視化されました。どのくらい余裕があるか、を意識できるようになっています。便利という話ではないですが、リソースの空きを意識して生活している、身近な例ではないでしょうか。
そこで、クラウドサービスでも、リソースの空き状況を公開すると面白いのになぁ、と思うのです。でもわたしは、そのようなサービスを見たことがありません。
ユーザーがそのサービスを判断する情報になりますし、電力事業者間で電力をやりとりしているように、事業者間でリソースを融通するような、新しい仕組みにつながる気もします。
ビジネス上、難しいことは重々承知で書いています。でも、クラウドサービスが本当に「ユーティリティ」を目指すのなら、いつか問われる課題ではないかと。
みなさんは、どう思われますか?</description>
    </item>
    
    <item>
      <title>クラウド = 発電所?</title>
      <link>http://torumakabe.github.io/post/cloud-and-power/</link>
      <pubDate>Sun, 16 Mar 2014 00:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/cloud-and-power/</guid>
      <description>思考停止してないだろうか クラウドコンピューティングは、発電所に例えられることが多いです。そのうちみんな自家発電をやめて、発電所に任せるようになるよ、と。ふーん、そうかもなぁ。
でも本当にそうなんでしょうか。雰囲気だけで、ちゃんと考えてない、思考停止している気がしています。
本当に発電は大規模発電所任せ? 最近CMでよく見ますが、エネファームってご存じですか。これ、ざっくり言うと戸別の発電所じゃないでしょうか。エネルギーは、使うところの近くで作った方が効率的なので、こういう仕組みが出てきたんでしょうね。
戸別の発電は、将来的には燃料電池など新しい技術も使われて、さらに普及するんじゃないでしょうか。使う人の近くで、その使い方に合わせて発電した方が、合理的ですものね。
オンプレIT基盤は無くなる? で、クラウドの話です。オンプレミスのIT基盤は無くなって、全部クラウドに移ってしまうのでしょうか。でも、もしその考えが「発電所のように」という根拠であれば、「従来の」という前提が要ります。なぜなら、発電の仕組みも進化しているので。エネファームのように。
ネットワーク遅延を考えれば、処理する場所の近くにデータがあったほうがいいですよね。利用者みんなが、クラウドが動くデータセンターの近くにいるわけではないので。
また、発電所は、ピークに合わせて設備投資をしています。いっぽうで、いざというとき、あなたの契約しているクラウドは、契約者全員が使えるだけの能力を供給できるでしょうか。ピークに合わせて設備投資しているでしょうか。そもそもピークをどう定義しているでしょうか。災害時にそれを期待した利用者の需要で、パンクしないでしょうか。
そのインフラ知識は捨てないほうがいい 発電の世界で燃料電池が期待されているように、ITの世界でも不揮発性メモリなど、その使い方が大きく変わるイノベーションの種が研究開発されています。普段は電源を切っておいて、処理するときだけ瞬時に起動、処理、また停止するようなコンピュータ。家とかオフィスに置きたくないですか。性能的にも経済的にもリスク管理的にも、合理的かもしれませんよ。
そして、その設備ではリソースが足りない、読めない、あまり使わないものはクラウドに置き、動かせばいいのではないかと思います。あと、クラウドのほうが、いいものをすぐに使える場合。SaaSとか。
「未来はどっちだ」という白か黒かの議論をして、どちらかと心中する必要はありません。どっちも使えばいいです。かっこいい言い方をすると、ハイブリッドです。
なので、「クラウド時代に自分で基盤作ることなんてなくなるから、インフラの知識はもう要らないよね」とか言って、せっかく身につけたハードウェア、ITインフラの知識は、捨てるどころか磨いた方がいいですよ。知識は荷物になりません、あなたを守る懐刀。</description>
    </item>
    
  </channel>
</rss>