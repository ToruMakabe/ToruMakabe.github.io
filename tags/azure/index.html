<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure &middot; re-imagine</title>

    <meta name="description" content="my life is the sum of my imagination">

    <meta name="generator" content="Hugo 0.15" />
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="tmak_tw" />
    <meta name="twitter:title" content="Azure &middot; re-imagine">
    <meta name="twitter:description" content="my life is the sum of my imagination">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Azure &middot; re-imagine">
    <meta property="og:description" content="my life is the sum of my imagination">

    <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Oxygen:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-old-ie-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css">
    <!--<![endif]-->

    <link rel="stylesheet" href="http://torumakabe.github.io//css/all.min.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

    <link rel="alternate" type="application/rss+xml" title="re-imagine" href="http://torumakabe.github.io//index.xml" />
</head>
<body>


<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
    <div class="header">
        <hgroup>
            <h1 class="brand-title"><a href="http://torumakabe.github.io/">re-imagine</a></h1>
            <h2 class="brand-tagline"> my life is the sum of my imagination </h2>
        </hgroup>

        <nav class="nav">
            <ul class="nav-list">
                
                <li class="nav-item">
                    <a class="pure-button" href="https://twitter.com/tmak_tw"><i class="fa fa-twitter"></i> Twitter</a>
                </li>
                
                
                <li class="nav-item">
                    <a class="pure-button" href="https://github.com/ToruMakabe "><i class="fa fa-github-alt"></i> github</a>
                </li>
                
                <li class="nav-item">
                    <a class="pure-button" href="http://torumakabe.github.io//index.xml"><i class="fa fa-rss"></i> rss</a>
                </li>
            </ul>
        </nav>
    </div>
</div>


    <div class="content pure-u-1 pure-u-md-3-4">
        <div>
            
            <div class="posts">
                
                <h1 class="content-subhead">29 Apr 2016, 17:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_batch_docker/" class="post-title">Azure BatchとDockerで管理サーバレスバッチ環境を作る</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="サーバレスって言いたいだけじゃないです:1e958ca6820e4dcff939a22a84382ed3">サーバレスって言いたいだけじゃないです</h2>

<p>Linux向けAzure BatchのPreviewが<a href="https://azure.microsoft.com/ja-jp/blog/announcing-support-of-linux-vm-on-azure-batch-service/">はじまり</a>ました。地味ですが、なかなかのポテンシャルです。</p>

<p>クラウドでバッチを走らせる時にチャレンジしたいことの筆頭は「ジョブを走らせる時だけサーバー使う。待機時間は消しておいて、
節約」でしょう。</p>

<p>ですが、仕組み作りが意外に面倒なんですよね。管理サーバーを作って、ジョブ管理ソフト入れて、Azure SDK/CLI入れて。クレデンシャルを安全に管理して。可用性確保して。バックアップして。で、管理サーバーは消せずに常時起動。なんか中途半端です。</p>

<p>その課題、Azure Batchを使って解決しましょう。レッツ管理サーバーレスバッチ処理。</p>

<h2 id="コンセプト:1e958ca6820e4dcff939a22a84382ed3">コンセプト</h2>

<ul>
<li>管理サーバーを作らない</li>
<li>Azure Batchコマンドでジョブを投入したら、あとはスケジュール通りに定期実行される</li>
<li>ジョブ実行サーバー群(Pool)は必要な時に作成され、処理が終わったら削除される</li>
<li>サーバーの迅速な作成とアプリ可搬性担保のため、dockerを使う</li>
<li>セットアップスクリプト、タスク実行ファイル、アプリ向け入力/出力ファイルはオブジェクトストレージに格納</li>
</ul>

<h2 id="サンプル:1e958ca6820e4dcff939a22a84382ed3">サンプル</h2>

<p>Githubにソースを<a href="https://github.com/ToruMakabe/Azure_Batch_Sample">置いておきます</a>。</p>

<h3 id="バッチアカウントとストレージアカウント-コンテナーの作成とアプリ-データの配置:1e958ca6820e4dcff939a22a84382ed3">バッチアカウントとストレージアカウント、コンテナーの作成とアプリ、データの配置</h3>

<p><a href="https://azure.microsoft.com/ja-jp/documentation/articles/batch-technical-overview/">公式ドキュメント</a>で概要を確認しましょう。うっすら理解できたら、バッチアカウントとストレージアカウントを作成します。</p>

<p>ストレージアカウントに、Blobコンテナーを作ります。サンプルの構成は以下の通り。</p>

<pre><code>.
├── blob
│   ├── application
│   │   ├── starttask.sh
│   │   └── task.sh
│   ├── input
│   │   └── the_star_spangled_banner.txt
│   └── output
</code></pre>

<p>applicationコンテナーに、ジョブ実行サーバー作成時のスクリプト(starttask.sh)と、タスク実行時のスクリプト(task.sh)を配置します。</p>

<ul>
<li><a href="https://github.com/ToruMakabe/Azure_Batch_Sample/blob/master/blob/application/starttask.sh">starttask.sh</a> - docker engineをインストールします</li>
<li><a href="https://github.com/ToruMakabe/Azure_Batch_Sample/blob/master/blob/application/task.sh">task.sh</a> - docker hubからサンプルアプリが入ったコンテナーを持ってきて実行します。<a href="https://github.com/ToruMakabe/Azure_Batch_Sample/tree/master/docker">サンプル</a>はPythonで書いたシンプルなWord Countアプリです</li>
</ul>

<p>また、アプリにデータをわたすinputコンテナーと、実行結果を書き込むoutputコンテナーも作ります。サンプルのinputデータはアメリカ国歌です。</p>

<p>さて、いよいよジョブをJSONで定義します。詳細は<a href="https://msdn.microsoft.com/en-us/library/azure/dn820158.aspx?f=255&amp;MSPPError=-2147217396">公式ドキュメント</a>を確認してください。ポイントだけまとめます。</p>

<ul>
<li>2016/04/29 05:30(UTC)から開始する - schedule/doNotRunUntil</li>
<li>4時間ごとに実行する - schedule/recurrenceInterval</li>
<li>ジョブ実行後にサーバープールを削除する - jobSpecification/poolInfo/autoPoolSpecification/poolLifetimeOption</li>
<li>ジョブ実行時にtask.shを呼び出す  - jobSpecification/jobManagerTask/commandLine</li>
<li>サーバーはUbuntu 14.04とする - jobSpecification/poolInfo/autoPoolSpecification/virtualMachineConfiguration</li>
<li>サーバー数は1台とする - jobSpecification/poolInfo/autoPoolSpecification/pool/targetDedicated</li>
<li>サーバープール作成時にstarttask.shを呼び出す - jobSpecification/poolInfo/autoPoolSpecification/pool/startTask</li>
</ul>

<pre><code>  {
  &quot;odata.metadata&quot;:&quot;https://myaccount.myregion.batch.azure.com/$metadata#jobschedules/@Element&quot;,
  &quot;id&quot;:&quot;myjobschedule1&quot;,
  &quot;schedule&quot;: {
    &quot;doNotRunUntil&quot;:&quot;2016-04-29T05:30:00.000Z&quot;,
    &quot;recurrenceInterval&quot;:&quot;PT4H&quot;
  },
  &quot;jobSpecification&quot;: {
    &quot;priority&quot;:100,
    &quot;constraints&quot;: {
      &quot;maxWallClockTime&quot;:&quot;PT1H&quot;,
      &quot;maxTaskRetryCount&quot;:-1
    },
    &quot;jobManagerTask&quot;: {
      &quot;id&quot;:&quot;mytask1&quot;,
      &quot;commandLine&quot;:&quot;/bin/bash -c 'export LC_ALL=en_US.UTF-8; ./task.sh'&quot;,
      &quot;resourceFiles&quot;: [ {
        &quot;blobSource&quot;:&quot;yourbloburi&amp;sas&quot;,
        &quot;filePath&quot;:&quot;task.sh&quot;
      }], 
      &quot;environmentSettings&quot;: [ {
        &quot;name&quot;:&quot;VAR1&quot;,
        &quot;value&quot;:&quot;hello&quot;
      } ],
      &quot;constraints&quot;: {
        &quot;maxWallClockTime&quot;:&quot;PT1H&quot;,
        &quot;maxTaskRetryCount&quot;:0,
        &quot;retentionTime&quot;:&quot;PT1H&quot;
      },
      &quot;killJobOnCompletion&quot;:false,
      &quot;runElevated&quot;:true,
      &quot;runExclusive&quot;:true
      },
      &quot;poolInfo&quot;: {
        &quot;autoPoolSpecification&quot;: {
          &quot;autoPoolIdPrefix&quot;:&quot;mypool&quot;,
          &quot;poolLifetimeOption&quot;:&quot;job&quot;,
          &quot;pool&quot;: {
            &quot;vmSize&quot;:&quot;STANDARD_D1&quot;,
            &quot;virtualMachineConfiguration&quot;: {
              &quot;imageReference&quot;: {
                &quot;publisher&quot;:&quot;Canonical&quot;,
                &quot;offer&quot;:&quot;UbuntuServer&quot;,
                &quot;sku&quot;:&quot;14.04.4-LTS&quot;,
                &quot;version&quot;:&quot;latest&quot;
              },
              &quot;nodeAgentSKUId&quot;:&quot;batch.node.ubuntu 14.04&quot;
            },
            &quot;resizeTimeout&quot;:&quot;PT15M&quot;,
            &quot;targetDedicated&quot;:1,
            &quot;maxTasksPerNode&quot;:1,
            &quot;taskSchedulingPolicy&quot;: {
              &quot;nodeFillType&quot;:&quot;Spread&quot;
            },
            &quot;enableAutoScale&quot;:false,
            &quot;enableInterNodeCommunication&quot;:false,
            &quot;startTask&quot;: {
              &quot;commandLine&quot;:&quot;/bin/bash -c 'export LC_ALL=en_US.UTF-8; ./starttask.sh'&quot;,
              &quot;resourceFiles&quot;: [ {
                &quot;blobSource&quot;:&quot;yourbloburi&amp;sas&quot;,
                &quot;filePath&quot;:&quot;starttask.sh&quot;
              } ],
              &quot;environmentSettings&quot;: [ {
                &quot;name&quot;:&quot;VAR2&quot;,
                &quot;value&quot;:&quot;Chao&quot;
              } ],
              &quot;runElevated&quot;:true,
              &quot;waitForSuccess&quot;:true
            },
            &quot;metadata&quot;: [ {
              &quot;name&quot;:&quot;myproperty&quot;,
              &quot;value&quot;:&quot;myvalue&quot;
            } ]
          }
        }
      }
    }
  }
</code></pre>

<p>他にも面白そうなパラメータがありますね。並列バッチやジョブリリース時のタスクなど、今回使っていないものもあります。応用版はまたの機会に。</p>

<p>ではスケジュールジョブをAzure BatchにCLIで送り込みます。</p>

<pre><code>azure batch job-schedule create -f ./create_jobsched.json -u https://yourendpoint.location.batch.azure.com -a yourbatchaccount -k yourbatchaccountkey
</code></pre>

<p>以上です。あとはAzureにお任せです。4時間に1回、アメリカ国歌の単語を数える刺身タンポポなジョブですが、コツコツいきましょう。</p>

<h2 id="azure-automationとの使い分け:1e958ca6820e4dcff939a22a84382ed3">Azure Automationとの使い分け</h2>

<p>Azure Automationを使っても、ジョブの定期実行はできます。大きな違いは、PowerShellの要否と並列実行フレームワークの有無です。Azure AutomationはPowerShell前提ですが、Azure BatchはPowerShellに馴染みのない人でも使うことができます。また、今回は触れませんでしたが、Azure Batchは並列バッチ、オートスケールなど、バッチ処理に特化した機能を提供していることが特長です。うまく使い分けましょう。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">21 Apr 2016, 21:30</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_pageblob_billable_linux/" class="post-title">Azure Linux VMのディスク利用料節約Tips</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="定義領域全てが課金されるわけではありません:73b15a413c7cb87e88f45a7aaba2eebd">定義領域全てが課金されるわけではありません</h2>

<p>AzureのIaaSでは、VMに接続するディスクとしてAzure StorageのPage Blobを使います。Page Blobは作成時に容量を定義しますが、課金対象となるのは、実際に書き込んだ領域分のみです。たとえば10GBytesのVHD Page Blobを作ったとしても、1GBytesしか書き込んでいなければ、課金対象は1GBytesです。</p>

<p>なお、Premium Storageは例外です。<a href="https://azure.microsoft.com/ja-jp/pricing/details/storage/">FAQ</a>を確認してみましょう。</p>

<pre><code>仮想マシンに空の 100 GB ディスクを接続した場合、100 GB 全体に対する料金が請求されますか? それとも使用したストレージ領域の分だけが請求されますか?

空の 100 GB ディスクが Premium Storage アカウントによって保持されている場合、P10 (128 GB) ディスクの料金が課金されます。その他の種類の Storage アカウントが使用されている場合、割り当てられたディスク サイズに関わらず、ディスクに書き込まれたデータを保存するために使用しているストレージ領域分のみ請求されます。
</code></pre>

<p>詳細な定義は、以下で。</p>

<p><a href="https://blogs.msdn.microsoft.com/windowsazurestorage/2010/07/08/understanding-windows-azure-storage-billing-bandwidth-transactions-and-capacity/">Understanding Windows Azure Storage Billing – Bandwidth, Transactions, and Capacity</a></p>

<h2 id="書き込み方はosやファイルシステム次第:73b15a413c7cb87e88f45a7aaba2eebd">書き込み方はOSやファイルシステム次第</h2>

<p>じゃあ、OSなりファイルシステムが、実際にどのタイミングでディスクに書き込むのか、気になりますね。実データの他に管理情報、メタデータがあるので、特徴があるはずです。Linuxで検証してみましょう。</p>

<ul>
<li>RHEL 7.2 on Azure</li>
<li>XFS &amp; Ext4</li>
<li>10GBytesのPage Blobの上にファイルシステムを作成</li>
<li>mkfsはデフォルト</li>
<li>mountはデフォルトとdiscardオプションありの2パターン</li>
<li>MD、LVM構成にしない</li>
<li>以下のタイミングで課金対象容量を確認

<ul>
<li>Page BlobのVMアタッチ時</li>
<li>ファイルシステム作成時</li>
<li>マウント時</li>
<li>約5GBytesのデータ書き込み時 (ddで/dev/zeroをbs=1M、count=5000で書き込み)</li>
<li>5GBytesのファイル削除時</li>
</ul></li>
</ul>

<p>課金対象容量は、以下のPowerShellで取得します。リファレンスは<a href="https://gallery.technet.microsoft.com/scriptcenter/Get-Billable-Size-of-32175802">ここ</a>。</p>

<pre><code>$Blob = Get-AzureStorageBlob yourDataDisk.vhd -Container vhds -Context $Ctx

$blobSizeInBytes = 124 + $Blob.Name.Length * 2

$metadataEnumerator = $Blob.ICloudBlob.Metadata.GetEnumerator()
while ($metadataEnumerator.MoveNext())
{
    $blobSizeInBytes += 3 + $metadataEnumerator.Current.Key.Length + $metadataEnumerator.Current.Value.Length
}

$Blob.ICloudBlob.GetPageRanges() | 
    ForEach-Object { $blobSizeInBytes += 12 + $_.EndOffset - $_.StartOffset }

return $blobSizeInBytes
</code></pre>

<p>ストレージコンテキストの作り方は<a href="https://azure.microsoft.com/ja-jp/documentation/articles/storage-powershell-guide-full/">ここ</a>を参考にしてください。</p>

<h2 id="結果:73b15a413c7cb87e88f45a7aaba2eebd">結果</h2>

<h3 id="xfs:73b15a413c7cb87e88f45a7aaba2eebd">XFS</h3>

<table>
<thead>
<tr>
<th align="left">　確認タイミング　</th>
<th align="right">　課金対象容量(Bytes)　</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Page BlobのVMアタッチ時</td>
<td align="right">960</td>
</tr>

<tr>
<td align="left">ファイルシステム作成時</td>
<td align="right">10,791,949</td>
</tr>

<tr>
<td align="left">マウント時</td>
<td align="right">10,791,949</td>
</tr>

<tr>
<td align="left">5GBytesのデータ書き込み時</td>
<td align="right">5,253,590,051</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時</td>
<td align="right">5,253,590,051</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時 (discard)</td>
<td align="right">10,710,029</td>
</tr>
</tbody>
</table>

<h3 id="ext4:73b15a413c7cb87e88f45a7aaba2eebd">Ext4</h3>

<table>
<thead>
<tr>
<th align="left">　確認タイミング　</th>
<th align="right">　課金対象容量(Bytes)　</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Page BlobのVMアタッチ時</td>
<td align="right">960</td>
</tr>

<tr>
<td align="left">ファイルシステム作成時</td>
<td align="right">138,683,592</td>
</tr>

<tr>
<td align="left">マウント時</td>
<td align="right">306,451,689</td>
</tr>

<tr>
<td align="left">5GBytesのデータ書き込み時</td>
<td align="right">5,549,470,887</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時</td>
<td align="right">5,549,470,887</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時 (discard)</td>
<td align="right">306,586,780</td>
</tr>
</tbody>
</table>

<p>この結果から、以下のことがわかります。</p>

<ul>
<li>10GBytesのBlobを作成しても、全てが課金対象ではない</li>
<li>当然だが、ファイルシステムによってメタデータの書き方が違う、よって書き込み容量も異なる</li>
<li>discardオプションなしでマウントすると、ファイルを消しても課金対象容量は減らない

<ul>
<li>OSがPage Blobに&rdquo;消した&rdquo;と伝えないから</li>
<li>discardオプションにてSCSI UNMAPがPage Blobに伝えられ、領域は解放される(課金対象容量も減る)</li>
<li>discardオプションはリアルタイムであるため便利。でも性能影響があるため、実運用ではバッチ適用(fstrim)が<a href="https://access.redhat.com/documentation/ja-JP/Red_Hat_Enterprise_Linux/7/html/Storage_Administration_Guide/ch02s05.html">おすすめ</a></li>
</ul></li>
</ul>

<p>知っているとコスト削減に役立つTipsでした。ぜひ運用前には、利用予定のファイルシステムやオプションで、事前に検証してみてください。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">17 Apr 2016, 10:30</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_docker_cntk/" class="post-title">AzureとDockerでDeep Learning(CNTK)環境をサク作する</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="気軽に作って壊せる環境を作る:7c419a069d08019c3093e0308a68c463">気軽に作って壊せる環境を作る</h2>

<p>Deep Learning環境設計のお手伝いをする機会に恵まれまして。インフラおじさんはDeep Learningであれこれする主役ではないのですが、ちょっとは中身を理解しておきたいなと思い、環境作ってます。</p>

<p>試行錯誤するでしょうから、萎えないようにデプロイは自動化します。</p>

<h2 id="方針:7c419a069d08019c3093e0308a68c463">方針</h2>

<ul>
<li>インフラはAzure Resource Manager Templateでデプロイする

<ul>
<li>Linux (Ubuntu 14.04) VM, 仮想ネットワーク/ストレージ関連リソース</li>
</ul></li>
<li>CNTKをビルド済みのdockerリポジトリをDocker Hubに置いておく

<ul>
<li>Dockerfileの元ネタは<a href="https://github.com/Microsoft/CNTK/tree/master/Tools/docker">ここ</a>

<ul>
<li>GPUむけもあるけどグッと我慢、今回はCPUで</li>
</ul></li>
<li>Docker Hub上のリポジトリは <a href="https://hub.docker.com/r/torumakabe/cntk-cpu/">torumakabe/cntk-cpu</a></li>
</ul></li>
<li>ARM TemplateデプロイでVM Extensionを仕込んで、上物のセットアップもやっつける

<ul>
<li>docker extensionでdocker engineを導入</li>
<li>custom script extensionでdockerリポジトリ(torumakabe/cntk-cpu)をpull</li>
</ul></li>
<li>VMにログインしたら即CNTKを使える、幸せ</li>
</ul>

<h2 id="使い方:7c419a069d08019c3093e0308a68c463">使い方</h2>

<p>Azure CLIでARM Templateデプロイします。WindowsでもMacでもLinuxでもOK。</p>

<p>リソースグループを作ります。</p>

<pre><code>C:\Work&gt; azure group create CNTK -l &quot;Japan West&quot;
</code></pre>

<p>ARMテンプレートの準備をします。テンプレートはGithubに置いておきました。</p>

<ul>
<li><a href="https://github.com/ToruMakabe/CNTK/blob/master/deploy_singlenode/azuredeploy.json">azuredeploy.json</a>

<ul>
<li>編集不要です</li>
</ul></li>
<li><a href="https://github.com/ToruMakabe/CNTK/blob/master/deploy_singlenode/azuredeploy.parameters.sample.json">azuredeploy.parameters.json</a>

<ul>
<li>テンプレートに直で書かきたくないパラメータです</li>
<li>fileUris、commandToExecute以外は、各々で</li>
<li>fileUris、commandToExecuteもGist読んでdocker pullしているだけなので、お好みで変えてください</li>
<li>ファイル名がazuredeploy.parameters.&ldquo;sample&rdquo;.jsonなので、以降の手順では&rdquo;sample&rdquo;を外して読み替えてください</li>
</ul></li>
</ul>

<p>うし、デプロイ。</p>

<pre><code>C:\Work&gt; azure group deployment create CNTK dep01 -f .\azuredeploy.json -e .\azuredeploy.parameters.json
</code></pre>

<p>10分くらい待つと、できあがります。VMのパブリックIPを確認し、sshしましょう。</p>

<p>docker engine入ってますかね。</p>

<pre><code>yourname@yournamecntkr0:~$ docker -v
Docker version 1.11.0, build 4dc5990
</code></pre>

<p>CNTKビルド済みのdockerイメージ、pullできてますかね。</p>

<pre><code>yourname@yournamecntkr0:~$ docker images
REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
yournamebe/cntk-cpu   latest              9abab8a76543        9 hours ago         2.049 GB
</code></pre>

<p>問題なし。ではエンジョイ Deep Learning。</p>

<pre><code>yourname@yournamecntkr0:~$ docker run -it torumakabe/cntk-cpu
root@a1234bc5d67d:/cntk#
</code></pre>

<p>CNTKの利用例は、<a href="https://github.com/Microsoft/CNTK/tree/master/Examples">Github</a>にあります。</p>

<h2 id="今後の展開:7c419a069d08019c3093e0308a68c463">今後の展開</h2>

<p>インフラおじさんは、最近Linuxむけに<a href="https://azure.microsoft.com/ja-jp/blog/announcing-support-of-linux-vm-on-azure-batch-service/">Previewがはじまった</a>Azure Batchと、このエントリで使った仕掛けを組み合わせて、大規模並列Deep Learning環境の自動化と使い捨て化を企んでいます。</p>

<p>これだけ簡単に再現性ある環境を作れるなら、常時インフラ起動しておく必要ないですものね。使い捨てでいいです。</p>

<p>もちろんdockerやGPUまわりの性能など別の課題にぶつかりそうですが、人間がどれだけ楽できるかとのトレードオフかと。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">06 Apr 2016, 17:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_auditlog_alert/" class="post-title">Azureの監査ログアラートからWebhookの流れで楽をする</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="監査ログからアラートを上げられるようになります:aafd9305d99be4ae8d2b9c3fb4887452">監査ログからアラートを上げられるようになります</h2>

<p>Azureの監査ログからアラートを上げる機能のプレビューが<a href="https://azure.microsoft.com/ja-jp/blog/new-features-for-azure-alerts-and-autoscale/">はじまりました</a>。これ、地味ですが便利な機能です。日々の運用に効きます。</p>

<h2 id="どんな風に使えるか:aafd9305d99be4ae8d2b9c3fb4887452">どんな風に使えるか</h2>

<p>ルールに合致した監査ログが生成された場合、メール通知とWebhookによる自動アクションができます。可能性無限大です。</p>

<p>たとえば、「特定のリソースグループにVMが生成された場合、そのVMに対し強制的にログ収集エージェントをインストールし、ログを集める」なんてことができます。</p>

<p>これは「生産性を上げるため、アプリ開発チームにVMの生成は委任したい。でもセキュリティなどの観点から、ログは集めておきたい」なんてインフラ担当/Opsの課題に効きます。開発チームに「VM生成時には必ず入れてね」とお願いするのも手ですが、やはり人間は忘れる生き物ですので、自動で適用できる仕組みがあるとうれしい。</p>

<p>これまでは監視用のVMを立てて、「新しいVMがあるかどうか定期的にチェックして、あったらエージェントを叩き込む」なんてことをしていたわけですが、もうそのVMは不要です。定期的なチェックも要りません。アラートからアクションを実現する仕組みを、Azureがマネージドサービスとして提供します。</p>

<h2 id="実装例:aafd9305d99be4ae8d2b9c3fb4887452">実装例</h2>

<p>例としてこんな仕組みを作ってみましょう。</p>

<ul>
<li>西日本リージョンのリソースグループ&rdquo;dev&rdquo;にVMが作成されたら、自動的にメール通知とWebhookを実行</li>
<li>WebhookでAzure AutomationのRunbook Jobを呼び出し、OMS(Operations Management Suite)エージェントを該当のVMにインストール、接続先OMSを設定する</li>
<li>OMSでログ分析</li>
</ul>

<h2 id="準備:aafd9305d99be4ae8d2b9c3fb4887452">準備</h2>

<p>以下の準備ができているか確認します。</p>

<ul>
<li>Azure Automation向けADアプリ、サービスプリンシパル作成</li>
<li>サービスプリンシパルへのロール割り当て</li>
<li>Azure Automationのアカウント作成</li>
<li>Azure Automation Runbook実行時ログインに必要な証明書や資格情報などの資産登録</li>
<li>Azure Automation Runbookで使う変数資産登録 (Runbook内でGet-AutomationVariableで取得できます。暗号化もできますし、コードに含めるべきでない情報は、登録しましょう。後述のサンプルではログイン関連情報、OMS関連情報を登録しています)</li>
<li>OMSワークスペースの作成</li>
</ul>

<p>もしAutomationまわりの作業がはじめてであれば、下記記事を参考にしてください。とてもわかりやすい。</p>

<p><strong><a href="http://qiita.com/sengoku/items/1c3994ac8a2f0f0e88c5">勤務時間中だけ仮想マシンを動かす（スケジュールによる自動起動・停止）</a></strong></p>

<h2 id="azure-automation側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452">Azure Automation側の仕掛け</h2>

<p>先にAutomationのRunbookを作ります。アラート設定をする際、RunbookのWebhook URLが必要になるので。</p>

<p>ちなみにわたしは証明書を使ってログインしています。資格情報を使う場合はログインまわりのコードを読み替えてください。</p>

<pre><code>param ( 
    [object]$WebhookData          
)

if ($WebhookData -ne $null) {  
    $WebhookName    =   $WebhookData.WebhookName
    $WebhookBody    =   $WebhookData.RequestBody  
    $WebhookBody = (ConvertFrom-Json -InputObject $WebhookBody)

    $AlertContext = [object]$WebhookBody.context

    $SPAppID = Get-AutomationVariable -Name 'SPAppID'
    $Tenant = Get-AutomationVariable -Name 'TenantID'
    $OMSWorkspaceId = Get-AutomationVariable -Name 'OMSWorkspaceId'
    $OMSWorkspaceKey = Get-AutomationVariable -Name 'OMSWorkspaceKey'
    $CertificationName = Get-AutomationVariable -Name 'CertificationName'
    $Certificate = Get-AutomationCertificate -Name $CertificationName
    $CertThumbprint = ($Certificate.Thumbprint).ToString()    

    $null = Login-AzureRmAccount -ServicePrincipal -TenantId $Tenant -CertificateThumbprint $CertThumbprint -ApplicationId $SPAppID   

    $resourceObj = Get-AzureRmResource -ResourceId $AlertContext.resourceId
    $VM = Get-AzureRmVM -Name $resourceObj.Name -ResourceGroupName $resourceObj.ResourceGroupName

    $Settings = @{&quot;workspaceId&quot; = &quot;$OMSWorkspaceId&quot;}
    $ProtectedSettings = @{&quot;workspaceKey&quot; = &quot;$OMSWorkspaceKey&quot;}

    if ($VM.StorageProfile.OsDisk.OsType -eq &quot;Linux&quot;) {  
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &quot;OmsAgentForLinux&quot; -Publisher &quot;Microsoft.EnterpriseCloud.Monitoring&quot; -ExtensionType &quot;OmsAgentForLinux&quot; -TypeHandlerVersion &quot;1.0&quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    elseif ($VM.StorageProfile.OsDisk.OsType -eq &quot;Windows&quot;)
    {
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &quot;MicrosoftMonitoringAgent&quot; -Publisher &quot;Microsoft.EnterpriseCloud.Monitoring&quot; -ExtensionType &quot;MicrosoftMonitoringAgent&quot; -TypeHandlerVersion &quot;1.0&quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    else
    {
        Write-Error &quot;Unknown OS Type.&quot;
    }
}
else 
{
    Write-Error &quot;This runbook is meant to only be started from a webhook.&quot; 
}
</code></pre>

<p>Runbookができたら、Webhookを作ります。詳しくは<a href="https://azure.microsoft.com/ja-jp/documentation/articles/automation-webhooks/">こちら</a>。</p>

<p>WebhookのURLを控えておいてください。</p>

<h2 id="azure-監査ログアラート側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452">Azure 監査ログアラート側の仕掛け</h2>

<p>Powershellでアラートルールを作ります。実行アカウントの権限に気をつけてください。</p>

<pre><code>PS C:\work&gt; $actionEmail = New-AzureRmAlertRuleEmail -CustomEmail yourname@example.com

PS C:\work&gt; $actionWebhook = New-AzureRmAlertRuleWebhook -ServiceUri https://abcdefgh.azure-automation.net/webhooks?token=your_token

PS C:\work&gt; Add-AzureRmLogAlertRule -Name createdVM -Location &quot;Japan West&quot; -ResourceGroup dev -OperationName Microsoft.Compute/virtualMachines/write -Status Succeeded  -SubStatus Created -TargetResourceGroup dev -Actions $actionEmail,$actionWebhook
</code></pre>

<p>以上。これで&rdquo;dev&rdquo;リソースグループにVMが作られた場合、自動でOMSエージェントがインストールされ、ログ収集がはじまります。</p>

<p>なお、メールも飛んできますので、うっとおしくなったらメール通知はアクションから外すか、ルールでさばいてくださいね。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">25 Mar 2016, 22:50</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_terraform_earlyphase_tips/" class="post-title">Azure &amp; Terraform Tips (ARM対応 2016春版)</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="俺の屍を越えていけ:9776a375b7d12db77e52b9c8d97b8677">俺の屍を越えていけ</h2>

<p>今週リリースされたTerraform v0.6.14で、Azure Resource Manager ProviderのリソースにVMとテンプレートデプロイが<a href="https://github.com/hashicorp/terraform/blob/v0.6.14/CHANGELOG.md">追加</a>されました。この週末お楽しみ、という人も多いかもしれません。</p>

<p>小生、v0.6.14以前から触っていたこともあり、土地勘があります。そこで現時点でのTipsをいくつかご紹介します。</p>

<h2 id="この3つは触る前から意識しよう:9776a375b7d12db77e52b9c8d97b8677">この3つは触る前から意識しよう</h2>

<ol>
<li>ARMテンプレートリソースは分離して使う</li>
<li>リソース競合したら依存関係を定義する</li>
<li>公開鍵認証SSH指定でエラーが出ても驚かない</li>
</ol>

<h2 id="1-armテンプレートリソースは分離して使う:9776a375b7d12db77e52b9c8d97b8677">1. ARMテンプレートリソースは分離して使う</h2>

<p>v0.6.14で、リソース<a href="https://www.terraform.io/docs/providers/azurerm/r/template_deployment.html">&ldquo;azurerm_template_deployment&rdquo;</a>が追加されました。なんとARMテンプレートを、Terraformの定義ファイル内にインラインで書けます。</p>

<p>でも、現時点の実装では、おすすめしません。</p>

<h3 id="armテンプレートのデプロイ機能とterraformで作ったリソースが不整合を起こす:9776a375b7d12db77e52b9c8d97b8677">ARMテンプレートのデプロイ機能とTerraformで作ったリソースが不整合を起こす</h3>

<p>避けるべきなのは&rdquo;Complete(完全)&ldquo;モードでのARMテンプレートデプロイです。なぜなら完全モードでは、ARM リソースマネージャーは次の動きをするからです。</p>

<p><strong><a href="https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-template-deploy/">リソース グループに存在するが、テンプレートに指定されていないリソースを削除します</a></strong></p>

<p>つまり、ARMテンプレートで作ったリソース以外、Terraform担当部分を消しにいきます。恐怖! デプロイ vs デプロイ!!。リソースグループを分ければ回避できますが、リスク高めです。</p>

<h3 id="タイムアウトしがち:9776a375b7d12db77e52b9c8d97b8677">タイムアウトしがち</h3>

<p>それでもTerraformの外でARMテンプレートデプロイは継続します。成功すれば結果オーライですが&hellip;Terraform上はエラーが残ります。「ああそれ無視していいよ」ではあるのですが、<a href="https://ja.wikipedia.org/wiki/%E5%89%B2%E3%82%8C%E7%AA%93%E7%90%86%E8%AB%96">割れ窓理論</a>的によろしくないです。</p>

<h3 id="せっかくのリソースグラフを活用できない:9776a375b7d12db77e52b9c8d97b8677">せっかくのリソースグラフを活用できない</h3>

<p>Terraformはグラフ構造で賢くリソース間の依存関係を管理し、整合性を維持しています。サクサク apply &amp; destroyできるのもそれのおかげです。ARMテンプレートでデプロイしたリソースはそれに入れられないので、もったいないです。</p>

<h3 id="読みづらい:9776a375b7d12db77e52b9c8d97b8677">読みづらい</h3>

<p>Terraform DSLにJSONが混ざって読みにくいです。Terraform DSLを使わない手もありますが、それでいいのかという話です。</p>

<p>それでも&rdquo;terraformコマンドに操作を統一したい&rdquo;など、どうしても使いたい人は、ARMテンプレート実行部は管理も実行も分離した方がいいと思います。</p>

<h2 id="2-リソース競合したら依存関係を定義する:9776a375b7d12db77e52b9c8d97b8677">2. リソース競合したら依存関係を定義する</h2>

<p>Terraformはリソース間の依存関係を明示する必要がありません。ですが、行き届かないこともあります。その場合は<a href="https://www.terraform.io/intro/getting-started/dependencies.html">&ldquo;depends_on&rdquo;</a>で明示してあげましょう。</p>

<p>例えば、<a href="http://torumakabe.github.io/post/azure_terraform_429_workaround/">以前のエントリ</a>で紹介した下記の問題。</p>

<pre><code>Error applying plan:

1 error(s) occurred:
azurerm_virtual_network.vnet1: autorest:DoErrorUnlessStatusCode 429 PUT https://management.azure.com/subscriptions/my_subscription_id/resourceGroups/mygroup/providers/Microsoft.Network/virtualnetworks/vnet1?api-version=2015-06-15 failed with 429


Cannot proceed with operation since resource /subscriptions/GUID/resourceGroups/xxxx/providers/Microsoft.Network/networkSecurityGroups/yyy allocated to resource /subscriptions/GUID/resourceGroups/***/providers/Microsoft.Network/virtualNetworks/yyy is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is PutSecurityRuleOperation. 
</code></pre>

<p>HTTPステータスコード429(Too many requests)が返ってきているのでわかりにくいですが、実態はセキュリティーグループリソースの取り合いです。</p>

<ul>
<li>サブネットリソース作成側: サブネットを新規作成し、セキュリティーグループを紐付けたい</li>
<li>セキュリティーグループルール作成側: ルールをセキュリティーグループに登録したい(更新処理)</li>
</ul>

<p>この2つが並行してセキュリティーグループを取り合うので、高確率でエラーになります。セキュリティーグループルールはリソースの新規作成でなく、セキュリティーグループの更新処理であるため「リソースを<strong>作成したら/存在したら</strong>次にすすむ」というTerraformのグラフでうまく表現できないようです。</p>

<p>そのような場合、明示的に依存関係を&rdquo;depends_on&rdquo;で定義します。</p>

<pre><code># Create a frontend subnet
# &quot;depends_on&quot; arg is a workaround to avoid conflict with updating NSG rules 
resource &quot;azurerm_subnet&quot; &quot;frontend&quot; {
    name = &quot;frontend&quot;
    resource_group_name = &quot;${var.resource_group_name}&quot;
    virtual_network_name = &quot;${azurerm_virtual_network.vnet1.name}&quot;
    address_prefix = &quot;${var.vnet1_frontend_address_prefix}&quot;
    network_security_group_id = &quot;${azurerm_network_security_group.frontend.id}&quot;
    depends_on = [
        &quot;azurerm_network_security_rule.fe_web80&quot;,
        &quot;azurerm_network_security_rule.fe_web443&quot;,
        &quot;azurerm_network_security_rule.fe_ssh&quot;
    ]
}
</code></pre>

<p>これでサブネット作成処理は、セキュリティーグループルール登録完了まで、作成処理開始を待ちます。美しくないですが、当面の回避策です。</p>

<h2 id="3-公開鍵認証ssh指定でエラーが出ても驚かない:9776a375b7d12db77e52b9c8d97b8677">3. 公開鍵認証SSH指定でエラーが出ても驚かない</h2>

<p>TerraformはLinux VMの定義で、公開鍵認証SSHを指定できます。こんな感じで。</p>

<pre><code>os_profile_linux_config {
    disable_password_authentication = true
    ssh_keys {
        path = &quot;/home/${var.adminuser}/.ssh/authorized_keys&quot;
        key_data = &quot;${file(&quot;/Users/you/.ssh/yourkey.pem&quot;)}&quot;
    }
}
</code></pre>

<p>が、エラーが返ってきます。</p>

<pre><code>[DEBUG] Error setting Virtual Machine Storage OS Profile Linux Configuration: &amp;errors.errorString{s:&quot;Invalid address to set: []string{\&quot;os_profile_linux_config\&quot;, \&quot;12345678\&quot;, \&quot;ssh_keys\&quot;}&quot;}
</code></pre>

<p>残念ながら、Terraformが使っているAzure SDK(Golang)のバグです。</p>

<p>妥当性チェックのエラーで、実際にはキーの登録はできているようです。私は何度か試行してすべて公開鍵SSHログインに成功しています。</p>

<p><a href="https://github.com/hashicorp/terraform/issues/5793">Issueとして認識</a>されていますので、修正を待ちましょう。</p>

                    </div>
                </section>
                
            </div>
            
<div class="pagination">
  <nav role="pagination" class="post-list-pagination">
      
    <span class="post-list-pagination-item post-list-pagination-item-current">Page 1 of 4</span>
    
      <a href="/tags/azure/page/2/" class="post-list-pagination-item pure-button post-list-pagination-item-next">
        Older&nbsp;<i class="fa fa-angle-double-right"></i>
      </a>
    
  </nav>
</div>


            <div class="footer">
    <div class="pure-menu pure-menu-horizontal pure-menu-open">
        <ul>
            <li>Powered by <a class="hugo" href="http://hugo.spf13.com/" target="_blank">hugo</a></li>
        </ul>
    </div>
</div>
<script src="http://torumakabe.github.io//js/all.min.js"></script>
        </div>
    </div>
</div>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');

</script>

</body>
</html>
