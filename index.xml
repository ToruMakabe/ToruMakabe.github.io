<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>re-imagine</title>
    <link>http://torumakabe.github.io/</link>
    <description>Recent content on re-imagine</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 07 Oct 2016 17:00:00 +0900</lastBuildDate>
    <atom:link href="http://torumakabe.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>SlackとAzure FunctionsでChatOpsする</title>
      <link>http://torumakabe.github.io/post/azure_chatops_onfunctions/</link>
      <pubDate>Fri, 07 Oct 2016 17:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_chatops_onfunctions/</guid>
      <description>

&lt;h2 id=&#34;azure-functionsでやってみよう:3a5e8d97b60e50a739f033a761af1408&#34;&gt;Azure Functionsでやってみよう&lt;/h2&gt;

&lt;p&gt;Azure上でChatOpsしたい、と相談をいただきました。&lt;/p&gt;

&lt;p&gt;AzureでChatOpsと言えば、Auth0のSandrino Di Mattia氏が作った素敵な&lt;a href=&#34;http://fabriccontroller.net/chatops-deploy-and-manage-complete-environments-on-azure-using-slack/&#34;&gt;サンプル&lt;/a&gt;があります。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://fabriccontroller.net/static/chatops-how-this-works.png.pagespeed.ce.lN444drUKd.png&#34; alt=&#34;Azure Runスラッシュ&#34; title=&#34;from fabriccontroller.net&#34; /&gt;&lt;/p&gt;

&lt;p&gt;素晴らしい。これで十分、という気もしますが、実装のバリエーションがあったほうが後々参考になる人も多いかなと思い、Web App/Web JobをAzure Functionsで置き換えてみました。&lt;/p&gt;

&lt;h2 id=&#34;slackからrunbookを実行できて-何がうれしいか:3a5e8d97b60e50a739f033a761af1408&#34;&gt;SlackからRunbookを実行できて、何がうれしいか&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;誰がいつ、どんな文脈でRunbookを実行したかを可視化する&lt;/li&gt;
&lt;li&gt;CLIやAPIをRunbookで隠蔽し、おぼえることを減らす&lt;/li&gt;
&lt;li&gt;CLIやAPIをRunbookで隠蔽し、できることを制限する&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ブツ:3a5e8d97b60e50a739f033a761af1408&#34;&gt;ブツ&lt;/h2&gt;

&lt;p&gt;Githubに上げておきました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ToruMakabe/AZChatOpsSample&#34;&gt;AZChatOpsSample&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;おおまかな流れ:3a5e8d97b60e50a739f033a761af1408&#34;&gt;おおまかな流れ&lt;/h2&gt;

&lt;p&gt;手順書つらいのでポイントだけ。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;SlackのSlash CommandとIncoming Webhookを作る&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;流れは氏の&lt;a href=&#34;http://fabriccontroller.net/chatops-deploy-and-manage-complete-environments-on-azure-using-slack/&#34;&gt;元ネタ&lt;/a&gt;と同じ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ARM TemplateでFunction Appをデプロイ&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Github上のDeployボタンからでもいいですが、パラメータファイルを作っておけばCLIで楽に繰り返せます&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;パラメータファイルのサンプルは&lt;a href=&#34;https://github.com/ToruMakabe/AZChatOpsSample/blob/master/sample.azuredeploy.parameters.json&#34;&gt;sample.azuredeploy.parameters.json&lt;/a&gt;です。GUIでデプロイするにしても、パラメータの意味を理解するためにざっと読むと幸せになれると思います&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Function AppのデプロイはGithubからのCIです。クローンしたリポジトリとブランチを指定してください&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GithubからのCIは、&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/app-service-deploy-complex-application-predictably/&#34;&gt;はじめてのケースを考慮し&lt;/a&gt;ARM Templateのリソースプロパティ&amp;rdquo;IsManualIntegration&amp;rdquo;をtrueにしています&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Azure Automationのジョブ実行権限を持つサービスプリンシパルが必要です (パラメータ SUBSCRIPTION_ID、TENANT_ID、CLIENT_ID、CLIENT_SECRET で指定)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Azure Automationについて詳しく説明しませんが、Slackから呼び出すRunbookを準備しておいてください。そのAutomationアカウントと所属するリソースグループを指定します&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;作成済みのSlack関連パラメータを指定します&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ARM Templateデプロイ後にkuduのデプロイメントスクリプトが走るので、しばし待つ(Function Appの設定-&amp;gt;継続的インテグレーションの構成から進捗が見えます)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;デプロイ後、Slash Commandで呼び出すhttptrigger function(postJob)のtokenを変更&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;kuduでdata/Functions/secrets/postJob.jsonの値を、Slackが生成したSlash Commandのtokenに書き換え&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Slack上で、Slash Commandのリクエスト先URLを変更 (例: &lt;a href=&#34;https://yourchatops.azurewebsites.net/api/postJob?code=TokenTokenToken&#34;&gt;https://yourchatops.azurewebsites.net/api/postJob?code=TokenTokenToken&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ファンクションが動いたら、Slackの指定チャンネルでSlash Commandが打てるようになる&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;/runbook [runbook名] [parm1] [parm2] [parm&amp;hellip;]&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;パラメータはrunbook次第&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Runbookの進捗はIncoming Webhookでslackに通知される&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Runbookのステータスが変わったときに通知&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;よもやま話:3a5e8d97b60e50a739f033a761af1408&#34;&gt;よもやま話&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;SlackのSlash Commandは、3秒以内に返事を返さないとタイムアウトします。なのでいくつか工夫しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ファンクションはトリガーされるまで寝ています。また、5分間動きがないとこれまた寝ます(cold状態になる)。寝た子を起こすのには時間がかかるので、Slackの3秒ルールに間に合わない可能性があります。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Azure FunctionsのWebコンソールログが無活動だと30分で停止するので、coldに入る条件も30分と誤解していたのですが、正しくは5分。ソースは&lt;a href=&#34;https://github.com/Azure/azure-webjobs-sdk-script/issues/529&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;そこで、4分周期でTimer Triggerし、postJobにダミーPOSTするpingFuncを作りました。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ファンクションのコードに更新があった場合、リロード処理が走ります。リロード後、またしてもトリガーを待って寝てしまうので、コード変更直後にSlash Commandを打つとタイムアウトする可能性大です。あせらずpingまで待ちましょう。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Azure Functionsはまだプレビューなので、&lt;a href=&#34;https://github.com/Azure/azure-webjobs-sdk-script/issues/529&#34;&gt;議論されているとおり&lt;/a&gt;改善の余地が多くあります。期待しましょう。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Bash on WindowsでNode開発環境を作る</title>
      <link>http://torumakabe.github.io/post/bashonwindows_nvm/</link>
      <pubDate>Wed, 14 Sep 2016 15:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/bashonwindows_nvm/</guid>
      <description>

&lt;h2 id=&#34;bash-on-windows-現時点での使いどころ:a32d2312b9ac4610e007379f05304450&#34;&gt;Bash on Windows 現時点での使いどころ&lt;/h2&gt;

&lt;p&gt;Windows 10 Anniversary Updateでベータ提供がはじまったBash on Ubuntu on Windows、みなさん使ってますか。わたしは、まだベータなので本気運用ではないのですが、開発ツールを動かすのに使い始めてます。Linux/Macと同じツールが使えるってのは便利です。&lt;/p&gt;

&lt;p&gt;たとえばNodeのバージョン管理。Windowsには&lt;a href=&#34;https://github.com/marcelklehr/nodist&#34;&gt;nodist&lt;/a&gt;がありますが、Linux/Macでは動きません。Linux/Macで使ってる&lt;a href=&#34;https://github.com/creationix/nvm&#34;&gt;NVM&lt;/a&gt;がWindowsで動いたら、いくつもバージョン管理ツールを覚えずに済むのに！あ、Bash on Windowsあるよ！！おお、そうだな！！！という話です。&lt;/p&gt;

&lt;p&gt;最近、Azure FunctionsでNode v6.4.0が&lt;a href=&#34;https://blogs.msdn.microsoft.com/appserviceteam/2016/09/01/azure-functions-0-5-release-august-portal-update/&#34;&gt;使えるようになった&lt;/a&gt;ので、「これからバージョン管理どうすっかな」と考えていた人も多いのでは。それはわたしです。&lt;/p&gt;

&lt;h2 id=&#34;nvmのインストール:a32d2312b9ac4610e007379f05304450&#34;&gt;NVMのインストール&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Bash on Ubuntu on Windowsを入れます (&lt;a href=&#34;http://www.atmarkit.co.jp/ait/articles/1608/08/news039.html&#34;&gt;参考&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Bash on Ubuntu on Windowsを起動します&lt;/li&gt;
&lt;li&gt;build-essentialとlibssl-devを入れます&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install build-essential checkinstall
sudo apt-get install libssl-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;インストールスクリプトを流します&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.31.7/install.sh | bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;バージョンアップを考慮し、インストールのつど&lt;a href=&#34;https://github.com/creationix/nvm&#34;&gt;公式ページ&lt;/a&gt;を確認してください。&lt;/p&gt;

&lt;p&gt;以上。&lt;/p&gt;

&lt;h2 id=&#34;nvmの使い方:a32d2312b9ac4610e007379f05304450&#34;&gt;NVMの使い方&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;nvm install 6.4.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指定のバージョンをインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nvm use 6.4.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使うバージョンを指定します。&lt;/p&gt;

&lt;p&gt;簡単ですね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /mnt/c/your_work_directory
node ./index.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なんて感じで、書いたコードをテストしちゃってください。&lt;/p&gt;

&lt;p&gt;なお、Visual Studio Code使いの人は&lt;a href=&#34;https://blogs.msdn.microsoft.com/ayatokura/2016/08/06/vsc_windows_bash/&#34;&gt;統合ターミナルをBashにしておく&lt;/a&gt;と、さらに幸せになれます。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure Functionsで運用管理サーバレス生活(使用量データ取得編)</title>
      <link>http://torumakabe.github.io/post/azurefunctions_getusagedata/</link>
      <pubDate>Tue, 13 Sep 2016 17:30:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azurefunctions_getusagedata/</guid>
      <description>

&lt;h2 id=&#34;背景と動機:13f4070f39b47880df2f217875deb9f9&#34;&gt;背景と動機&lt;/h2&gt;

&lt;p&gt;Azure Functions使ってますか。「サーバレス」という、ネーミングに突っ込みたい衝動を抑えられないカテゴリに属するため損をしている気もしますが、システムのつくり方を変える可能性がある、潜在能力高めなヤツです。キャッチアップして損はないです。&lt;/p&gt;

&lt;p&gt;さて、Azure Functionsを使ってAzureの使用量データを取得、蓄積したいというリクエストを最近いくつかいただきました。いい機会なのでまとめておきます。以下、その背景。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;運用管理業務がビジネスの差別化要素であるユーザは少ない。可能な限り省力化したい。運用管理ソフトの導入維持はもちろん、その土台になるサーバの導入、維持は真っ先に無くしたいオーバヘッド。もうパッチ当てとか監視システムの監視とか、やりたくない。&lt;/li&gt;
&lt;li&gt;Azure自身が持つ運用管理の機能が充実し、また、運用管理SaaS(&lt;a href=&#34;https://www.microsoft.com/ja-jp/server-cloud/products-operations-management-suite.aspx&#34;&gt;MS OMS&lt;/a&gt;、New Relic、Datadogなど)が魅力的になっており、使い始めている。いつかは運用管理サーバを無くしたい。&lt;/li&gt;
&lt;li&gt;でも、それら標準的なサービスでカバーされていない、ちょっとした機能が欲しいことがある。&lt;/li&gt;
&lt;li&gt;Azureリソースの使用量データ取得が一例。Azureでは使用量データを&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/billing-understand-your-bill/&#34;&gt;ポータルからダウンロード&lt;/a&gt;したり、&lt;a href=&#34;https://powerbi.microsoft.com/ja-jp/documentation/powerbi-content-pack-azure-enterprise/&#34;&gt;Power BIで分析&lt;/a&gt;できたりするが、元データは自分でコントロールできるようためておきたい。もちろん手作業なし、自動で。&lt;/li&gt;
&lt;li&gt;ちょっとしたコードを気軽に動かせる仕組みがあるなら、使いたい。インフラエンジニアがさくっと書くレベルで。&lt;/li&gt;
&lt;li&gt;それAzure Functionsで出来るよ。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;方針:13f4070f39b47880df2f217875deb9f9&#34;&gt;方針&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Azure FunctionsのTimer Triggerを使って、日次で実行&lt;/li&gt;
&lt;li&gt;Azure Resource Usage APIを使って使用量を取得し、ファイルに書き込み&lt;/li&gt;
&lt;li&gt;Nodeで書く (C#のサンプルはたくさんあるので)&lt;/li&gt;
&lt;li&gt;業務、チームでの運用を考慮して、ブラウザでコード書かずにソース管理ツールと繋げる (Githubを使う)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;quick-start:13f4070f39b47880df2f217875deb9f9&#34;&gt;Quick Start&lt;/h2&gt;

&lt;h3 id=&#34;準備:13f4070f39b47880df2f217875deb9f9&#34;&gt;準備&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;ところでAzure Funtionsって何よ、って人はまず&lt;a href=&#34;https://blogs.technet.microsoft.com/azure-sa-members/azurefunctions/&#34;&gt;いい資料1&lt;/a&gt;と&lt;a href=&#34;https://buchizo.wordpress.com/2016/06/04/azure-functions-overview-and-under-the-hood/&#34;&gt;いい資料2&lt;/a&gt;でざっと把握を&lt;/li&gt;
&lt;li&gt;AzureのAPIにプログラムからアクセスするため、サービスプリンシパルを作成 (&lt;a href=&#34;https://doc.co/66mYfB&#34;&gt;ここ&lt;/a&gt;とか&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-authenticate-service-principal/&#34;&gt;ここ&lt;/a&gt;を参考に)

&lt;ul&gt;
&lt;li&gt;後ほど環境変数に設定するので、Domain(Tenant ID)、Client ID(App ID)、Client Secret(Password)、Subscription IDを控えておいてください&lt;/li&gt;
&lt;li&gt;権限はsubscriptionに対するreaderが妥当でしょう&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Githubのリポジトリを作成 (VSTSやBitbucketも使えます)&lt;/li&gt;
&lt;li&gt;使用量データを貯めるストレージアカウントを作成

&lt;ul&gt;
&lt;li&gt;後ほど環境変数に設定するので、接続文字列を控えておいてください&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;デプロイ:13f4070f39b47880df2f217875deb9f9&#34;&gt;デプロイ&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Function Appを作成

&lt;ul&gt;
&lt;li&gt;ポータル左上&amp;rdquo;+新規&amp;rdquo; -&amp;gt; Web + モバイル -&amp;gt; Function App&lt;/li&gt;
&lt;li&gt;アプリ名は.azurewebsites.net空間でユニークになるように&lt;/li&gt;
&lt;li&gt;App Seriviceプランは、占有型の&amp;rdquo;クラシック&amp;rdquo;か、共有で実行したぶん課金の&amp;rdquo;動的&amp;rdquo;かを選べます。今回の使い方だと動的がお得でしょう&lt;/li&gt;
&lt;li&gt;メモリは128MBあれば十分です&lt;/li&gt;
&lt;li&gt;他のパラメータはお好みで&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;環境変数の設定

&lt;ul&gt;
&lt;li&gt;Function Appへポータルからアクセス -&amp;gt; Function Appの設定 -&amp;gt; アプリケーション設定の構成 -&amp;gt; アプリ設定&lt;/li&gt;
&lt;li&gt;先ほど控えた環境変数を設定します(CLIENT_ID、DOMAIN、APPLICATION_SECRET、AZURE_SUBSCRIPTION_ID、azfuncpoc_STORAGE)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;サンプルコードを取得

&lt;ul&gt;
&lt;li&gt;githubに置いてますので、作業するマシンにcloneしてください -&amp;gt; &lt;a href=&#34;https://github.com/ToruMakabe/AZFuncTimerTriggerSample&#34;&gt;AZFuncTimerTriggerSample&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;準備済みのGithubリポジトリにpush&lt;/li&gt;
&lt;li&gt;リポジトリとFunction Appを同期

&lt;ul&gt;
&lt;li&gt;Function Appへポータルからアクセス -&amp;gt; Function Appの設定 -&amp;gt; 継続的インテグレーションの構成 -&amp;gt; セットアップ&lt;/li&gt;
&lt;li&gt;Githubリポジトリとブランチを設定し、同期を待ちます&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Nodeのモジュールをインストール

&lt;ul&gt;
&lt;li&gt;&lt;del&gt;Function Appへポータルからアクセス -&amp;gt; Function Appの設定 -&amp;gt; kuduに移動 -&amp;gt; site/wwwroot/getUsageData へ移動&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;このディレクトリが、実行する関数、functionの単位です&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&amp;ldquo;npm install&amp;rdquo; を実行 (package.jsonの定義に従ってNodeのモジュールが”node_modules&amp;rdquo;へインストールされます)&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;deploy.cmd で自動的にインストールするよう変えました&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これで、指定ストレージアカウントの&amp;rdquo;usagedata&amp;rdquo;コンテナに日次で使用量データファイルができます。&lt;/p&gt;

&lt;h2 id=&#34;コード解説:13f4070f39b47880df2f217875deb9f9&#34;&gt;コード解説&lt;/h2&gt;

&lt;p&gt;3つのファイルをデプロイしました。簡単な順に、ざっと解説します。&lt;a href=&#34;https://github.com/ToruMakabe/AZFuncTimerTriggerSample&#34;&gt;コード&lt;/a&gt;を眺めながら読み進めてください。&lt;/p&gt;

&lt;h3 id=&#34;package-json:13f4070f39b47880df2f217875deb9f9&#34;&gt;package.json&lt;/h3&gt;

&lt;p&gt;主となるコードファイルは後述の&amp;rdquo;index.js&amp;rdquo;ですが、その動作に必要な環境を定義します。依存モジュールのバージョンの違いでトラブらないよう、dependenciesで指定するところがクライマックスです。&lt;/p&gt;

&lt;h3 id=&#34;function-json:13f4070f39b47880df2f217875deb9f9&#34;&gt;function.json&lt;/h3&gt;

&lt;p&gt;Azure Functionsの特徴である、TriggerとBindingsを定義します。サンプルはTimer Triggerなので、実行タイミングをここに書きます。&amp;rdquo;schedule&amp;rdquo;属性に、cron形式({秒}{分}{時}{日}{月}{曜日})で。&lt;/p&gt;

&lt;p&gt;&amp;ldquo;0 0 0 * * *&amp;rdquo; と指定しているので、毎日0時0分0秒に起動します。UTCです。&lt;/p&gt;

&lt;h3 id=&#34;index-js:13f4070f39b47880df2f217875deb9f9&#34;&gt;index.js&lt;/h3&gt;

&lt;p&gt;メインロジックです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;先ほど設定した環境変数は、&amp;rdquo;process.env.HOGE&amp;rdquo;を通じ実行時に読み込まれます。認証関連情報はハードコードせず、このやり口で。&lt;/li&gt;
&lt;li&gt;日付関連処理はUTCの明示を徹底しています。Azure Functions実行環境はUTCですが、ローカルでのテストなど他環境を考えると、指定できるところはしておくのがおすすめです。これはクラウドでグローバル展開する可能性があるコードすべてに言えます。&lt;/li&gt;
&lt;li&gt;0時に起動しますが、使用量データ作成遅延の可能性があるので、処理対象は2日前です。お好みで調整してください。詳細仕様は&lt;a href=&#34;https://msdn.microsoft.com/en-us/library/azure/mt219001.aspx&#34;&gt;こちら&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;module.export からが主フローです。asyncを使って、Blobコンテナの作成、使用量データ取得&amp;amp;ファイル書き込みを、順次処理しています。後ほど豆知識で補足します。&lt;/li&gt;
&lt;li&gt;最後にcontext.done()でFunctionsに対してアプリの終了を伝えます。黙って終わるような行儀の悪い子は嫌いです。&lt;/li&gt;
&lt;li&gt;ヘルパー関数たちは最後にまとめてあります。ポイントはcontinuationTokenを使ったループ処理です。

&lt;ul&gt;
&lt;li&gt;Resource Usage API は、レスポンスで返すデータが多い場合に、途中で切って「次はこのトークンで続きからアクセスしてちょ」という動きをします。&lt;/li&gt;
&lt;li&gt;ループが2周目に入った場合は、データを書きだすファイルが分かれます。フォーマットは&amp;rdquo;YYYY-MM-DD_n.json&amp;rdquo;です。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;豆知識-node-on-azure-functions:13f4070f39b47880df2f217875deb9f9&#34;&gt;豆知識 (Node on Azure Functions)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;通信やI/Oの関数など、非同期処理の拾い忘れ、突き抜けに注意してください

&lt;ul&gt;
&lt;li&gt;NodeはJavascript、シングルスレッドなので時間のかかる処理でブロックしないのが基本です&lt;/li&gt;
&lt;li&gt;Azure FunctionsはNode v6.4.0が使えるのでES6のpromiseが書けるのですが、SDKがまだpromiseを&lt;a href=&#34;https://github.com/Azure/azure-sdk-for-node/issues/1450&#34;&gt;サポートしていない&lt;/a&gt;ので、サポートされるまではcallbackで堅く書きましょう&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Nodeに限った話ではないですが、Azure Functions Timer TriggerはInput/Output Bindingと組み合わせられません

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/functions-reference/#-7&#34;&gt;サポートマトリックス&lt;/a&gt;を確認しましょう&lt;/li&gt;
&lt;li&gt;なのでサンプルではOutput Binding使わずに書きました&lt;/li&gt;
&lt;li&gt;Input/Outputを使える他のTriggerでは、楽なのでぜひ活用してください&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;豆知識-azure-usage-api:13f4070f39b47880df2f217875deb9f9&#34;&gt;豆知識 (Azure Usage API)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Resource Usage APIは使用量のためのAPIなので、料金に紐づけたい場合は、&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/billing-usage-rate-card-overview/&#34;&gt;Ratecard API&lt;/a&gt;を組み合わせてください&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;それでは、幸せな運用管理サーバレス生活を。&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OMSでLinuxコンテナのログを分析する</title>
      <link>http://torumakabe.github.io/post/oms_container_linux/</link>
      <pubDate>Thu, 25 Aug 2016 16:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/oms_container_linux/</guid>
      <description>

&lt;h2 id=&#34;oms-container-solution-for-linux-プレビュー開始:494184e69e067c0e711200d6bf38d283&#34;&gt;OMS Container Solution for Linux プレビュー開始&lt;/h2&gt;

&lt;p&gt;OMS Container Solution for Linuxのプレビューが&lt;a href=&#34;https://blogs.technet.microsoft.com/msoms/2016/08/24/announcing-public-preview-oms-container-solution-for-linux/&#34;&gt;はじまりました&lt;/a&gt;。OMSのログ分析機能は500MB/日のログ転送まで無料で使えるので、利用者も多いのではないでしょうか。&lt;/p&gt;

&lt;p&gt;さて、このたびプレビュー開始したLinuxコンテナのログ分析機能、サクッと使えるので紹介します。まだプレビューなので、仕様が変わったらごめんなさい。&lt;/p&gt;

&lt;h2 id=&#34;何ができるか-とその特徴:494184e69e067c0e711200d6bf38d283&#34;&gt;何ができるか、とその特徴&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Dockerコンテナに関わるログの収集と分析、ダッシュボード表示

&lt;ul&gt;
&lt;li&gt;収集データの詳細 - &lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/log-analytics-containers/#containers-data-collection-details&#34;&gt;Containers data collection details&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;導入が楽ちん

&lt;ol&gt;
&lt;li&gt;OMSエージェントコンテナを導入し、コンテナホスト上のすべてのコンテナのログ分析ができる&lt;/li&gt;
&lt;li&gt;コンテナホストに直接OMS Agentを導入することもできる&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1がコンテナ的でいいですよね。実現イメージはこんな感じです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://msdnshared.blob.core.windows.net/media/2016/08/3-OMS-082416.png&#34; alt=&#34;OMS Agent Installation Type&#34; title=&#34;from microsoft.com&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これであれば、CoreOSのような「コンテナホストはあれこれいじらない」というポリシーのディストリビューションにも対応できます。&lt;/p&gt;

&lt;p&gt;では試しに、1のやり口でUbuntuへ導入してみましょう。&lt;/p&gt;

&lt;h2 id=&#34;手順:494184e69e067c0e711200d6bf38d283&#34;&gt;手順&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;OMSのログ分析機能を有効化しワークスペースを作成、IDとKeyを入手 (&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/log-analytics-get-started/&#34;&gt;参考&lt;/a&gt;)

&lt;ul&gt;
&lt;li&gt;Azureのサブスクリプションを持っている場合、&amp;rdquo;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/log-analytics-get-started/#microsoft-azure&#34;&gt;Microsoft Azure を使用した迅速なサインアップ&lt;/a&gt;&amp;ldquo;から読むと、話が早いです&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OMSポータルのソリューションギャラリーから、&amp;rdquo;Containers&amp;rdquo;を追加&lt;/li&gt;
&lt;li&gt;UbuntuにDockerを導入

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/installation/linux/ubuntulinux/&#34;&gt;参考&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;現在、OMSエージェントが対応するDockerバージョンは 1.11.2までなので、たとえばUbuntu 16.04の場合は sudo apt-get install docker-engine=1.11.2-0~xenial とするなど、バージョン指定してください&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OMSエージェントコンテナを導入

&lt;ul&gt;
&lt;li&gt;先ほど入手したOMSのワークスペースIDとKeyを入れてください&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run --privileged -d -v /var/run/docker.sock:/var/run/docker.sock -e WSID=&amp;quot;your workspace id&amp;quot; -e KEY=&amp;quot;your key&amp;quot; -h=`hostname` -p 127.0.0.1:25224:25224/udp -p 127.0.0.1:25225:25225 --name=&amp;quot;omsagent&amp;quot; --log-driver=none --restart=always microsoft/oms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上。これでOMSポータルからログ分析ができます。こんな感じで。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://acom.azurecomcdn.net/80C57D/cdn/mediahandler/docarticles/dpsmedia-prod/azure.microsoft.com/en-us/documentation/articles/log-analytics-containers/20160824105310/containers-dash01.png&#34; alt=&#34;Dashboard1&#34; title=&#34;from microsoft.com&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://acom.azurecomcdn.net/80C57D/cdn/mediahandler/docarticles/dpsmedia-prod/azure.microsoft.com/en-us/documentation/articles/log-analytics-containers/20160824105310/containers-dash02.png&#34; alt=&#34;Dashboard2&#34; title=&#34;from microsoft.com&#34; /&gt;&lt;/p&gt;

&lt;p&gt;なんと簡単じゃありませんか。詳細が気になるかたは、&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/log-analytics-containers/&#34;&gt;こちら&lt;/a&gt;から。&lt;/p&gt;

&lt;p&gt;なお、フィードバック&lt;a href=&#34;https://blogs.technet.microsoft.com/msoms/2016/08/24/announcing-public-preview-oms-container-solution-for-linux/&#34;&gt;熱烈歓迎&lt;/a&gt;だそうです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker for WindowsでインストールレスAzure CLI環境を作る</title>
      <link>http://torumakabe.github.io/post/dockerforwin_azurecli/</link>
      <pubDate>Wed, 22 Jun 2016 15:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/dockerforwin_azurecli/</guid>
      <description>

&lt;h2 id=&#34;舌の根の乾かぬ内に:07c5653d87682735481a0855219b8241&#34;&gt;舌の根の乾かぬ内に&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://torumakabe.github.io/post/azure_osstools_iac/&#34;&gt;最近&lt;/a&gt;、VagrantとVirualBoxで似たようなやり口を紹介しましたが、気にしないでください。テクノロジーの進化は早い。&lt;/p&gt;

&lt;h2 id=&#34;動機:07c5653d87682735481a0855219b8241&#34;&gt;動機&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Docker for Windows(on Client Hyper-V)のベータが一般開放された&lt;/li&gt;
&lt;li&gt;Dockerもそうだが、Hyper-V前提のツールが今後増えそう、となると、それとぶつかるVirtualBoxをぼちぼちやめたい&lt;/li&gt;
&lt;li&gt;月一ペースでアップデートされるAzure CLIをいちいちインストールしたくない、コンテナ引っ張って以上、にしたい&lt;/li&gt;
&lt;li&gt;開発端末の環境を汚したくない、いつでもきれいに作り直せるようにしたい&lt;/li&gt;
&lt;li&gt;○○レスって言ってみたかった&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;やり口:07c5653d87682735481a0855219b8241&#34;&gt;やり口&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;もちろんDocker for Windows (on Client Hyper-V) を使う&lt;/li&gt;
&lt;li&gt;いちいちdocker run&amp;hellip;と打たなくていいよう、エイリアス的にPowerShellのfunction &amp;ldquo;azure_cli&amp;rdquo; を作る&lt;/li&gt;
&lt;li&gt;&amp;ldquo;azure_cli&amp;rdquo;入力にてAzure CLIコンテナを起動&lt;/li&gt;
&lt;li&gt;コンテナとホスト(Windows)間でファイル共有、ホスト側のIDEなりエディタを使えるようにする&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;作業の中身:07c5653d87682735481a0855219b8241&#34;&gt;作業の中身&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Docker for Windowsを&lt;a href=&#34;https://docs.docker.com/docker-for-windows/&#34;&gt;インストール&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;64bit Windows 10 Pro/Enterprise/Education 1511以降に対応&lt;/li&gt;
&lt;li&gt;Hyper-Vの有効化を忘れずに&lt;/li&gt;
&lt;li&gt;Hyper-VとぶつかるVirtualBoxとはお別れです&lt;/li&gt;
&lt;li&gt;Docker for Windowsの起動時にIPをとれないケースがありますが、その場合はsettings -&amp;gt; Network から、設定変えずにApplyしてみてください。いまのところこれで対処できています。この辺はベータなので今後の調整を期待しましょう。&lt;/li&gt;
&lt;li&gt;共有ドライブも共有が外れていることが。settings -&amp;gt; Shared Drives で共有しなおしてください。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;PowerShell functionを作成

&lt;ul&gt;
&lt;li&gt;のちほど詳しく&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;powershellのfunctionを作る:07c5653d87682735481a0855219b8241&#34;&gt;PowerShellのfunctionを作る&lt;/h2&gt;

&lt;p&gt;ここが作業のハイライト。&lt;/p&gt;

&lt;p&gt;PowerShellのプロファイルを編集します。ところでエディタはなんでもいいのですが、AzureやDockerをがっつり触る人にはVS Codeがおすすめです。&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=msazurermtools.azurerm-vscode-tools&#34;&gt;Azure Resource Manager Template&lt;/a&gt;や&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=PeterJausovec.vscode-docker&#34;&gt;Docker&lt;/a&gt;むけextensionがあります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace\dockereval\arm&amp;gt; code $profile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;こんなfunctionを作ります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function azure_cli {
   C:\PROGRA~1\Docker\Docker\Resources\bin\docker.exe run -it --rm -v ${HOME}/.azure:/root/.azure -v ${PWD}:/data -w /data microsoft/azure-cli:latest
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;エイリアスでなくfunctionにした理由は、引数です。エイリアスだと引数を渡せないので&lt;/li&gt;
&lt;li&gt;コンテナが溜まるのがいやなので、&amp;ndash;rmで都度消します&lt;/li&gt;
&lt;li&gt;毎度 azure login しなくていいよう、トークンが保管されるコンテナの/root/azureディレクトリをホストの${HOME}/.azureと-v オプションで共有します&lt;/li&gt;
&lt;li&gt;ARM TemplateのJSONファイルなど、ホストからファイルを渡したいため、カレントディレクトリ ${PWD} をコンテナと -v オプションで共有します&lt;/li&gt;
&lt;li&gt;コンテナはdocker hubのMicrosoft公式イメージ、latestを引っ張ります。latestで不具合あればバージョン指定してください&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ではテスト。まずはホスト側のファイルを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace\dockereval\arm&amp;gt; ls


    ディレクトリ: C:\Workspace\dockereval\arm


Mode                LastWriteTime         Length Name
----                -------------         ------ ----
d-----       2016/06/22     11:21                subd
-a----       2016/06/22     10:26           8783 azuredeploy.json
-a----       2016/06/22     11:28            690 azuredeploy.parameters.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;いくつかのファイルとサブディレクトリがあります。&lt;/p&gt;

&lt;p&gt;コンテナを起動してみましょう。azure_cli functionを呼びます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace\dockereval\arm&amp;gt; azure_cli
root@be41d3389a21:/data#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コンテナを起動し、入出力をつなぎました。ここからは頭と手をLinuxに切り替えてください。公式Azure CLIコンテナは&lt;a href=&#34;https://hub.docker.com/r/microsoft/azure-cli/~/dockerfile/&#34;&gt;debianベース&lt;/a&gt;です。&lt;/p&gt;

&lt;p&gt;ファイル共有できているか確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@be41d3389a21:/data# ls
azuredeploy.json  azuredeploy.parameters.json  subd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できてますね。&lt;/p&gt;

&lt;p&gt;azureコマンドが打てるか確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@be41d3389a21:/data# azure -v
0.10.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;しあわせ。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure X-Plat CLIでResource Policyを設定する</title>
      <link>http://torumakabe.github.io/post/azure_cli_resourcepolicy/</link>
      <pubDate>Sat, 21 May 2016 11:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_cli_resourcepolicy/</guid>
      <description>

&lt;h2 id=&#34;azure-x-plat-cliのリリースサイクル:6386657500959cd2c6c4ed079ad7f062&#34;&gt;Azure X-Plat CLIのリリースサイクル&lt;/h2&gt;

&lt;p&gt;OSS/Mac/Linux派なAzurerの懐刀、Azure X-Plat CLIのリリースサイクルは、おおよそ&lt;a href=&#34;https://github.com/Azure/azure-xplat-cli/releases&#34;&gt;月次&lt;/a&gt;です。改善と機能追加を定期的にまわしていくことには意味があるのですが、いっぽう、Azureの機能追加へタイムリーに追随できないことがあります。短期間とはいえ、次のリリースまで空白期間ができてしまうのです。&lt;/p&gt;

&lt;p&gt;たとえば、今回のテーマであるResource Policy。GA直後に公開された&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-manager-policy/&#34;&gt;ドキュメント&lt;/a&gt;に、X-Plat CLIでの使い方が2016/5/21現在書かれていません。おやCLIではできないのかい、と思ってしまいますね。でもその後のアップデートで、できるようになりました。&lt;/p&gt;

&lt;p&gt;機能リリース時点ではCLIでできなかった、でもCLIの月次アップデートで追加された、いまはできる、ドキュメントの更新待ち。こんなパターンは多いので、あきらめずに探ってみてください。&lt;/p&gt;

&lt;h2 id=&#34;ポリシーによるアクセス管理:6386657500959cd2c6c4ed079ad7f062&#34;&gt;ポリシーによるアクセス管理&lt;/h2&gt;

&lt;p&gt;さて本題。リソースの特性に合わせて、きめ細かいアクセス管理をしたいことがあります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VMやストレージのリソースタグに組織コードを入れること強制し、費用負担の計算に使いたい&lt;/li&gt;
&lt;li&gt;日本国外リージョンのデータセンタを使えないようにしたい&lt;/li&gt;
&lt;li&gt;Linuxのディストリビューションを標準化し、その他のディストリビューションは使えなくしたい&lt;/li&gt;
&lt;li&gt;開発環境リソースグループでは、大きなサイズのインスタンスを使えないようにしたい&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;などなど。こういう課題にポリシーが効きます。&lt;/p&gt;

&lt;p&gt;従来からあるRBACは「役割と人」目線です。「この役割を持つ人は、このリソースを読み取り/書き込み/アクションできる」という表現をします。&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/role-based-access-built-in-roles/&#34;&gt;組み込みロールの一覧&lt;/a&gt;を眺めると、理解しやすいでしょう。&lt;/p&gt;

&lt;p&gt;ですが、RBACは役割と人を切り口にしているので、各リソースの多様な特性にあわせた統一表現が難しいです。たとえばストレージにはディストリビューションという属性はありません。無理してカスタム属性なんかで表現すると破綻しそうです。&lt;/p&gt;

&lt;p&gt;リソース目線でのアクセス管理もあったほうがいい、ということで、ポリシーの出番です。もちろんRBACと、組み合わせできます。&lt;/p&gt;

&lt;h2 id=&#34;x-plat-cliでの定義方法:6386657500959cd2c6c4ed079ad7f062&#34;&gt;X-Plat CLIでの定義方法&lt;/h2&gt;

&lt;p&gt;2016/4リリースの&lt;a href=&#34;https://github.com/Azure/azure-xplat-cli/releases/tag/v0.9.20-April2016&#34;&gt;v0.9.20&lt;/a&gt;から、X-Plat CLIでもResource Policyを定義できます。&lt;/p&gt;

&lt;p&gt;ポリシーの定義、構文はPowerShellと同じなので、公式ドキュメントに任せます。ご一読を。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-manager-policy/&#34;&gt;ポリシーを使用したリソース管理とアクセス制御&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;X-Plat CLI固有部分に絞って紹介します。&lt;/p&gt;

&lt;h3 id=&#34;ポリシー定義ファイルを作る:6386657500959cd2c6c4ed079ad7f062&#34;&gt;ポリシー定義ファイルを作る&lt;/h3&gt;

&lt;p&gt;CLIでインラインに書けるようですが、人類には早すぎる気がします。ここではファイルに。&lt;/p&gt;

&lt;p&gt;例として、作成できるVMのサイズを限定してみましょう。開発環境などでよくあるパターンと思います。VM作成時、Standard_D1～5_v2に当てはまらないVMサイズが指定されると、拒否します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;if&amp;quot;: {
    &amp;quot;allOf&amp;quot;: [
      {
        &amp;quot;field&amp;quot;: &amp;quot;type&amp;quot;,
        &amp;quot;equals&amp;quot;: &amp;quot;Microsoft.Compute/virtualMachines&amp;quot;
      },
      {
        &amp;quot;not&amp;quot;: {
          &amp;quot;field&amp;quot;: &amp;quot;Microsoft.Compute/virtualMachines/sku.name&amp;quot;,
          &amp;quot;in&amp;quot;: [ &amp;quot;Standard_D1_v2&amp;quot;, &amp;quot;Standard_D2_v2&amp;quot;,&amp;quot;Standard_D3_v2&amp;quot;, &amp;quot;Standard_D4_v2&amp;quot;, &amp;quot;Standard_D5_v2&amp;quot; ]
        }
      }
    ]
  },
  &amp;quot;then&amp;quot;: {
    &amp;quot;effect&amp;quot;: &amp;quot;deny&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;policy_deny_vmsize.json というファイル名にしました。では投入。ポリシー名は deny_vmsize とします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ azure policy definition create -n deny_vmsize -p ./policy_deny_vmsize.json
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;info:    Executing command policy definition create
+ Creating policy definition deny_vmsize
data:    PolicyName:             deny_vmsize
data:    PolicyDefinitionId:     /subscriptions/mysubscription/providers/Microsoft.Authorization/policyDefinitions/deny_vmsize
data:    PolicyType:             Custom
data:    DisplayName:
data:    Description:
data:    PolicyRule:             allOf=[field=type, equals=Microsoft.Compute/virtualMachines, field=Microsoft.Compute/virtualMachines/sku.name, in=[Standard_D1_v2, Standard_D2_v2, Standard_D3_v2, Standard_D4_v2, Standard_D5_v2]], effect=deny
info:    policy definition create command OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できたみたいです。&lt;/p&gt;

&lt;h3 id=&#34;ポリシーをアサインする:6386657500959cd2c6c4ed079ad7f062&#34;&gt;ポリシーをアサインする&lt;/h3&gt;

&lt;p&gt;では、このポリシーを割り当てます。割り当ての範囲(スコープ)はサブスクリプションとします。リソースグループなど、より細かいスコープも&lt;a href=&#34;https://msdn.microsoft.com/ja-jp/library/azure/mt588464.aspx&#34;&gt;指定可能&lt;/a&gt;です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ azure policy assignment create -n deny_vmsize_assignment -p /subscriptions/mysubscription/providers/Microsoft.Authorization/policyDefinitions/deny_vmsize -s /subscriptions/mysubscription
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;info:    Executing command policy assignment create
+ Creating policy assignment deny_vmsize_assignment
data:    PolicyAssignmentName:     deny_vmsize_assignment
data:    Type:                     Microsoft.Authorization/policyAssignments
data:    DisplayName:
data:    PolicyDefinitionId:       /subscriptions/mysubscription/providers/Microsoft.Authorization/policyDefinitions/deny_vmsize
data:    Scope:                    /subscriptions/mysubscription
info:    policy assignment create command OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;割り当て完了。では試しに、このサブスクリプションに属するユーザで、Gシリーズのゴジラ級インスタンスを所望してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ azure vm quick-create -g RPPoC -n rppocvm westus -y Linux -Q &amp;quot;canonical:ubuntuserver:14.04.4-LTS:latest&amp;quot; -u &amp;quot;adminname&amp;quot; -p &amp;quot;adminpass&amp;quot; -z Standard_G5
info:    Executing command vm quick-create
[...snip]
+ Creating VM &amp;quot;rppocvm&amp;quot;
error:   The resource action &#39;Microsoft.Compute/virtualMachines/write&#39; is disallowed by one or more policies. Policy identifier(s): &#39;/subscriptions/mysubscription/providers/Microsoft.Authorization/policyDefinitions/deny_vmsize&#39;.
info:    Error information has been recorded to /root/.azure/azure.err
error:   vm quick-create command failed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;拒否られました。&lt;/p&gt;

&lt;p&gt;許可されているVMサイズだと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ azure vm quick-create -g RPPoC -n rppocvm westus -y Linux -Q &amp;quot;canonical:ubuntuserver:14.04.4-LTS:latest&amp;quot; -u &amp;quot;adminname&amp;quot; -p &amp;quot;adminpass&amp;quot; -z Standard_D1_v2
info:    Executing command vm quick-create
[...snip]
info:    vm quick-create command OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;成功。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VagrantとDockerによるAzure向けOSS開発・管理端末のコード化</title>
      <link>http://torumakabe.github.io/post/azure_osstools_iac/</link>
      <pubDate>Fri, 13 May 2016 18:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_osstools_iac/</guid>
      <description>

&lt;h2 id=&#34;端末だってコード化されたい:4b51bf5da7c597406600f164b7d91579&#34;&gt;端末だってコード化されたい&lt;/h2&gt;

&lt;p&gt;Infrastructure as Codeは特に騒ぐ話でもなくなってきました。このエントリは、じゃあ端末の開発環境やツール群もコード化しようという話です。結論から書くと、VagrantとDockerを活かします。超絶便利なのにAzure界隈ではあまり使われてない印象。もっと使われていいのではと思い、書いております。&lt;/p&gt;

&lt;h2 id=&#34;解決したい課題:4b51bf5da7c597406600f164b7d91579&#34;&gt;解決したい課題&lt;/h2&gt;

&lt;p&gt;こんな悩みを解決します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;WindowsでOSS開発環境、Azure管理ツールのセットアップをするのがめんどくさい&lt;/li&gt;
&lt;li&gt;WindowsもMacも使っているので、どちらでも同じ環境を作りたい&lt;/li&gt;
&lt;li&gt;サーバはLinuxなので手元にもLinux環境欲しいけど、Linuxデスクトップはノーサンキュー&lt;/li&gt;
&lt;li&gt;2016年にもなって長いコードをVimとかEmacsで書きたくない&lt;/li&gt;
&lt;li&gt;Hyper-VとかVirtualboxで仮想マシンのセットアップと起動、後片付けをGUIでするのがいちいちめんどくさい&lt;/li&gt;
&lt;li&gt;仮想マシン起動したあとにターミナル起動-&amp;gt;IP指定-&amp;gt;ID/Passでログインとか、かったるい&lt;/li&gt;
&lt;li&gt;Azure CLIやTerraformなどクラウド管理ツールの進化が頻繁でつらい(月一回アップデートとか)&lt;/li&gt;
&lt;li&gt;でもアップデートのたびに超絶便利機能が追加されたりするので、なるべく追いかけたい&lt;/li&gt;
&lt;li&gt;新メンバーがチームに入るたび、セットアップが大変&lt;/li&gt;
&lt;li&gt;不思議とパソコンが生えてくる部屋に住んでおり、セットアップが大変&lt;/li&gt;
&lt;li&gt;毎度作業のどこかが抜ける、漏れる、間違う 人間だもの&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;やり口:4b51bf5da7c597406600f164b7d91579&#34;&gt;やり口&lt;/h2&gt;

&lt;p&gt;VagrantとDockerで解決します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Windows/Macどちらにも対応しているVirtualboxでLinux仮想マシンを作る&lt;/li&gt;
&lt;li&gt;Vagrantでセットアップを自動化する&lt;/li&gt;
&lt;li&gt;Vagrantfile(RubyベースのDSL)でシンプルに環境をコード化する&lt;/li&gt;
&lt;li&gt;Vagrant Puttyプラグインを使って、Windowsでもsshログインを簡素化する&lt;/li&gt;
&lt;li&gt;公式dockerイメージがあるツールは、インストールせずコンテナを引っ張る&lt;/li&gt;
&lt;li&gt;Windows/MacのいまどきなIDEなりエディタを使えるようにする&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;セットアップ概要:4b51bf5da7c597406600f164b7d91579&#34;&gt;セットアップ概要&lt;/h2&gt;

&lt;p&gt;簡単す。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Virtualboxを&lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;インストール&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vagrantを&lt;a href=&#34;https://www.vagrantup.com/downloads.html&#34;&gt;インストール&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vagrant Putty Plugin(vagrant-multi-putty)を&lt;a href=&#34;https://github.com/nickryand/vagrant-multi-putty&#34;&gt;インストール&lt;/a&gt; #Windowsのみ。Puttyは別途入れてください&lt;/li&gt;
&lt;li&gt;作業フォルダを作り、Vagrant ファイルを書く&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;もしWindowsでうまく動かない時は、Hyper-Vが有効になっていないか確認しましょう。Virtualboxと共存できません。&lt;/p&gt;

&lt;h2 id=&#34;サンプル解説:4b51bf5da7c597406600f164b7d91579&#34;&gt;サンプル解説&lt;/h2&gt;

&lt;p&gt;OSSなAzurerである、わたしのVagrantfileです。日々環境に合わせて変えてますが、以下は現時点でのスナップショット。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# -*- mode: ruby -*-
# vi: set ft=ruby :

# Vagrantfile API/syntax version. Don&#39;t touch unless you know what you&#39;re doing!
VAGRANTFILE_API_VERSION = &amp;quot;2&amp;quot;

$bootstrap=&amp;lt;&amp;lt;SCRIPT

#Common tools
sudo apt-get update
sudo apt-get -y install wget unzip jq

#Docker Engine
sudo apt-get -y install apt-transport-https ca-certificates
sudo apt-get -y install linux-image-extra-$(uname -r)
sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D
sudo sh -c &amp;quot;echo deb https://apt.dockerproject.org/repo ubuntu-trusty main &amp;gt; /etc/apt/sources.list.d/docker.list&amp;quot;
sudo apt-get update
sudo apt-get -y purge lxc-docker
sudo apt-cache policy docker-engine
sudo apt-get -y install docker-engine=1.11.1-0~trusty
sudo gpasswd -a vagrant docker
sudo service docker restart

#Docker Machine
sudo sh -c &amp;quot;curl -L https://github.com/docker/machine/releases/download/v0.7.0/docker-machine-`uname -s`-`uname -m` &amp;gt;/usr/local/bin/docker-machine &amp;amp;&amp;amp; chmod +x /usr/local/bin/docker-machine&amp;quot;

#Azure CLI
echo &amp;quot;alias azure=&#39;docker run -it --rm -v \\\$HOME/.azure:/root/.azure -v \\\$PWD:/data -w /data microsoft/azure-cli:latest azure&#39;&amp;quot; &amp;gt;&amp;gt; $HOME/.bashrc

#Terraform
echo &amp;quot;alias terraform=&#39;docker run -it --rm -v \\\$PWD:/data -w /data hashicorp/terraform:0.6.14&#39;&amp;quot; &amp;gt;&amp;gt; $HOME/.bashrc

#Packer
echo &amp;quot;alias packer=&#39;docker run -it --rm -v \\\$PWD:/data -w /data hashicorp/packer:latest&#39;&amp;quot; &amp;gt;&amp;gt; $HOME/.bashrc

#nodebrew
curl -L git.io/nodebrew | perl - setup
echo &#39;export PATH=$HOME/.nodebrew/current/bin:$PATH&#39; &amp;gt;&amp;gt; $HOME/.bashrc
$HOME/.nodebrew/current/bin/nodebrew install-binary 5.9.1
$HOME/.nodebrew/current/bin/nodebrew use 5.9.1

#Python3
wget -qO- https://bootstrap.pypa.io/get-pip.py | sudo -H python3.4

SCRIPT

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  # Every Vagrant virtual environment requires a box to build off of.

  config.vm.box = &amp;quot;ubuntu/trusty64&amp;quot;

  # Create a private network, which allows host-only access to the machine
  # using a specific IP.

  config.vm.network &amp;quot;private_network&amp;quot;, ip: &amp;quot;192.168.33.10&amp;quot;

  config.vm.provider &amp;quot;virtualbox&amp;quot; do |vb|
     vb.customize [&amp;quot;modifyvm&amp;quot;, :id, &amp;quot;--memory&amp;quot;, &amp;quot;2048&amp;quot;]
  end

  config.vm.provision :shell, inline: $bootstrap, privileged: false

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$bootstrap=&amp;lt;&amp;lt;SCRIPT から SCRIPT が、プロビジョニングシェルです。初回のvagrant up時とvagrant provision時に実行されます。&lt;/p&gt;

&lt;h3 id=&#34;common-tools:4b51bf5da7c597406600f164b7d91579&#34;&gt;Common tools&lt;/h3&gt;

&lt;p&gt;一般的なツールをaptでインストールします。wgetとかjqとか。&lt;/p&gt;

&lt;h3 id=&#34;docker-engine-machine:4b51bf5da7c597406600f164b7d91579&#34;&gt;Docker Engine &amp;amp; Machine&lt;/h3&gt;

&lt;p&gt;この後前提となるDockerをインストール。Dockerのバージョンは1.11.1を明示しています。Dockerは他への影響が大きいので、バージョンアップは慎重めの方針です。&lt;/p&gt;

&lt;h3 id=&#34;azure-cli:4b51bf5da7c597406600f164b7d91579&#34;&gt;Azure CLI&lt;/h3&gt;

&lt;p&gt;インストールせずに&lt;a href=&#34;https://hub.docker.com/r/microsoft/azure-cli/&#34;&gt;MS公式のDockerイメージ&lt;/a&gt;を引っ張ります。なのでalias設定だけ。
-v オプションで、ホストLinuxとコンテナ間でデータを共有します。CLIが使う認証トークン($HOME/.azure下)やCLI実行時に渡すjsonファイル(作業ディレクトリ)など。詳細は後ほど。
また、azureコマンド発行ごとにコンテナが溜まっていくのがつらいので、&amp;ndash;rmで消します。&lt;/p&gt;

&lt;h3 id=&#34;terraform-packer:4b51bf5da7c597406600f164b7d91579&#34;&gt;Terraform &amp;amp; Packer&lt;/h3&gt;

&lt;p&gt;Azure CLIと同様です。Hashicorpが&lt;a href=&#34;https://hub.docker.com/u/hashicorp/&#34;&gt;公式イメージ&lt;/a&gt;を提供しているので、それを活用します。
方針はlatest追いですが、不具合があればバージョンを指定します。たとえば、現状Terraformのlatestイメージに不具合があるので、0.6.14を指定しています。
-v オプションもAzure CLIと同じ。ホストとコンテナ間のファイルマッピングに使います。&lt;/p&gt;

&lt;p&gt;なお、公式とはいえ他人のイメージを使う時には、Dockerfileの作りやビルド状況は確認しましょう。危険がデンジャラスですし、ENTRYPOINTとか知らずにうっかり使うと途方に暮れます。&lt;/p&gt;

&lt;h3 id=&#34;nodebrew:4b51bf5da7c597406600f164b7d91579&#34;&gt;nodebrew&lt;/h3&gt;

&lt;p&gt;nodeのバージョンを使い分けるため。セットアップ時にv5.9.1を入れています。Azure Functions開発向け。&lt;/p&gt;

&lt;h3 id=&#34;python3:4b51bf5da7c597406600f164b7d91579&#34;&gt;Python3&lt;/h3&gt;

&lt;p&gt;Ubuntu 14.04では標準がPython2なので別途入れてます。Azure Batch向け開発でPython3使いたいので。&lt;/p&gt;

&lt;p&gt;みなさん他にもいろいろあるでしょう。シェルなのでお好みで。&lt;/p&gt;

&lt;p&gt;さて、ここまでがプロビジョニング時の処理です。以降の&amp;rdquo;Vagrant.configure～&amp;rdquo;は仮想マシンの定義で、難しくありません。ubuntu/trusty64(14.04)をboxイメージとし、IPやメモリを指定し、先ほど定義したプロビジョニング処理を指しているだけです。&lt;/p&gt;

&lt;h2 id=&#34;どれだけ楽か:4b51bf5da7c597406600f164b7d91579&#34;&gt;どれだけ楽か&lt;/h2&gt;

&lt;p&gt;では、環境を作ってみましょう。Vagrantfileがあるフォルダで&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vagrant up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;仮想マシンが作成されます。初回はプロビジョニング処理も走ります。&lt;/p&gt;

&lt;p&gt;できましたか。できたら、&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vagrant putty
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;はい。Puttyが起動し、ID/Passを入れなくてもsshログインします。破壊力抜群。わたしはこの魅力だけでTeraterm(Terraformではない)からPuttyに乗り換えました。ちなみにMacでは、vagrant sshで済みます。&lt;/p&gt;

&lt;p&gt;あとはプロビジョニングされたLinuxを使って楽しんでください。そして、必要なくなったら or 作り直したくなったら&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vagrant destroy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;綺麗さっぱりです。仮想マシンごと消します。消さずにまた使う時は、vagrant haltを。&lt;/p&gt;

&lt;p&gt;なお、vagrant upしたフォルダにあるファイルは、Virtualboxの共有フォルダ機能で仮想マシンと共有されます。shareとかいう名のフォルダを作って、必要なファイルを放り込んでおきましょう。その場合、仮想マシンのUbuntuからは/vagrant/shareと見えます。双方向で同期されます。&lt;/p&gt;

&lt;p&gt;わたしは長いコードを書くときは、Windows/Mac側のIDEなりエディタを使って、実行は仮想マシンのLinux側、という流れで作業しています。&lt;/p&gt;

&lt;p&gt;ちなみに、改行コードの違いやパーミッションには気を付けてください。改行コードはLFにする癖をつけておくと幸せになれます。パーミッションは全開、かつ共有領域では変えられないので、問題になるときは仮想マシン側で/vagrant外にコピーして使ってください。パーミッション全開だと怒られる認証鍵など置かないよう、注意。&lt;/p&gt;

&lt;p&gt;また、Dockerコンテナを引っ張るAzure CLI、Terraform、Packerの注意点。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;初回実行時にイメージのPullを行うので、帯域の十分なところでやりましょう&lt;/li&gt;
&lt;li&gt;サンプルでは -v $PWD:/data オプションにて、ホストのカレントディレクトリをコンテナの/dataにひもづけています。そして、-w /data にて、コンテナ内ワーキングディレクトリを指定しています。コマンドの引数でファイル名を指定したい場合は、実行したいファイルがあるディレクトリに移動して実行してください

&lt;ul&gt;
&lt;li&gt;(例) azure group deployment create RG01 DEP01 -f ./azuredeploy.json -e ./azuredeploy.parameters.json&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;bash-on-windowsまで待つとか言わない:4b51bf5da7c597406600f164b7d91579&#34;&gt;Bash on Windowsまで待つとか言わない&lt;/h2&gt;

&lt;p&gt;「WindowsではOSSの開発や管理がしにくい。Bash on Windowsが出てくるまで待ち」という人は、待たないで今すぐGoです。思い立ったが吉日です。繰り返しますがVagrantとDocker、超絶便利です。&lt;/p&gt;

&lt;p&gt;インフラのコード化なんか信用ならん！という人も、まず今回紹介したように端末からはじめてみたらいかがでしょう。激しく生産性上がると思います。&lt;/p&gt;

&lt;p&gt;夏近し、楽して早く帰ってビール呑みましょう。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure FunctionsとFacebook Messenger APIで好みなんて聞いてないBotを作る</title>
      <link>http://torumakabe.github.io/post/azure_functions_fbmsgapi/</link>
      <pubDate>Sun, 08 May 2016 14:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_functions_fbmsgapi/</guid>
      <description>

&lt;h2 id=&#34;まだ好みなんて聞いてないぜ:99ec2e7c4c63926799149ef94c45b73e&#34;&gt;まだ好みなんて聞いてないぜ&lt;/h2&gt;

&lt;p&gt;Build 2016で、&lt;a href=&#34;https://azure.microsoft.com/ja-jp/services/functions/&#34;&gt;Azure Functions&lt;/a&gt;が発表されました。&lt;/p&gt;

&lt;p&gt;Azure Functionsは、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;アプリを放り込めば動く。サーバの管理が要らない。サーバレス。  #でもこれは従来のPaaSもそう&lt;/li&gt;
&lt;li&gt;利用メモリ単位での、粒度の細かい課金。  #現在プレビュー中にて、詳細は今後発表&lt;/li&gt;
&lt;li&gt;Azure内外機能との、容易なイベント連動。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;が特徴です。AWSのLambdaと似てるっちゃ似ています。&lt;/p&gt;

&lt;p&gt;何が新しいかというと、特に3つ目の特徴、イベント連動です。触ってみなければわからん、ということで、流行りのBotでも作ってみたいと思います。&lt;/p&gt;

&lt;h3 id=&#34;基本方針:99ec2e7c4c63926799149ef94c45b73e&#34;&gt;基本方針&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;FunctionsはAzure内の様々な機能と&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/functions-reference/#bindings&#34;&gt;イベント連動&lt;/a&gt;できるが、あえてサンプルの少ないAzure外とつないでみる&lt;/li&gt;
&lt;li&gt;Facebook Messenger APIを使って、webhook連動する&lt;/li&gt;
&lt;li&gt;Facebook Messenger向けに書き込みがあると、ランダムでビールの種類と参考URLを返す&lt;/li&gt;
&lt;li&gt;ビールは&lt;a href=&#34;http://beertaster.org/beerstyle/web/beerstyle_main_j.html&#34;&gt;Craft Beer Association&lt;/a&gt;の分類に従い、協会のビアスタイル・ガイドライン参考ページの該当URLを返す&lt;/li&gt;
&lt;li&gt;Botらしく、それらしい文末表現をランダムで返す&lt;/li&gt;
&lt;li&gt;好みとか文脈は全く聞かないぜSorry&lt;/li&gt;
&lt;li&gt;アプリはNodeで書く。C#のサンプルは増えてきたので&lt;/li&gt;
&lt;li&gt;静的データをランダムに返す、かつ少量なのでメモリ上に広げてもいいが、せっかくなのでNodeと相性のいいDocumentDBを使う&lt;/li&gt;
&lt;li&gt;DocumentDBではSQLでいうORDER BY RAND()のようなランダムな問い合わせを書けないため、ストアドプロシージャで実装する  #&lt;a href=&#34;https://gist.github.com/murdockcrc/12266f9d844be416a6a0&#34;&gt;サンプル&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;FunctionsとGithubを連携し、GithubへのPush -&amp;gt; Functionsへのデプロイというフローを作る&lt;/li&gt;
&lt;li&gt;拡張性はひとまず目をつぶる  #&lt;a href=&#34;http://qiita.com/yoichiro@github/items/6d4c7309210af20a5c8f&#34;&gt;この辺の話&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ひとまずFunctionsとBotの枠組みの理解をゴールとします。ロジックをたくさん書けばそれなりに文脈を意識した返事はできるのですが、書かずに済む仕組みがこれからいろいろ出てきそうなので、書いたら負けの精神でぐっと堪えます。&lt;/p&gt;

&lt;h2 id=&#34;必要な作業:99ec2e7c4c63926799149ef94c45b73e&#34;&gt;必要な作業&lt;/h2&gt;

&lt;p&gt;以下が必要な作業の流れです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Azureで

&lt;ul&gt;
&lt;li&gt;Function Appの作成  #1&lt;/li&gt;
&lt;li&gt;Bot用Functionの作成 #2&lt;/li&gt;
&lt;li&gt;Facebook Messenger APIとの接続検証  #6&lt;/li&gt;
&lt;li&gt;Facebook Messenger API接続用Tokenの設定  #8&lt;/li&gt;
&lt;li&gt;DocumentDBのデータベース、コレクション作成、ドキュメント投入  #9&lt;/li&gt;
&lt;li&gt;DocumentDBのストアドプロシージャ作成  #10&lt;/li&gt;
&lt;li&gt;Function Appを書く  #11&lt;/li&gt;
&lt;li&gt;FunctionsのサイトにDocumentDB Node SDKを導入 #12&lt;/li&gt;
&lt;li&gt;Function AppのGithub連携設定  #13&lt;/li&gt;
&lt;li&gt;Function Appのデプロイ (GithubへのPush)  #14&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Facebookで

&lt;ul&gt;
&lt;li&gt;Facebook for Developersへの登録  #3&lt;/li&gt;
&lt;li&gt;Botをひも付けるFacebook Pageの作成  #4&lt;/li&gt;
&lt;li&gt;Bot用マイアプリの作成  #5&lt;/li&gt;
&lt;li&gt;Azure Functionsからのcallback URLを登録、接続検証  #6&lt;/li&gt;
&lt;li&gt;Azure Functions向けTokenを生成 #7&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;アプリのコード書きの他はそれほど重くない作業ですが、すべての手順を書くと本ができそうです。Function Appの作りにポイントを絞りたいので、以下、参考になるサイトをご紹介します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Function Appを書くまで、#1〜2、#5〜8は、&lt;a href=&#34;http://oauth.jp/blog/2016/04/19/fb-message-callback-with-azure-function/&#34;&gt;こちらのブログエントリ&lt;/a&gt;がとても参考になります。&lt;/li&gt;
&lt;li&gt;Facebook for Developersへの登録、#3は、&lt;a href=&#34;https://developers.facebook.com/&#34;&gt;https://developers.facebook.com/&lt;/a&gt; から。いきなり迷子の人は、&lt;a href=&#34;http://qiita.com/k_kuni/items/3d7176ee4e3009b45dd8&#34;&gt;こちら&lt;/a&gt;も参考に。&lt;/li&gt;
&lt;li&gt;Facebook Pageの作成は、&lt;a href=&#34;http://allabout.co.jp/gm/gc/387840/&#34;&gt;ここ&lt;/a&gt;を。Botで楽しむだけなら細かい設定は後回しでいいです。&lt;/li&gt;
&lt;li&gt;DocumentDBについては、&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/documentdb-introduction/&#34;&gt;公式&lt;/a&gt;を。

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/documentdb-create-account/&#34;&gt;DBアカウント〜コレクション作成&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/documentdb-import-data/&#34;&gt;ドキュメントインポート&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/documentdb-programming/&#34;&gt;ストアドプロシージャ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;FunctionsのサイトにDocumentDB Node SDKを導入する#12は、&lt;a href=&#34;http://tech.guitarrapc.com/entry/2016/04/05/043723&#34;&gt;こちら&lt;/a&gt;を。コンソールからnpm installできます。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Github連携設定、#13〜14は、&lt;a href=&#34;http://tech.guitarrapc.com/entry/2016/04/03/051552&#34;&gt;こちら&lt;/a&gt;がとても参考になります。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;function-appのサンプル:99ec2e7c4c63926799149ef94c45b73e&#34;&gt;Function Appのサンプル&lt;/h2&gt;

&lt;p&gt;Githubにソースを&lt;a href=&#34;https://github.com/ToruMakabe/MakabeerBot&#34;&gt;置いておきます&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;ちなみにこのディレクトリ階層はGithub連携を考慮し、Function Appサイトのそれと合わせています。以下がデプロイ後のサイト階層です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;D:\home\site\wwwroot
├── fb-message-callback
│   ├── TestOutput.json
│   ├── function.json
│   └── index.js  #これが今回のアプリ
├── node_modules  #DocumentDB Node SDKが入っている
├── host.json
├── README.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なお、DocumentDBのSDKパッケージは、なぜかfb-message-callbackローカルに置くと読み込まれないため、暫定的にルートへ配置しています。&lt;/p&gt;

&lt;p&gt;ではFunction Appの実体、index.jsを見てみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var https = require(&#39;https&#39;);
var documentClient = require(&amp;quot;documentdb&amp;quot;).DocumentClient;
const databaseUrl = &amp;quot;dbs/&amp;quot; + process.env.APPSETTING_DOCDB_DB_ID;

var client = new documentClient(process.env.APPSETTING_DOCDB_ENDPOINT, { &amp;quot;masterKey&amp;quot;: process.env.APPSETTING_DOCDB_AUTHKEY });

function sendTextMessage(sender, text, context) {
  getDataFromDocDB().then(function (value) {
    var msgAll = value[0].randomDocument.beer + &amp;quot; &amp;quot; + value[1].randomDocument.msg;
    var postData = JSON.stringify({
      recipient: sender,
      message: {
        &amp;quot;attachment&amp;quot;:{
          &amp;quot;type&amp;quot;:&amp;quot;template&amp;quot;,
          &amp;quot;payload&amp;quot;:{
            &amp;quot;template_type&amp;quot;:&amp;quot;button&amp;quot;,
            &amp;quot;text&amp;quot;:msgAll,
            &amp;quot;buttons&amp;quot;:[
              {
                &amp;quot;type&amp;quot;:&amp;quot;web_url&amp;quot;,
                &amp;quot;url&amp;quot;:value[0].randomDocument.url,
                &amp;quot;title&amp;quot;:&amp;quot;詳しく&amp;quot;
              }
            ]
          }
        }
      }
    });
    var req = https.request({
      hostname: &#39;graph.facebook.com&#39;,
      port: 443,
      path: &#39;/v2.6/me/messages&#39;,
      method: &#39;POST&#39;,
      headers: {
        &#39;Content-Type&#39;: &#39;application/json&#39;,
        &#39;Authorization&#39;: &#39;Bearer &#39; + process.env.APPSETTING_FB_PAGE_TOKEN
      }
    });
    req.write(postData);
    req.end();
  }).catch(function(err){
    context.log(err);
  });  
}

function getRandomDoc(sprocUrl){
  return new Promise(function (resolve, reject) {
    const sprocParams = {};
    client.executeStoredProcedure(sprocUrl, sprocParams, function(err, result, responseHeaders) {
      if (err) {
        reject(err);
      }
      if (result) {
        resolve(result);
      }
    });
  });
}

var results = {
  beer: function getBeer() {
    var collectionUrl = databaseUrl + &amp;quot;/colls/beer&amp;quot;;
    var sprocUrl = collectionUrl + &amp;quot;/sprocs/GetRandomDoc&amp;quot;;
    return getRandomDoc(sprocUrl).then(function (result) {
      return result;
    });
  },
  eom: function getEom() {
    var collectionUrl = databaseUrl + &amp;quot;/colls/eom&amp;quot;;
    var sprocUrl = collectionUrl + &amp;quot;/sprocs/GetRandomDoc&amp;quot;;
    return getRandomDoc(sprocUrl).then(function (result) {
      return result;
    });
  }
}

function getDataFromDocDB() {
  return Promise.all([results.beer(), results.eom()]);
}

module.exports = function (context, req) {
  messaging_evts = req.body.entry[0].messaging;
  for (i = 0; i &amp;lt; messaging_evts.length; i++) {
    evt = req.body.entry[0].messaging[i];
    sender = evt.sender;
    if (evt.message &amp;amp;&amp;amp; evt.message.text, context) {
      sendTextMessage(sender, evt.message.text, context);
    }
  }
  context.done();
};
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;最下部のmodule.export以降のブロックで、webhookイベントを受け取ります&lt;/li&gt;
&lt;li&gt;それがmessageイベントで、テキストが入っていれば、sendTextMessage関数を呼びます

&lt;ul&gt;
&lt;li&gt;好みは聞いてないので、以降、受け取ったテキストが読まれることはありませんが&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;sendTextMessage関数内、getDataFromDocDB関数呼び出しでDocumentDBへ問い合わせてビールと文末表現をランダムに取り出します

&lt;ul&gt;
&lt;li&gt;コレクション&amp;rdquo;beer&amp;rdquo;、&amp;rdquo;eom(end of message)&amp;ldquo;の構造はそれぞれこんな感じ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;url&amp;quot;: &amp;quot;http://beertaster.org/beerstyle/web/001A.html#japanese&amp;quot;,
  &amp;quot;beer&amp;quot;: &amp;quot;酵母なし、ライトアメリカン・ウィートビール&amp;quot;,
  &amp;quot;id&amp;quot;: &amp;quot;bf3636c5-4284-4e7a-b587-9002a771f214&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;msg&amp;quot;: &amp;quot;はウマい&amp;quot;,
  &amp;quot;id&amp;quot;: &amp;quot;acd63222-2138-4e19-894e-dc85a950be64&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;DocumentDBの2つのコレクションへの問い合わせが終わった後、Facebookへメッセージを返すため、逐次処理目的でJavaScriptの&lt;a href=&#34;http://azu.github.io/promises-book/&#34;&gt;Promise&lt;/a&gt;を使っています&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;いかがでしょう。好みを聞かない気まぐれBotとはいえ、気軽に作れることがわかりました。ゼロからこの手のイベント処理を作るの、面倒ですものね。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&amp;ldquo;なお、Facebook Messenger API連動アプリの外部公開には、審査が必要とのことです&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure BatchとDockerで管理サーバレスバッチ環境を作る</title>
      <link>http://torumakabe.github.io/post/azure_batch_docker/</link>
      <pubDate>Fri, 29 Apr 2016 17:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_batch_docker/</guid>
      <description>

&lt;h2 id=&#34;サーバレスって言いたいだけじゃないです:1e958ca6820e4dcff939a22a84382ed3&#34;&gt;サーバレスって言いたいだけじゃないです&lt;/h2&gt;

&lt;p&gt;Linux向けAzure BatchのPreviewが&lt;a href=&#34;https://azure.microsoft.com/ja-jp/blog/announcing-support-of-linux-vm-on-azure-batch-service/&#34;&gt;はじまり&lt;/a&gt;ました。地味ですが、なかなかのポテンシャルです。&lt;/p&gt;

&lt;p&gt;クラウドでバッチを走らせる時にチャレンジしたいことの筆頭は「ジョブを走らせる時だけサーバ使う。待機時間は消しておいて、
節約」でしょう。&lt;/p&gt;

&lt;p&gt;ですが、仕組み作りが意外に面倒なんですよね。管理サーバを作って、ジョブ管理ソフト入れて、Azure SDK/CLI入れて。クレデンシャルを安全に管理して。可用性確保して。バックアップして。で、管理サーバは消せずに常時起動。なんか中途半端です。&lt;/p&gt;

&lt;p&gt;その課題、Azure Batchを使って解決しましょう。レッツ管理サーバレスバッチ処理。&lt;/p&gt;

&lt;h2 id=&#34;コンセプト:1e958ca6820e4dcff939a22a84382ed3&#34;&gt;コンセプト&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;管理サーバを作らない&lt;/li&gt;
&lt;li&gt;Azure Batchコマンドでジョブを投入したら、あとはスケジュール通りに定期実行される&lt;/li&gt;
&lt;li&gt;ジョブ実行サーバ群(Pool)は必要な時に作成され、処理が終わったら削除される&lt;/li&gt;
&lt;li&gt;サーバの迅速な作成とアプリ可搬性担保のため、dockerを使う&lt;/li&gt;
&lt;li&gt;セットアップスクリプト、タスク実行ファイル、アプリ向け入力/出力ファイルはオブジェクトストレージに格納&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サンプル:1e958ca6820e4dcff939a22a84382ed3&#34;&gt;サンプル&lt;/h2&gt;

&lt;p&gt;Githubにソースを&lt;a href=&#34;https://github.com/ToruMakabe/Azure_Batch_Sample&#34;&gt;置いておきます&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;バッチアカウントとストレージアカウント-コンテナの作成とアプリ-データの配置:1e958ca6820e4dcff939a22a84382ed3&#34;&gt;バッチアカウントとストレージアカウント、コンテナの作成とアプリ、データの配置&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/batch-technical-overview/&#34;&gt;公式ドキュメント&lt;/a&gt;で概要を確認しましょう。うっすら理解できたら、バッチアカウントとストレージアカウントを作成します。&lt;/p&gt;

&lt;p&gt;ストレージアカウントに、Blobコンテナを作ります。サンプルの構成は以下の通り。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├── blob
│   ├── application
│   │   ├── starttask.sh
│   │   └── task.sh
│   ├── input
│   │   └── the_star_spangled_banner.txt
│   └── output
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;applicationコンテナに、ジョブ実行サーバ作成時のスクリプト(starttask.sh)と、タスク実行時のスクリプト(task.sh)を配置します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ToruMakabe/Azure_Batch_Sample/blob/master/blob/application/starttask.sh&#34;&gt;starttask.sh&lt;/a&gt; - docker engineをインストールします&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ToruMakabe/Azure_Batch_Sample/blob/master/blob/application/task.sh&#34;&gt;task.sh&lt;/a&gt; - docker hubからサンプルアプリが入ったコンテナを持ってきて実行します。&lt;a href=&#34;https://github.com/ToruMakabe/Azure_Batch_Sample/tree/master/docker&#34;&gt;サンプル&lt;/a&gt;はPythonで書いたシンプルなWord Countアプリです&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;また、アプリにデータをわたすinputコンテナと、実行結果を書き込むoutputコンテナも作ります。サンプルのinputデータはアメリカ国歌です。&lt;/p&gt;

&lt;p&gt;コンテナ、ファイルには、適宜SASを生成しておいてください。inputではreadとlist、outputでは加えてwrite権限を。&lt;/p&gt;

&lt;p&gt;さて、いよいよジョブをJSONで定義します。詳細は&lt;a href=&#34;https://msdn.microsoft.com/en-us/library/azure/dn820158.aspx?f=255&amp;amp;MSPPError=-2147217396&#34;&gt;公式ドキュメント&lt;/a&gt;を確認してください。ポイントだけまとめます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2016/04/29 05:30(UTC)から開始する - schedule/doNotRunUntil&lt;/li&gt;
&lt;li&gt;4時間ごとに実行する - schedule/recurrenceInterval&lt;/li&gt;
&lt;li&gt;ジョブ実行後にサーバプールを削除する - jobSpecification/poolInfo/autoPoolSpecification/poolLifetimeOption&lt;/li&gt;
&lt;li&gt;ジョブ実行時にtask.shを呼び出す  - jobSpecification/jobManagerTask/commandLine&lt;/li&gt;
&lt;li&gt;サーバはUbuntu 14.04とする - jobSpecification/poolInfo/autoPoolSpecification/virtualMachineConfiguration&lt;/li&gt;
&lt;li&gt;サーバ数は1台とする - jobSpecification/poolInfo/autoPoolSpecification/pool/targetDedicated&lt;/li&gt;
&lt;li&gt;サーバプール作成時にstarttask.shを呼び出す - jobSpecification/poolInfo/autoPoolSpecification/pool/startTask&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  {
  &amp;quot;odata.metadata&amp;quot;:&amp;quot;https://myaccount.myregion.batch.azure.com/$metadata#jobschedules/@Element&amp;quot;,
  &amp;quot;id&amp;quot;:&amp;quot;myjobschedule1&amp;quot;,
  &amp;quot;schedule&amp;quot;: {
    &amp;quot;doNotRunUntil&amp;quot;:&amp;quot;2016-04-29T05:30:00.000Z&amp;quot;,
    &amp;quot;recurrenceInterval&amp;quot;:&amp;quot;PT4H&amp;quot;
  },
  &amp;quot;jobSpecification&amp;quot;: {
    &amp;quot;priority&amp;quot;:100,
    &amp;quot;constraints&amp;quot;: {
      &amp;quot;maxWallClockTime&amp;quot;:&amp;quot;PT1H&amp;quot;,
      &amp;quot;maxTaskRetryCount&amp;quot;:-1
    },
    &amp;quot;jobManagerTask&amp;quot;: {
      &amp;quot;id&amp;quot;:&amp;quot;mytask1&amp;quot;,
      &amp;quot;commandLine&amp;quot;:&amp;quot;/bin/bash -c &#39;export LC_ALL=en_US.UTF-8; ./task.sh&#39;&amp;quot;,
      &amp;quot;resourceFiles&amp;quot;: [ {
        &amp;quot;blobSource&amp;quot;:&amp;quot;yourbloburi&amp;amp;sas&amp;quot;,
        &amp;quot;filePath&amp;quot;:&amp;quot;task.sh&amp;quot;
      }], 
      &amp;quot;environmentSettings&amp;quot;: [ {
        &amp;quot;name&amp;quot;:&amp;quot;VAR1&amp;quot;,
        &amp;quot;value&amp;quot;:&amp;quot;hello&amp;quot;
      } ],
      &amp;quot;constraints&amp;quot;: {
        &amp;quot;maxWallClockTime&amp;quot;:&amp;quot;PT1H&amp;quot;,
        &amp;quot;maxTaskRetryCount&amp;quot;:0,
        &amp;quot;retentionTime&amp;quot;:&amp;quot;PT1H&amp;quot;
      },
      &amp;quot;killJobOnCompletion&amp;quot;:false,
      &amp;quot;runElevated&amp;quot;:true,
      &amp;quot;runExclusive&amp;quot;:true
      },
      &amp;quot;poolInfo&amp;quot;: {
        &amp;quot;autoPoolSpecification&amp;quot;: {
          &amp;quot;autoPoolIdPrefix&amp;quot;:&amp;quot;mypool&amp;quot;,
          &amp;quot;poolLifetimeOption&amp;quot;:&amp;quot;job&amp;quot;,
          &amp;quot;pool&amp;quot;: {
            &amp;quot;vmSize&amp;quot;:&amp;quot;STANDARD_D1&amp;quot;,
            &amp;quot;virtualMachineConfiguration&amp;quot;: {
              &amp;quot;imageReference&amp;quot;: {
                &amp;quot;publisher&amp;quot;:&amp;quot;Canonical&amp;quot;,
                &amp;quot;offer&amp;quot;:&amp;quot;UbuntuServer&amp;quot;,
                &amp;quot;sku&amp;quot;:&amp;quot;14.04.4-LTS&amp;quot;,
                &amp;quot;version&amp;quot;:&amp;quot;latest&amp;quot;
              },
              &amp;quot;nodeAgentSKUId&amp;quot;:&amp;quot;batch.node.ubuntu 14.04&amp;quot;
            },
            &amp;quot;resizeTimeout&amp;quot;:&amp;quot;PT15M&amp;quot;,
            &amp;quot;targetDedicated&amp;quot;:1,
            &amp;quot;maxTasksPerNode&amp;quot;:1,
            &amp;quot;taskSchedulingPolicy&amp;quot;: {
              &amp;quot;nodeFillType&amp;quot;:&amp;quot;Spread&amp;quot;
            },
            &amp;quot;enableAutoScale&amp;quot;:false,
            &amp;quot;enableInterNodeCommunication&amp;quot;:false,
            &amp;quot;startTask&amp;quot;: {
              &amp;quot;commandLine&amp;quot;:&amp;quot;/bin/bash -c &#39;export LC_ALL=en_US.UTF-8; ./starttask.sh&#39;&amp;quot;,
              &amp;quot;resourceFiles&amp;quot;: [ {
                &amp;quot;blobSource&amp;quot;:&amp;quot;yourbloburi&amp;amp;sas&amp;quot;,
                &amp;quot;filePath&amp;quot;:&amp;quot;starttask.sh&amp;quot;
              } ],
              &amp;quot;environmentSettings&amp;quot;: [ {
                &amp;quot;name&amp;quot;:&amp;quot;VAR2&amp;quot;,
                &amp;quot;value&amp;quot;:&amp;quot;Chao&amp;quot;
              } ],
              &amp;quot;runElevated&amp;quot;:true,
              &amp;quot;waitForSuccess&amp;quot;:true
            },
            &amp;quot;metadata&amp;quot;: [ {
              &amp;quot;name&amp;quot;:&amp;quot;myproperty&amp;quot;,
              &amp;quot;value&amp;quot;:&amp;quot;myvalue&amp;quot;
            } ]
          }
        }
      }
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そろそろ人類はJSONに変わるやり口を発明すべきですが、XMLよりはいいですね。&lt;/p&gt;

&lt;p&gt;それはさておき、面白そうなパラメータたち。並列バッチやジョブリリース時のタスクなど、今回使っていないものもまだまだあります。応用版はまたの機会に。&lt;/p&gt;

&lt;p&gt;ではスケジュールジョブをAzure BatchにCLIで送り込みます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;azure batch job-schedule create -f ./create_jobsched.json -u https://yourendpoint.location.batch.azure.com -a yourbatchaccount -k yourbatchaccountkey
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上です。あとはAzureにお任せです。4時間に1回、アメリカ国歌の単語を数える刺身タンポポなジョブですが、コツコツいきましょう。&lt;/p&gt;

&lt;h2 id=&#34;azure-automationとの使い分け:1e958ca6820e4dcff939a22a84382ed3&#34;&gt;Azure Automationとの使い分け&lt;/h2&gt;

&lt;p&gt;Azure Automationを使っても、ジョブの定期実行はできます。大きな違いは、PowerShellの要否と並列実行フレームワークの有無です。Azure AutomationはPowerShell前提ですが、Azure BatchはPowerShellに馴染みのない人でも使うことができます。また、今回は触れませんでしたが、Azure Batchは並列バッチ、オートスケールなど、バッチ処理に特化した機能を提供していることが特長です。うまく使い分けましょう。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure Linux VMのディスク利用料節約Tips</title>
      <link>http://torumakabe.github.io/post/azure_pageblob_billable_linux/</link>
      <pubDate>Thu, 21 Apr 2016 21:30:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_pageblob_billable_linux/</guid>
      <description>

&lt;h2 id=&#34;定義領域全てが課金されるわけではありません:73b15a413c7cb87e88f45a7aaba2eebd&#34;&gt;定義領域全てが課金されるわけではありません&lt;/h2&gt;

&lt;p&gt;AzureのIaaSでは、VMに接続するディスクとしてAzure StorageのPage Blobを使います。Page Blobは作成時に容量を定義しますが、課金対象となるのは、実際に書き込んだ領域分のみです。たとえば10GBytesのVHD Page Blobを作ったとしても、1GBytesしか書き込んでいなければ、課金対象は1GBytesです。&lt;/p&gt;

&lt;p&gt;なお、Premium Storageは例外です。&lt;a href=&#34;https://azure.microsoft.com/ja-jp/pricing/details/storage/&#34;&gt;FAQ&lt;/a&gt;を確認してみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;仮想マシンに空の 100 GB ディスクを接続した場合、100 GB 全体に対する料金が請求されますか? それとも使用したストレージ領域の分だけが請求されますか?

空の 100 GB ディスクが Premium Storage アカウントによって保持されている場合、P10 (128 GB) ディスクの料金が課金されます。その他の種類の Storage アカウントが使用されている場合、割り当てられたディスク サイズに関わらず、ディスクに書き込まれたデータを保存するために使用しているストレージ領域分のみ請求されます。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;詳細な定義は、以下で。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/windowsazurestorage/2010/07/08/understanding-windows-azure-storage-billing-bandwidth-transactions-and-capacity/&#34;&gt;Understanding Windows Azure Storage Billing – Bandwidth, Transactions, and Capacity&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;書き込み方はosやファイルシステム次第:73b15a413c7cb87e88f45a7aaba2eebd&#34;&gt;書き込み方はOSやファイルシステム次第&lt;/h2&gt;

&lt;p&gt;じゃあ、OSなりファイルシステムが、実際にどのタイミングでディスクに書き込むのか、気になりますね。実データの他に管理情報、メタデータがあるので、特徴があるはずです。Linuxで検証してみましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RHEL 7.2 on Azure&lt;/li&gt;
&lt;li&gt;XFS &amp;amp; Ext4&lt;/li&gt;
&lt;li&gt;10GBytesのPage Blobの上にファイルシステムを作成&lt;/li&gt;
&lt;li&gt;mkfsはデフォルト&lt;/li&gt;
&lt;li&gt;mountはデフォルトとdiscardオプションありの2パターン&lt;/li&gt;
&lt;li&gt;MD、LVM構成にしない&lt;/li&gt;
&lt;li&gt;以下のタイミングで課金対象容量を確認

&lt;ul&gt;
&lt;li&gt;Page BlobのVMアタッチ時&lt;/li&gt;
&lt;li&gt;ファイルシステム作成時&lt;/li&gt;
&lt;li&gt;マウント時&lt;/li&gt;
&lt;li&gt;約5GBytesのデータ書き込み時 (ddで/dev/zeroをbs=1M、count=5000で書き込み)&lt;/li&gt;
&lt;li&gt;5GBytesのファイル削除時&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;課金対象容量は、以下のPowerShellで取得します。リファレンスは&lt;a href=&#34;https://gallery.technet.microsoft.com/scriptcenter/Get-Billable-Size-of-32175802&#34;&gt;ここ&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$Blob = Get-AzureStorageBlob yourDataDisk.vhd -Container vhds -Context $Ctx

$blobSizeInBytes = 124 + $Blob.Name.Length * 2

$metadataEnumerator = $Blob.ICloudBlob.Metadata.GetEnumerator()
while ($metadataEnumerator.MoveNext())
{
    $blobSizeInBytes += 3 + $metadataEnumerator.Current.Key.Length + $metadataEnumerator.Current.Value.Length
}

$Blob.ICloudBlob.GetPageRanges() | 
    ForEach-Object { $blobSizeInBytes += 12 + $_.EndOffset - $_.StartOffset }

return $blobSizeInBytes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ストレージコンテキストの作り方は&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-powershell-guide-full/&#34;&gt;ここ&lt;/a&gt;を参考にしてください。&lt;/p&gt;

&lt;h2 id=&#34;結果:73b15a413c7cb87e88f45a7aaba2eebd&#34;&gt;結果&lt;/h2&gt;

&lt;h3 id=&#34;xfs:73b15a413c7cb87e88f45a7aaba2eebd&#34;&gt;XFS&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;　確認タイミング　&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;　課金対象容量(Bytes)　&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Page BlobのVMアタッチ時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;960&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ファイルシステム作成時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10,791,949&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;マウント時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10,791,949&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;5GBytesのデータ書き込み時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5,253,590,051&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;5Gbytesのファイル削除時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5,253,590,051&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;5Gbytesのファイル削除時 (discard)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10,710,029&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;ext4:73b15a413c7cb87e88f45a7aaba2eebd&#34;&gt;Ext4&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;　確認タイミング　&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;　課金対象容量(Bytes)　&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Page BlobのVMアタッチ時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;960&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ファイルシステム作成時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;138,683,592&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;マウント時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;306,451,689&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;5GBytesのデータ書き込み時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5,549,470,887&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;5Gbytesのファイル削除時&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5,549,470,887&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;5Gbytesのファイル削除時 (discard)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;306,586,780&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;この結果から、以下のことがわかります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;10GBytesのBlobを作成しても、全てが課金対象ではない&lt;/li&gt;
&lt;li&gt;当然だが、ファイルシステムによってメタデータの書き方が違う、よって書き込み容量も異なる&lt;/li&gt;
&lt;li&gt;discardオプションなしでマウントすると、ファイルを消しても課金対象容量は減らない

&lt;ul&gt;
&lt;li&gt;OSがPage Blobに&amp;rdquo;消した&amp;rdquo;と伝えないから&lt;/li&gt;
&lt;li&gt;discardオプションにてSCSI UNMAPがPage Blobに伝えられ、領域は解放される(課金対象容量も減る)&lt;/li&gt;
&lt;li&gt;discardオプションはリアルタイムであるため便利。でも性能影響があるため、実運用ではバッチ適用(fstrim)が&lt;a href=&#34;https://access.redhat.com/documentation/ja-JP/Red_Hat_Enterprise_Linux/7/html/Storage_Administration_Guide/ch02s05.html&#34;&gt;おすすめ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;知っているとコスト削減に役立つTipsでした。ぜひ運用前には、利用予定のファイルシステムやオプションで、事前に検証してみてください。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AzureとDockerでDeep Learning(CNTK)環境をサク作する</title>
      <link>http://torumakabe.github.io/post/azure_docker_cntk/</link>
      <pubDate>Sun, 17 Apr 2016 10:30:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_docker_cntk/</guid>
      <description>

&lt;h2 id=&#34;気軽に作って壊せる環境を作る:7c419a069d08019c3093e0308a68c463&#34;&gt;気軽に作って壊せる環境を作る&lt;/h2&gt;

&lt;p&gt;Deep Learning環境設計のお手伝いをする機会に恵まれまして。インフラおじさんはDeep Learningであれこれする主役ではないのですが、ちょっとは中身を理解しておきたいなと思い、環境作ってます。&lt;/p&gt;

&lt;p&gt;試行錯誤するでしょうから、萎えないようにデプロイは自動化します。&lt;/p&gt;

&lt;h2 id=&#34;方針:7c419a069d08019c3093e0308a68c463&#34;&gt;方針&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;インフラはAzure Resource Manager Templateでデプロイする

&lt;ul&gt;
&lt;li&gt;Linux (Ubuntu 14.04) VM, 仮想ネットワーク/ストレージ関連リソース&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;CNTKをビルド済みのdockerリポジトリをDocker Hubに置いておく

&lt;ul&gt;
&lt;li&gt;Dockerfileの元ネタは&lt;a href=&#34;https://github.com/Microsoft/CNTK/tree/master/Tools/docker&#34;&gt;ここ&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;GPUむけもあるけどグッと我慢、今回はCPUで&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Docker Hub上のリポジトリは &lt;a href=&#34;https://hub.docker.com/r/torumakabe/cntk-cpu/&#34;&gt;torumakabe/cntk-cpu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ARM TemplateデプロイでVM Extensionを仕込んで、上物のセットアップもやっつける

&lt;ul&gt;
&lt;li&gt;docker extensionでdocker engineを導入&lt;/li&gt;
&lt;li&gt;custom script extensionでdockerリポジトリ(torumakabe/cntk-cpu)をpull&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;VMにログインしたら即CNTKを使える、幸せ&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;使い方:7c419a069d08019c3093e0308a68c463&#34;&gt;使い方&lt;/h2&gt;

&lt;p&gt;Azure CLIでARM Templateデプロイします。WindowsでもMacでもLinuxでもOK。&lt;/p&gt;

&lt;p&gt;リソースグループを作ります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Work&amp;gt; azure group create CNTK -l &amp;quot;Japan West&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ARMテンプレートの準備をします。テンプレートはGithubに置いておきました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ToruMakabe/CNTK/blob/master/deploy_singlenode/azuredeploy.json&#34;&gt;azuredeploy.json&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;編集不要です&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ToruMakabe/CNTK/blob/master/deploy_singlenode/azuredeploy.parameters.sample.json&#34;&gt;azuredeploy.parameters.json&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;テンプレートに直で書かきたくないパラメータです&lt;/li&gt;
&lt;li&gt;fileUris、commandToExecute以外は、各々で&lt;/li&gt;
&lt;li&gt;fileUris、commandToExecuteもGist読んでdocker pullしているだけなので、お好みで変えてください&lt;/li&gt;
&lt;li&gt;ファイル名がazuredeploy.parameters.&amp;ldquo;sample&amp;rdquo;.jsonなので、以降の手順では&amp;rdquo;sample&amp;rdquo;を外して読み替えてください&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;うし、デプロイ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Work&amp;gt; azure group deployment create CNTK dep01 -f .\azuredeploy.json -e .\azuredeploy.parameters.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;10分くらい待つと、できあがります。VMのパブリックIPを確認し、sshしましょう。&lt;/p&gt;

&lt;p&gt;docker engine入ってますかね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yourname@yournamecntkr0:~$ docker -v
Docker version 1.11.0, build 4dc5990
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CNTKビルド済みのdockerイメージ、pullできてますかね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yourname@yournamecntkr0:~$ docker images
REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
yournamebe/cntk-cpu   latest              9abab8a76543        9 hours ago         2.049 GB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;問題なし。ではエンジョイ Deep Learning。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yourname@yournamecntkr0:~$ docker run -it torumakabe/cntk-cpu
root@a1234bc5d67d:/cntk#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CNTKの利用例は、&lt;a href=&#34;https://github.com/Microsoft/CNTK/tree/master/Examples&#34;&gt;Github&lt;/a&gt;にあります。&lt;/p&gt;

&lt;h2 id=&#34;今後の展開:7c419a069d08019c3093e0308a68c463&#34;&gt;今後の展開&lt;/h2&gt;

&lt;p&gt;インフラおじさんは、最近Linuxむけに&lt;a href=&#34;https://azure.microsoft.com/ja-jp/blog/announcing-support-of-linux-vm-on-azure-batch-service/&#34;&gt;Previewがはじまった&lt;/a&gt;Azure Batchと、このエントリで使った仕掛けを組み合わせて、大規模並列Deep Learning環境の自動化と使い捨て化を企んでいます。&lt;/p&gt;

&lt;p&gt;これだけ簡単に再現性ある環境を作れるなら、常時インフラ起動しておく必要ないですものね。使い捨てでいいです。&lt;/p&gt;

&lt;p&gt;もちろんdockerやGPUまわりの性能など別の課題にぶつかりそうですが、人間がどれだけ楽できるかとのトレードオフかと。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azureの監査ログアラートからWebhookの流れで楽をする</title>
      <link>http://torumakabe.github.io/post/azure_auditlog_alert/</link>
      <pubDate>Wed, 06 Apr 2016 17:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_auditlog_alert/</guid>
      <description>

&lt;h2 id=&#34;監査ログからアラートを上げられるようになります:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;監査ログからアラートを上げられるようになります&lt;/h2&gt;

&lt;p&gt;Azureの監査ログからアラートを上げる機能のプレビューが&lt;a href=&#34;https://azure.microsoft.com/ja-jp/blog/new-features-for-azure-alerts-and-autoscale/&#34;&gt;はじまりました&lt;/a&gt;。これ、地味ですが便利な機能です。日々の運用に効きます。&lt;/p&gt;

&lt;h2 id=&#34;どんな風に使えるか:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;どんな風に使えるか&lt;/h2&gt;

&lt;p&gt;ルールに合致した監査ログが生成された場合、メール通知とWebhookによる自動アクションができます。可能性無限大です。&lt;/p&gt;

&lt;p&gt;たとえば、「特定のリソースグループにVMが生成された場合、そのVMに対し強制的にログ収集エージェントをインストールし、ログを集める」なんてことができます。&lt;/p&gt;

&lt;p&gt;これは「生産性を上げるため、アプリ開発チームにVMの生成は委任したい。でもセキュリティなどの観点から、ログは集めておきたい」なんてインフラ担当/Opsの課題に効きます。開発チームに「VM生成時には必ず入れてね」とお願いするのも手ですが、やはり人間は忘れる生き物ですので、自動で適用できる仕組みがあるとうれしい。&lt;/p&gt;

&lt;p&gt;これまでは監視用のVMを立てて、「新しいVMがあるかどうか定期的にチェックして、あったらエージェントを叩き込む」なんてことをしていたわけですが、もうそのVMは不要です。定期的なチェックも要りません。アラートからアクションを実現する仕組みを、Azureがマネージドサービスとして提供します。&lt;/p&gt;

&lt;h2 id=&#34;実装例:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;実装例&lt;/h2&gt;

&lt;p&gt;例としてこんな仕組みを作ってみましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;西日本リージョンのリソースグループ&amp;rdquo;dev&amp;rdquo;にVMが作成されたら、自動的にメール通知とWebhookを実行&lt;/li&gt;
&lt;li&gt;WebhookでAzure AutomationのRunbook Jobを呼び出し、OMS(Operations Management Suite)エージェントを該当のVMにインストール、接続先OMSを設定する&lt;/li&gt;
&lt;li&gt;OMSでログ分析&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;準備:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;以下の準備ができているか確認します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Azure Automation向けADアプリ、サービスプリンシパル作成&lt;/li&gt;
&lt;li&gt;サービスプリンシパルへのロール割り当て&lt;/li&gt;
&lt;li&gt;Azure Automationのアカウント作成&lt;/li&gt;
&lt;li&gt;Azure Automation Runbook実行時ログインに必要な証明書や資格情報などの資産登録&lt;/li&gt;
&lt;li&gt;Azure Automation Runbookで使う変数資産登録 (Runbook内でGet-AutomationVariableで取得できます。暗号化もできますし、コードに含めるべきでない情報は、登録しましょう。後述のサンプルではログイン関連情報、OMS関連情報を登録しています)&lt;/li&gt;
&lt;li&gt;OMSワークスペースの作成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;もしAutomationまわりの作業がはじめてであれば、下記記事を参考にしてください。とてもわかりやすい。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://qiita.com/sengoku/items/1c3994ac8a2f0f0e88c5&#34;&gt;勤務時間中だけ仮想マシンを動かす（スケジュールによる自動起動・停止）&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;azure-automation側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;Azure Automation側の仕掛け&lt;/h2&gt;

&lt;p&gt;先にAutomationのRunbookを作ります。アラート設定をする際、RunbookのWebhook URLが必要になるので。&lt;/p&gt;

&lt;p&gt;ちなみにわたしは証明書を使ってログインしています。資格情報を使う場合はログインまわりのコードを読み替えてください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;param ( 
    [object]$WebhookData          
)

if ($WebhookData -ne $null) {  
    $WebhookName    =   $WebhookData.WebhookName
    $WebhookBody    =   $WebhookData.RequestBody  
    $WebhookBody = (ConvertFrom-Json -InputObject $WebhookBody)

    $AlertContext = [object]$WebhookBody.context

    $SPAppID = Get-AutomationVariable -Name &#39;SPAppID&#39;
    $Tenant = Get-AutomationVariable -Name &#39;TenantID&#39;
    $OMSWorkspaceId = Get-AutomationVariable -Name &#39;OMSWorkspaceId&#39;
    $OMSWorkspaceKey = Get-AutomationVariable -Name &#39;OMSWorkspaceKey&#39;
    $CertificationName = Get-AutomationVariable -Name &#39;CertificationName&#39;
    $Certificate = Get-AutomationCertificate -Name $CertificationName
    $CertThumbprint = ($Certificate.Thumbprint).ToString()    

    $null = Login-AzureRmAccount -ServicePrincipal -TenantId $Tenant -CertificateThumbprint $CertThumbprint -ApplicationId $SPAppID   

    $resourceObj = Get-AzureRmResource -ResourceId $AlertContext.resourceId
    $VM = Get-AzureRmVM -Name $resourceObj.Name -ResourceGroupName $resourceObj.ResourceGroupName

    $Settings = @{&amp;quot;workspaceId&amp;quot; = &amp;quot;$OMSWorkspaceId&amp;quot;}
    $ProtectedSettings = @{&amp;quot;workspaceKey&amp;quot; = &amp;quot;$OMSWorkspaceKey&amp;quot;}

    if ($VM.StorageProfile.OsDisk.OsType -eq &amp;quot;Linux&amp;quot;) {  
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &amp;quot;OmsAgentForLinux&amp;quot; -Publisher &amp;quot;Microsoft.EnterpriseCloud.Monitoring&amp;quot; -ExtensionType &amp;quot;OmsAgentForLinux&amp;quot; -TypeHandlerVersion &amp;quot;1.0&amp;quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    elseif ($VM.StorageProfile.OsDisk.OsType -eq &amp;quot;Windows&amp;quot;)
    {
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &amp;quot;MicrosoftMonitoringAgent&amp;quot; -Publisher &amp;quot;Microsoft.EnterpriseCloud.Monitoring&amp;quot; -ExtensionType &amp;quot;MicrosoftMonitoringAgent&amp;quot; -TypeHandlerVersion &amp;quot;1.0&amp;quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    else
    {
        Write-Error &amp;quot;Unknown OS Type.&amp;quot;
    }
}
else 
{
    Write-Error &amp;quot;This runbook is meant to only be started from a webhook.&amp;quot; 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Runbookができたら、Webhookを作ります。詳しくは&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/automation-webhooks/&#34;&gt;こちら&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;WebhookのURLを控えておいてください。&lt;/p&gt;

&lt;h2 id=&#34;azure-監査ログアラート側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;Azure 監査ログアラート側の仕掛け&lt;/h2&gt;

&lt;p&gt;Powershellでアラートルールを作ります。実行アカウントの権限に気をつけてください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\work&amp;gt; $actionEmail = New-AzureRmAlertRuleEmail -CustomEmail yourname@example.com

PS C:\work&amp;gt; $actionWebhook = New-AzureRmAlertRuleWebhook -ServiceUri https://abcdefgh.azure-automation.net/webhooks?token=your_token

PS C:\work&amp;gt; Add-AzureRmLogAlertRule -Name createdVM -Location &amp;quot;Japan West&amp;quot; -ResourceGroup dev -OperationName Microsoft.Compute/virtualMachines/write -Status Succeeded  -SubStatus Created -TargetResourceGroup dev -Actions $actionEmail,$actionWebhook
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上。これで&amp;rdquo;dev&amp;rdquo;リソースグループにVMが作られた場合、自動でOMSエージェントがインストールされ、ログ収集がはじまります。&lt;/p&gt;

&lt;p&gt;なお、メールも飛んできますので、うっとおしくなったらメール通知はアクションから外すか、ルールでさばいてくださいね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>書評: Site Reliability Engineering</title>
      <link>http://torumakabe.github.io/post/bookreview_site_reliability_engineering/</link>
      <pubDate>Sun, 27 Mar 2016 20:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/bookreview_site_reliability_engineering/</guid>
      <description>

&lt;h2 id=&#34;英語だけどぜひ読んでほしい:85f39e44bed874d49c5c215a7c1e75f5&#34;&gt;英語だけどぜひ読んでほしい&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.amazon.co.jp/Site-Reliability-Engineering-Production-Systems-ebook/dp/B01DCPXKZ6/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;amp;qid=1459069692&amp;amp;sr=8-1&#34;&gt;Site Reliability Engineering: How Google Runs Production Systems&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;参考になったのでご紹介。Googleのインフラ/Ops系技術チームの働き方や考え方を題材にした本です。GoogleのSREについては断片的に知っていたのですが、まとめて読むと違いますね。背景やストーリーがあって、理解しやすいです。&lt;/p&gt;

&lt;p&gt;共感できるネタがどんどん繰り出されるので、一気読みしました。読み込みが浅いところもあったので、改めて読む予定。&lt;/p&gt;

&lt;p&gt;以下、印象に残ったこと。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Site Reliability Engineering teamは、インフラ/Ops担当であるが、Unix内部やネットワークなどインフラの知見を持つソフトウェアエンジニアの集団。自分たちのオペレーションを効率的に、迅速に、確実にするために、コードを書く。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;インシデント対応、問い合わせ対応、手作業は仕事の50%に収まるように調整する。残りの時間は自分たちの仕事をより良く、楽にするために、コードを書く。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;日々のリアクティブな活動に忙殺されるインフラ/Ops担当はどうしても減点評価になりがちだが、仕事の半分がプロアクティブな活動であり、成果を加点評価できる。昇格、昇給の根拠になりやすい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;アプリ/製品チームとSREチームは&amp;rdquo;Error Budget&amp;rdquo;を定義、共有する。これは四半期ごとに定義される、サービスレベル目標である。ユーザがサービスを使えなくなると、その時間が、このError Budgetから取り崩されていく。Budgetが残り少なくなると、リスクを伴うデプロイなどは控える。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;インフラ/Ops担当は「サービスを少しでもダウンさせたら悪」となりがちだが、サービスごとにアプリ/製品チームとSREチームがError Budgetを共有することで、利害関係を一致できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Error Budgetの大きさはサービスごとに異なり、定義は製品チームの責任。当然Error Budgetが少ない = サービスレベルが高い = コストがかかる ので、製品チームはいたずらに高いサービスレベルを定義しない。Google Apps for WorkとYoutubeのError Budgetは異なる。Appsはサービスレベル重視であり、Youtubeは迅速で頻繁な機能追加を重視する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;SLA違反など、重大な障害では&amp;rdquo;Postmortem(過激だが死体解剖の意)&amp;ldquo;を作成し、失敗から学ぶ。客観的に、建設的に。誰かや何かを責めるためにやるわけではない。マサカリ投げない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;他の産業から学ぶ。製造業のビジネス継続プラン、国防のシミュレーションや演習、通信業の輻輳対策など。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;もう一回読んだら、また違う発見があるんじゃないかと。&lt;/p&gt;

&lt;h2 id=&#34;自分ごととして読みたい:85f39e44bed874d49c5c215a7c1e75f5&#34;&gt;自分ごととして読みたい&lt;/h2&gt;

&lt;p&gt;今後の働き方や所属組織に行き詰まりを感じているインフラ/Ops技術者に、参考になるネタが多いと思います。&lt;/p&gt;

&lt;p&gt;DevOpsムーブメントが来るか来ないかという今、Opsとしてのスタンスを考え直すのにも、いいかもしれません。&lt;/p&gt;

&lt;p&gt;もちろん、Googleの圧倒的物量、成長スピードゆえのミッションと働き方である事は否定しません。でも、自分とは無関係、と無視するにはもったいないです。&lt;/p&gt;

&lt;p&gt;なお、このSREチーム、できてから10年以上たっているそうです。それだけ持続できるということは、そこに何か本質的な価値があるのではないでしょうか。&lt;/p&gt;

&lt;p&gt;オススメです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure &amp; Terraform Tips (ARM対応 2016春版)</title>
      <link>http://torumakabe.github.io/post/azure_terraform_earlyphase_tips/</link>
      <pubDate>Fri, 25 Mar 2016 22:50:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_terraform_earlyphase_tips/</guid>
      <description>

&lt;h2 id=&#34;俺の屍を越えていけ:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;俺の屍を越えていけ&lt;/h2&gt;

&lt;p&gt;今週リリースされたTerraform v0.6.14で、Azure Resource Manager ProviderのリソースにVMとテンプレートデプロイが&lt;a href=&#34;https://github.com/hashicorp/terraform/blob/v0.6.14/CHANGELOG.md&#34;&gt;追加&lt;/a&gt;されました。この週末お楽しみ、という人も多いかもしれません。&lt;/p&gt;

&lt;p&gt;小生、v0.6.14以前から触っていたこともあり、土地勘があります。そこで現時点でのTipsをいくつかご紹介します。&lt;/p&gt;

&lt;h2 id=&#34;この3つは触る前から意識しよう:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;この3つは触る前から意識しよう&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;ARMテンプレートリソースは分離して使う&lt;/li&gt;
&lt;li&gt;リソース競合したら依存関係を定義する&lt;/li&gt;
&lt;li&gt;公開鍵認証SSH指定でエラーが出ても驚かない&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;1-armテンプレートリソースは分離して使う:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;1. ARMテンプレートリソースは分離して使う&lt;/h2&gt;

&lt;p&gt;v0.6.14で、リソース&lt;a href=&#34;https://www.terraform.io/docs/providers/azurerm/r/template_deployment.html&#34;&gt;&amp;ldquo;azurerm_template_deployment&amp;rdquo;&lt;/a&gt;が追加されました。なんとARMテンプレートを、Terraformの定義ファイル内にインラインで書けます。&lt;/p&gt;

&lt;p&gt;でも、現時点の実装では、おすすめしません。&lt;/p&gt;

&lt;h3 id=&#34;armテンプレートのデプロイ機能とterraformで作ったリソースが不整合を起こす:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;ARMテンプレートのデプロイ機能とTerraformで作ったリソースが不整合を起こす&lt;/h3&gt;

&lt;p&gt;避けるべきなのは&amp;rdquo;Complete(完全)&amp;ldquo;モードでのARMテンプレートデプロイです。なぜなら完全モードでは、ARM リソースマネージャーは次の動きをするからです。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-template-deploy/&#34;&gt;リソース グループに存在するが、テンプレートに指定されていないリソースを削除します&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;つまり、ARMテンプレートで作ったリソース以外、Terraform担当部分を消しにいきます。恐怖! デプロイ vs デプロイ!!。リソースグループを分ければ回避できますが、リスク高めです。&lt;/p&gt;

&lt;h3 id=&#34;タイムアウトしがち:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;タイムアウトしがち&lt;/h3&gt;

&lt;p&gt;それでもTerraformの外でARMテンプレートデプロイは継続します。成功すれば結果オーライですが&amp;hellip;Terraform上はエラーが残ります。「ああそれ無視していいよ」ではあるのですが、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%89%B2%E3%82%8C%E7%AA%93%E7%90%86%E8%AB%96&#34;&gt;割れ窓理論&lt;/a&gt;的によろしくないです。&lt;/p&gt;

&lt;h3 id=&#34;せっかくのリソースグラフを活用できない:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;せっかくのリソースグラフを活用できない&lt;/h3&gt;

&lt;p&gt;Terraformはグラフ構造で賢くリソース間の依存関係を管理し、整合性を維持しています。サクサク apply &amp;amp; destroyできるのもそれのおかげです。ARMテンプレートでデプロイしたリソースはそれに入れられないので、もったいないです。&lt;/p&gt;

&lt;h3 id=&#34;読みづらい:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;読みづらい&lt;/h3&gt;

&lt;p&gt;Terraform DSLにJSONが混ざって読みにくいです。Terraform DSLを使わない手もありますが、それでいいのかという話です。&lt;/p&gt;

&lt;p&gt;それでも&amp;rdquo;terraformコマンドに操作を統一したい&amp;rdquo;など、どうしても使いたい人は、ARMテンプレート実行部は管理も実行も分離した方がいいと思います。&lt;/p&gt;

&lt;h2 id=&#34;2-リソース競合したら依存関係を定義する:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;2. リソース競合したら依存関係を定義する&lt;/h2&gt;

&lt;p&gt;Terraformはリソース間の依存関係を明示する必要がありません。ですが、行き届かないこともあります。その場合は&lt;a href=&#34;https://www.terraform.io/intro/getting-started/dependencies.html&#34;&gt;&amp;ldquo;depends_on&amp;rdquo;&lt;/a&gt;で明示してあげましょう。&lt;/p&gt;

&lt;p&gt;例えば、&lt;a href=&#34;http://torumakabe.github.io/post/azure_terraform_429_workaround/&#34;&gt;以前のエントリ&lt;/a&gt;で紹介した下記の問題。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error applying plan:

1 error(s) occurred:
azurerm_virtual_network.vnet1: autorest:DoErrorUnlessStatusCode 429 PUT https://management.azure.com/subscriptions/my_subscription_id/resourceGroups/mygroup/providers/Microsoft.Network/virtualnetworks/vnet1?api-version=2015-06-15 failed with 429


Cannot proceed with operation since resource /subscriptions/GUID/resourceGroups/xxxx/providers/Microsoft.Network/networkSecurityGroups/yyy allocated to resource /subscriptions/GUID/resourceGroups/***/providers/Microsoft.Network/virtualNetworks/yyy is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is PutSecurityRuleOperation. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTTPステータスコード429(Too many requests)が返ってきているのでわかりにくいですが、実態はセキュリティーグループリソースの取り合いです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;サブネットリソース作成側: サブネットを新規作成し、セキュリティーグループを紐付けたい&lt;/li&gt;
&lt;li&gt;セキュリティーグループルール作成側: ルールをセキュリティーグループに登録したい(更新処理)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;この2つが並行してセキュリティーグループを取り合うので、高確率でエラーになります。セキュリティーグループルールはリソースの新規作成でなく、セキュリティーグループの更新処理であるため「リソースを&lt;strong&gt;作成したら/存在したら&lt;/strong&gt;次にすすむ」というTerraformのグラフでうまく表現できないようです。&lt;/p&gt;

&lt;p&gt;そのような場合、明示的に依存関係を&amp;rdquo;depends_on&amp;rdquo;で定義します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Create a frontend subnet
# &amp;quot;depends_on&amp;quot; arg is a workaround to avoid conflict with updating NSG rules 
resource &amp;quot;azurerm_subnet&amp;quot; &amp;quot;frontend&amp;quot; {
    name = &amp;quot;frontend&amp;quot;
    resource_group_name = &amp;quot;${var.resource_group_name}&amp;quot;
    virtual_network_name = &amp;quot;${azurerm_virtual_network.vnet1.name}&amp;quot;
    address_prefix = &amp;quot;${var.vnet1_frontend_address_prefix}&amp;quot;
    network_security_group_id = &amp;quot;${azurerm_network_security_group.frontend.id}&amp;quot;
    depends_on = [
        &amp;quot;azurerm_network_security_rule.fe_web80&amp;quot;,
        &amp;quot;azurerm_network_security_rule.fe_web443&amp;quot;,
        &amp;quot;azurerm_network_security_rule.fe_ssh&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでサブネット作成処理は、セキュリティーグループルール登録完了まで、作成処理開始を待ちます。美しくないですが、当面の回避策です。&lt;/p&gt;

&lt;h2 id=&#34;3-公開鍵認証ssh指定でエラーが出ても驚かない:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;3. 公開鍵認証SSH指定でエラーが出ても驚かない&lt;/h2&gt;

&lt;p&gt;TerraformはLinux VMの定義で、公開鍵認証SSHを指定できます。こんな感じで。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;os_profile_linux_config {
    disable_password_authentication = true
    ssh_keys {
        path = &amp;quot;/home/${var.adminuser}/.ssh/authorized_keys&amp;quot;
        key_data = &amp;quot;${file(&amp;quot;/Users/you/.ssh/yourkey.pem&amp;quot;)}&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;が、エラーが返ってきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[DEBUG] Error setting Virtual Machine Storage OS Profile Linux Configuration: &amp;amp;errors.errorString{s:&amp;quot;Invalid address to set: []string{\&amp;quot;os_profile_linux_config\&amp;quot;, \&amp;quot;12345678\&amp;quot;, \&amp;quot;ssh_keys\&amp;quot;}&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;残念ながら、Terraformが使っているAzure SDK(Golang)のバグです。&lt;/p&gt;

&lt;p&gt;妥当性チェックのエラーで、実際にはキーの登録はできているようです。私は何度か試行してすべて公開鍵SSHログインに成功しています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hashicorp/terraform/issues/5793&#34;&gt;Issueとして認識&lt;/a&gt;されていますので、修正を待ちましょう。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure &amp; Terraform エラーコード429の対処法</title>
      <link>http://torumakabe.github.io/post/azure_terraform_429_workaround/</link>
      <pubDate>Wed, 23 Mar 2016 13:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_terraform_429_workaround/</guid>
      <description>

&lt;h2 id=&#34;terraformer増加に備えて:41e5563e03314499a86e746f2fbd113b&#34;&gt;Terraformer増加に備えて&lt;/h2&gt;

&lt;p&gt;2016/3/21にリリースされたTerraform v0.6.14で、Azure Resource Manager ProviderのリソースにVMとテンプレートデプロイが&lt;a href=&#34;https://github.com/hashicorp/terraform/blob/v0.6.14/CHANGELOG.md&#34;&gt;追加&lt;/a&gt;されました。待っていた人も多いのではないでしょうか。&lt;/p&gt;

&lt;p&gt;追って&lt;a href=&#34;https://www.hashicorp.com/partners.html#sipart&#34;&gt;Hashicorp認定パートナー&lt;/a&gt;のクリエーションラインさんから導入・サポートサービスが&lt;a href=&#34;http://www.creationline.com/lab/13268&#34;&gt;アナウンス&lt;/a&gt;されましたし、今後AzureをTerraformでコントロールしようという需要は増えそうです。&lt;/p&gt;

&lt;h2 id=&#34;エラーコード429:41e5563e03314499a86e746f2fbd113b&#34;&gt;エラーコード429&lt;/h2&gt;

&lt;p&gt;さて、TerraformでAzureをいじっていると、下記のようなエラーに出くわすことがあります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error applying plan:

1 error(s) occurred:
azurerm_virtual_network.vnet1: autorest:DoErrorUnlessStatusCode 429 PUT https://management.azure.com/subscriptions/my_subscription_id/resourceGroups/mygroup/providers/Microsoft.Network/virtualnetworks/vnet1?api-version=2015-06-15 failed with 429
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;autorestがステータスコード429をキャッチしました。&lt;a href=&#34;https://tools.ietf.org/html/rfc6585#section-4&#34;&gt;RFC上で429は&lt;/a&gt;&amp;ldquo;Too many requests&amp;rdquo;です。何かが多すぎたようです。&lt;/p&gt;

&lt;h2 id=&#34;対処法:41e5563e03314499a86e746f2fbd113b&#34;&gt;対処法&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;もう一度applyしてください&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;冪等性最高。冪等性なんていらない、という人もいますが、こういうときはありがたい。Terraformが作成に失敗したリソースのみ再作成します。&lt;/p&gt;

&lt;h2 id=&#34;背景:41e5563e03314499a86e746f2fbd113b&#34;&gt;背景&lt;/h2&gt;

&lt;p&gt;エラーになった背景ですが、2つの可能性があります。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;APIリクエスト数上限に達した&lt;/li&gt;
&lt;li&gt;リソースの作成や更新に時間がかかっており、Azure側で処理を中断した&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-apiリクエスト数上限に達した:41e5563e03314499a86e746f2fbd113b&#34;&gt;1. APIリクエスト数上限に達した&lt;/h3&gt;

&lt;p&gt;Azure Resource Manager APIには時間当たりのリクエスト数制限があります。読み取り 15,000/時、書き込み1,200/時です。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/azure-subscription-service-limits/&#34;&gt;Azure サブスクリプションとサービスの制限、クォータ、制約&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Terraformは扱うリソースごとにAPIをコールするので、数が多い環境で作って壊してをやると、この上限にひっかかる可能性があります。&lt;/p&gt;

&lt;p&gt;長期的な対処として、Terraformにリトライ/Exponential Backoffロジックなどを実装してもらうのがいいのか、このままユーザ側でシンプルにリトライすべきか、悩ましいところです。&lt;/p&gt;

&lt;p&gt;ひとまずプロダクトの方針は確認したいので、Issueに質問を&lt;a href=&#34;https://github.com/hashicorp/terraform/issues/5704&#34;&gt;あげておきました&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;2-リソースの作成や更新に時間がかかっており-azure側で処理を中断した:41e5563e03314499a86e746f2fbd113b&#34;&gt;2. リソースの作成や更新に時間がかかっており、Azure側で処理を中断した&lt;/h3&gt;

&lt;p&gt;Terraform側ではエラーコードで判断するしかありませんが、Azureの監査ログで詳細が確認できます。&lt;/p&gt;

&lt;p&gt;わたしが経験したエラーの中に、こんなものがありました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cannot proceed with operation since resource /subscriptions/GUID/resourceGroups/xxxx/providers/Microsoft.Network/networkSecurityGroups/yyy allocated to resource /subscriptions/GUID/resourceGroups/***/providers/Microsoft.Network/virtualNetworks/yyy is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is PutSecurityRuleOperation. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Too many requestsというよりは、リソースのアップデートが終わってないので先に進めない、という内容です。&lt;/p&gt;

&lt;p&gt;Too many requestsをどう解釈するかにもよりますが、ちょっと混乱しますね。この問題はFeedbackとして&lt;a href=&#34;https://feedback.azure.com/forums/34192--general-feedback/suggestions/13069563-better-http-status-code-instead-of-429&#34;&gt;あがっています&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;でも安心してください。&lt;strong&gt;もう一度applyしてください&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(2016/3/25 追記) 回避策を&lt;a href=&#34;http://torumakabe.github.io/post/azure_terraform_earlyphase_tips/&#34;&gt;別エントリ&lt;/a&gt;に書きました&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>