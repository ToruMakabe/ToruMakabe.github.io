<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>re-imagine</title>
    <link>http://torumakabe.github.io/</link>
    <description>Recent content on re-imagine</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Wed, 06 Apr 2016 17:00:00 +0900</lastBuildDate>
    <atom:link href="http://torumakabe.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Azureの監査ログアラートからWebhookの流れで楽をする</title>
      <link>http://torumakabe.github.io/post/azure_auditlog_alert/</link>
      <pubDate>Wed, 06 Apr 2016 17:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_auditlog_alert/</guid>
      <description>

&lt;h2 id=&#34;監査ログからアラートを上げられるようになります:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;監査ログからアラートを上げられるようになります&lt;/h2&gt;

&lt;p&gt;Azureの監査ログからアラートを上げる機能のプレビューが&lt;a href=&#34;https://azure.microsoft.com/ja-jp/blog/new-features-for-azure-alerts-and-autoscale/&#34;&gt;はじまりました&lt;/a&gt;。これ、地味ですが便利な機能です。日々の運用に効きます。&lt;/p&gt;

&lt;h2 id=&#34;どんな風に使えるか:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;どんな風に使えるか&lt;/h2&gt;

&lt;p&gt;ルールに合致した監査ログが生成された場合、メール通知とWebhookによる自動アクションができます。可能性無限大です。&lt;/p&gt;

&lt;p&gt;たとえば、「特定のリソースグループにVMが生成された場合、そのVMに対し強制的にログ収集エージェントをインストールし、ログを集める」なんてことができます。&lt;/p&gt;

&lt;p&gt;これは「生産性を上げるため、アプリ開発チームにVMの生成は委任したい。でもセキュリティなどの観点から、ログは集めておきたい」なんてインフラ担当/Opsの課題に効きます。開発チームに「VM生成時には必ず入れてね」とお願いするのも手ですが、やはり人間は忘れる生き物ですので、自動で適用できる仕組みがあるとうれしい。&lt;/p&gt;

&lt;p&gt;これまでは監視用のVMを立てて、「新しいVMがあるかどうか定期的にチェックして、あったらエージェントを叩き込む」なんてことをしていたわけですが、もうそのVMは不要です。定期的なチェックも要りません。アラートからアクションを実現する仕組みを、Azureがマネージドサービスとして提供します。&lt;/p&gt;

&lt;h2 id=&#34;実装例:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;実装例&lt;/h2&gt;

&lt;p&gt;例としてこんな仕組みを作ってみましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;西日本リージョンのリソースグループ&amp;rdquo;dev&amp;rdquo;にVMが作成されたら、自動的にメール通知とWebhookを実行&lt;/li&gt;
&lt;li&gt;WebhookでAzure AutomationのRunbook Jobを呼び出し、OMS(Operations Management Suite)エージェントを該当のVMにインストール、接続先OMSを設定する&lt;/li&gt;
&lt;li&gt;OMSでログ分析&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;準備:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;準備&lt;/h2&gt;

&lt;p&gt;以下の準備ができているか確認します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Azure Automation向けADアプリ、サービスプリンシパル作成&lt;/li&gt;
&lt;li&gt;サービスプリンシパルへのロール割り当て&lt;/li&gt;
&lt;li&gt;Azure Automationのアカウント作成&lt;/li&gt;
&lt;li&gt;Azure Automation Runbook実行時ログインに必要な証明書や資格情報などの資産登録&lt;/li&gt;
&lt;li&gt;Azure Automation Runbookで使う変数資産登録 (Runbook内でGet-AutomationVariableで取得できます。暗号化もできますし、コードに含めるべきでない情報は、登録しましょう)&lt;/li&gt;
&lt;li&gt;OMSワークスペースの作成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;もしAutomationまわりの作業がはじめてであれば、下記記事を参考にしてください。とてもわかりやすい。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://qiita.com/sengoku/items/1c3994ac8a2f0f0e88c5&#34;&gt;勤務時間中だけ仮想マシンを動かす（スケジュールによる自動起動・停止）&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;azure-automation側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;Azure Automation側の仕掛け&lt;/h2&gt;

&lt;p&gt;先にAutomationのRunbookを作ります。アラート設定をする際、RunbookのWebhook URLが必要になるので。&lt;/p&gt;

&lt;p&gt;ちなみにわたしは証明書を使ってログインしています。資格情報を使う場合はログインまわりのコードを読み替えてください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;param ( 
    [object]$WebhookData          
)

if ($WebhookData -ne $null) {  
    $WebhookName    =   $WebhookData.WebhookName
    $WebhookBody    =   $WebhookData.RequestBody  
    $WebhookBody = (ConvertFrom-Json -InputObject $WebhookBody)

    $AlertContext = [object]$WebhookBody.context

    $SPAppID = Get-AutomationVariable -Name &#39;SPAppID&#39;
    $Tenant = Get-AutomationVariable -Name &#39;TenantID&#39;
    $OMSWorkspaceId = Get-AutomationVariable -Name &#39;OMSWorkspaceId&#39;
    $OMSWorkspaceKey = Get-AutomationVariable -Name &#39;OMSWorkspaceKey&#39;
    $CertificationName = Get-AutomationVariable -Name &#39;CertificationName&#39;
    $Certificate = Get-AutomationCertificate -Name $CertificationName
    $CertThumbprint = ($Certificate.Thumbprint).ToString()    

    $null = Login-AzureRmAccount -ServicePrincipal -TenantId $Tenant -CertificateThumbprint $CertThumbprint -ApplicationId $SPAppID   

    $resourceObj = Get-AzureRmResource -ResourceId $AlertContext.resourceId
    $VM = Get-AzureRmVM -Name $resourceObj.Name -ResourceGroupName $resourceObj.ResourceGroupName

    $Settings = @{&amp;quot;workspaceId&amp;quot; = &amp;quot;$OMSWorkspaceId&amp;quot;}
    $ProtectedSettings = @{&amp;quot;workspaceKey&amp;quot; = &amp;quot;$OMSWorkspaceKey&amp;quot;}

    if ($VM.StorageProfile.OsDisk.OsType -eq &amp;quot;Linux&amp;quot;) {  
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &amp;quot;OmsAgentForLinux&amp;quot; -Publisher &amp;quot;Microsoft.EnterpriseCloud.Monitoring&amp;quot; -ExtensionType &amp;quot;OmsAgentForLinux&amp;quot; -TypeHandlerVersion &amp;quot;1.0&amp;quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    elseif ($VM.StorageProfile.OsDisk.OsType -eq &amp;quot;Windows&amp;quot;)
    {
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &amp;quot;MicrosoftMonitoringAgent&amp;quot; -Publisher &amp;quot;Microsoft.EnterpriseCloud.Monitoring&amp;quot; -ExtensionType &amp;quot;MicrosoftMonitoringAgent&amp;quot; -TypeHandlerVersion &amp;quot;1.0&amp;quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    else
    {
        Write-Error &amp;quot;Unknown OS Type.&amp;quot;
    }
}
else 
{
    Write-Error &amp;quot;This runbook is meant to only be started from a webhook.&amp;quot; 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;azure-監査ログアラート側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452&#34;&gt;Azure 監査ログアラート側の仕掛け&lt;/h3&gt;

&lt;p&gt;Powershellでアラートルールを作ります。実行アカウントの権限に気をつけてください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\work&amp;gt; $actionEmail = New-AzureRmAlertRuleEmail -CustomEmail yourname@example.com

PS C:\work&amp;gt; $actionWebhook = New-AzureRmAlertRuleWebhook -ServiceUri https://abcdefgh.azure-automation.net/webhooks?token=your_token

PS C:\work&amp;gt; Add-AzureRmLogAlertRule -Name createdVM -Location &amp;quot;Japan West&amp;quot; -ResourceGroup dev -OperationName Microsoft.Compute/virtualMachines/write -Status Succeeded  -SubStatus Created -TargetResourceGroup dev -Actions $actionEmail,$actionWebhook
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上。これで&amp;rdquo;dev&amp;rdquo;リソースグループにVMが作られた場合、自動でOMSエージェントがインストールされ、ログ収集がはじまります。&lt;/p&gt;

&lt;p&gt;なお、メールも飛んできますので、うっとおしくなったらメール通知はアクションから外すか、ルールでさばいてくださいね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>書評: Site Reliability Engineering</title>
      <link>http://torumakabe.github.io/post/bookreview_site_reliability_engineering/</link>
      <pubDate>Sun, 27 Mar 2016 20:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/bookreview_site_reliability_engineering/</guid>
      <description>

&lt;h2 id=&#34;英語だけどぜひ読んでほしい:85f39e44bed874d49c5c215a7c1e75f5&#34;&gt;英語だけどぜひ読んでほしい&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.amazon.co.jp/Site-Reliability-Engineering-Production-Systems-ebook/dp/B01DCPXKZ6/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;amp;qid=1459069692&amp;amp;sr=8-1&#34;&gt;Site Reliability Engineering: How Google Runs Production Systems&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;参考になったのでご紹介。Googleのインフラ/Ops系技術チームの働き方や考え方を題材にした本です。GoogleのSREについては断片的に知っていたのですが、まとめて読むと違いますね。背景やストーリーがあって、理解しやすいです。&lt;/p&gt;

&lt;p&gt;共感できるネタがどんどん繰り出されるので、一気読みしました。読み込みが浅いところもあったので、改めて読む予定。&lt;/p&gt;

&lt;p&gt;以下、印象に残ったこと。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Site Reliability Engineering teamは、インフラ/Ops担当であるが、Unix内部やネットワークなどインフラの知見を持つソフトウェアエンジニアの集団。自分たちのオペレーションを効率的に、迅速に、確実にするために、コードを書く。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;インシデント対応、問い合わせ対応、手作業は仕事の50%に収まるように調整する。残りの時間は自分たちの仕事をより良く、楽にするために、コードを書く。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;日々のリアクティブな活動に忙殺されるインフラ/Ops担当はどうしても減点評価になりがちだが、仕事の半分がプロアクティブな活動であり、成果を加点評価できる。昇格、昇給の根拠になりやすい。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;アプリ/製品チームとSREチームは&amp;rdquo;Error Budget&amp;rdquo;を定義、共有する。これは四半期ごとに定義される、サービスレベル目標である。ユーザがサービスを使えなくなると、その時間が、このError Budgetから取り崩されていく。Budgetが残り少なくなると、リスクを伴うデプロイなどは控える。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;インフラ/Ops担当は「サービスを少しでもダウンさせたら悪」となりがちだが、サービスごとにアプリ/製品チームとSREチームがError Budgetを共有することで、利害関係を一致できる。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Error Budgetの大きさはサービスごとに異なり、定義は製品チームの責任。当然Error Budgetが少ない = サービスレベルが高い = コストがかかる ので、製品チームはいたずらに高いサービスレベルを定義しない。Google Apps for WorkとYoutubeのError Budgetは異なる。Appsはサービスレベル重視であり、Youtubeは迅速で頻繁な機能追加を重視する。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;SLA違反など、重大な障害では&amp;rdquo;Postmortem(過激だが死体解剖の意)&amp;ldquo;を作成し、失敗から学ぶ。客観的に、建設的に。誰かや何かを責めるためにやるわけではない。マサカリ投げない。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;他の産業から学ぶ。製造業のビジネス継続プラン、国防のシミュレーションや演習、通信業の輻輳対策など。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;もう一回読んだら、また違う発見があるんじゃないかと。&lt;/p&gt;

&lt;h2 id=&#34;自分ごととして読みたい:85f39e44bed874d49c5c215a7c1e75f5&#34;&gt;自分ごととして読みたい&lt;/h2&gt;

&lt;p&gt;今後の働き方や所属組織に行き詰まりを感じているインフラ/Ops技術者に、参考になるネタが多いと思います。&lt;/p&gt;

&lt;p&gt;DevOpsムーブメントが来るか来ないかという今、Opsとしてのスタンスを考え直すのにも、いいかもしれません。&lt;/p&gt;

&lt;p&gt;もちろん、Googleの圧倒的物量、成長スピードゆえのミッションと働き方である事は否定しません。でも、自分とは無関係、と無視するにはもったいないです。&lt;/p&gt;

&lt;p&gt;なお、このSREチーム、できてから10年以上たっているそうです。それだけ持続できるということは、そこに何か本質的な価値があるのではないでしょうか。&lt;/p&gt;

&lt;p&gt;オススメです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure &amp; Terraform Tips (ARM対応 2016春版)</title>
      <link>http://torumakabe.github.io/post/azure_terraform_earlyphase_tips/</link>
      <pubDate>Fri, 25 Mar 2016 22:50:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_terraform_earlyphase_tips/</guid>
      <description>

&lt;h2 id=&#34;俺の屍を越えていけ:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;俺の屍を越えていけ&lt;/h2&gt;

&lt;p&gt;今週リリースされたTerraform v0.6.14で、Azure Resource Manager ProviderのリソースにVMとテンプレートデプロイが&lt;a href=&#34;https://github.com/hashicorp/terraform/blob/v0.6.14/CHANGELOG.md&#34;&gt;追加&lt;/a&gt;されました。この週末お楽しみ、という人も多いかもしれません。&lt;/p&gt;

&lt;p&gt;小生、v0.6.14以前から触っていたこともあり、土地勘があります。そこで現時点でのTipsをいくつかご紹介します。&lt;/p&gt;

&lt;h2 id=&#34;この3つは触る前から意識しよう:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;この3つは触る前から意識しよう&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;ARMテンプレートリソースは分離して使う&lt;/li&gt;
&lt;li&gt;リソース競合したら依存関係を定義する&lt;/li&gt;
&lt;li&gt;公開鍵認証SSH指定でエラーが出ても驚かない&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;1-armテンプレートリソースは分離して使う:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;1. ARMテンプレートリソースは分離して使う&lt;/h2&gt;

&lt;p&gt;v0.6.14で、リソース&lt;a href=&#34;https://www.terraform.io/docs/providers/azurerm/r/template_deployment.html&#34;&gt;&amp;ldquo;azurerm_template_deployment&amp;rdquo;&lt;/a&gt;が追加されました。なんとARMテンプレートを、Terraformの定義ファイル内にインラインで書けます。&lt;/p&gt;

&lt;p&gt;でも、現時点の実装では、おすすめしません。&lt;/p&gt;

&lt;h3 id=&#34;armテンプレートのデプロイ機能とterraformで作ったリソースが不整合を起こす:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;ARMテンプレートのデプロイ機能とTerraformで作ったリソースが不整合を起こす&lt;/h3&gt;

&lt;p&gt;避けるべきなのは&amp;rdquo;Complete(完全)&amp;ldquo;モードでのARMテンプレートデプロイです。なぜなら完全モードでは、ARM リソースマネージャーは次の動きをするからです。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-template-deploy/&#34;&gt;リソース グループに存在するが、テンプレートに指定されていないリソースを削除します&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;つまり、ARMテンプレートで作ったリソース以外、Terraform担当部分を消しにいきます。恐怖! デプロイ vs デプロイ!!。リソースグループを分ければ回避できますが、リスク高めです。&lt;/p&gt;

&lt;h3 id=&#34;タイムアウトしがち:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;タイムアウトしがち&lt;/h3&gt;

&lt;p&gt;それでもTerraformの外でARMテンプレートデプロイは継続します。成功すれば結果オーライですが&amp;hellip;Terraform上はエラーが残ります。「ああそれ無視していいよ」ではあるのですが、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E5%89%B2%E3%82%8C%E7%AA%93%E7%90%86%E8%AB%96&#34;&gt;割れ窓理論&lt;/a&gt;的によろしくないです。&lt;/p&gt;

&lt;h3 id=&#34;せっかくのリソースグラフを活用できない:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;せっかくのリソースグラフを活用できない&lt;/h3&gt;

&lt;p&gt;Terraformはグラフ構造で賢くリソース間の依存関係を管理し、整合性を維持しています。サクサク apply &amp;amp; destroyできるのもそれのおかげです。ARMテンプレートでデプロイしたリソースはそれに入れられないので、もったいないです。&lt;/p&gt;

&lt;h3 id=&#34;読みづらい:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;読みづらい&lt;/h3&gt;

&lt;p&gt;Terraform DSLにJSONが混ざって読みにくいです。Terraform DSLを使わない手もありますが、それでいいのかという話です。&lt;/p&gt;

&lt;p&gt;それでも&amp;rdquo;terraformコマンドに操作を統一したい&amp;rdquo;など、どうしても使いたい人は、ARMテンプレート実行部は管理も実行も分離した方がいいと思います。&lt;/p&gt;

&lt;h2 id=&#34;2-リソース競合したら依存関係を定義する:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;2. リソース競合したら依存関係を定義する&lt;/h2&gt;

&lt;p&gt;Terraformはリソース間の依存関係を明示する必要がありません。ですが、行き届かないこともあります。その場合は&lt;a href=&#34;https://www.terraform.io/intro/getting-started/dependencies.html&#34;&gt;&amp;ldquo;depends_on&amp;rdquo;&lt;/a&gt;で明示してあげましょう。&lt;/p&gt;

&lt;p&gt;例えば、&lt;a href=&#34;http://torumakabe.github.io/post/azure_terraform_429_workaround/&#34;&gt;以前のエントリ&lt;/a&gt;で紹介した下記の問題。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error applying plan:

1 error(s) occurred:
azurerm_virtual_network.vnet1: autorest:DoErrorUnlessStatusCode 429 PUT https://management.azure.com/subscriptions/my_subscription_id/resourceGroups/mygroup/providers/Microsoft.Network/virtualnetworks/vnet1?api-version=2015-06-15 failed with 429


Cannot proceed with operation since resource /subscriptions/GUID/resourceGroups/xxxx/providers/Microsoft.Network/networkSecurityGroups/yyy allocated to resource /subscriptions/GUID/resourceGroups/***/providers/Microsoft.Network/virtualNetworks/yyy is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is PutSecurityRuleOperation. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTTPステータスコード429(Too many requests)が返ってきているのでわかりにくいですが、実態はセキュリティーグループリソースの取り合いです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;サブネットリソース作成側: サブネットを新規作成し、セキュリティーグループを紐付けたい&lt;/li&gt;
&lt;li&gt;セキュリティーグループルール作成側: ルールをセキュリティーグループに登録したい(更新処理)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;この2つが並行してセキュリティーグループを取り合うので、高確率でエラーになります。セキュリティーグループルールはリソースの新規作成でなく、セキュリティーグループの更新処理であるため「リソースを&lt;strong&gt;作成したら/存在したら&lt;/strong&gt;次にすすむ」というTerraformのグラフでうまく表現できないようです。&lt;/p&gt;

&lt;p&gt;そのような場合、明示的に依存関係を&amp;rdquo;depends_on&amp;rdquo;で定義します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Create a frontend subnet
# &amp;quot;depends_on&amp;quot; arg is a workaround to avoid conflict with updating NSG rules 
resource &amp;quot;azurerm_subnet&amp;quot; &amp;quot;frontend&amp;quot; {
    name = &amp;quot;frontend&amp;quot;
    resource_group_name = &amp;quot;${var.resource_group_name}&amp;quot;
    virtual_network_name = &amp;quot;${azurerm_virtual_network.vnet1.name}&amp;quot;
    address_prefix = &amp;quot;${var.vnet1_frontend_address_prefix}&amp;quot;
    network_security_group_id = &amp;quot;${azurerm_network_security_group.frontend.id}&amp;quot;
    depends_on = [
        &amp;quot;azurerm_network_security_rule.fe_web80&amp;quot;,
        &amp;quot;azurerm_network_security_rule.fe_web443&amp;quot;,
        &amp;quot;azurerm_network_security_rule.fe_ssh&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでサブネット作成処理は、セキュリティーグループルール登録完了まで、作成処理開始を待ちます。美しくないですが、当面の回避策です。&lt;/p&gt;

&lt;h2 id=&#34;3-公開鍵認証ssh指定でエラーが出ても驚かない:9776a375b7d12db77e52b9c8d97b8677&#34;&gt;3. 公開鍵認証SSH指定でエラーが出ても驚かない&lt;/h2&gt;

&lt;p&gt;TerraformはLinux VMの定義で、公開鍵認証SSHを指定できます。こんな感じで。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;os_profile_linux_config {
    disable_password_authentication = true
    ssh_keys {
        path = &amp;quot;/home/${var.adminuser}/.ssh/authorized_keys&amp;quot;
        key_data = &amp;quot;${file(&amp;quot;/Users/you/.ssh/yourkey.pem&amp;quot;)}&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;が、エラーが返ってきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[DEBUG] Error setting Virtual Machine Storage OS Profile Linux Configuration: &amp;amp;errors.errorString{s:&amp;quot;Invalid address to set: []string{\&amp;quot;os_profile_linux_config\&amp;quot;, \&amp;quot;12345678\&amp;quot;, \&amp;quot;ssh_keys\&amp;quot;}&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;残念ながら、Terraformが使っているAzure SDK(Golang)のバグです。&lt;/p&gt;

&lt;p&gt;妥当性チェックのエラーで、実際にはキーの登録はできているようです。私は何度か試行してすべて公開鍵SSHログインに成功しています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hashicorp/terraform/issues/5793&#34;&gt;Issueとして認識&lt;/a&gt;されていますので、修正を待ちましょう。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure &amp; Terraform エラーコード429の対処法</title>
      <link>http://torumakabe.github.io/post/azure_terraform_429_workaround/</link>
      <pubDate>Wed, 23 Mar 2016 13:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_terraform_429_workaround/</guid>
      <description>

&lt;h2 id=&#34;terraformer増加に備えて:41e5563e03314499a86e746f2fbd113b&#34;&gt;Terraformer増加に備えて&lt;/h2&gt;

&lt;p&gt;2016/3/21にリリースされたTerraform v0.6.14で、Azure Resource Manager ProviderのリソースにVMとテンプレートデプロイが&lt;a href=&#34;https://github.com/hashicorp/terraform/blob/v0.6.14/CHANGELOG.md&#34;&gt;追加&lt;/a&gt;されました。待っていた人も多いのではないでしょうか。&lt;/p&gt;

&lt;p&gt;追って&lt;a href=&#34;https://www.hashicorp.com/partners.html#sipart&#34;&gt;Hashicorp認定パートナー&lt;/a&gt;のクリエーションラインさんから導入・サポートサービスが&lt;a href=&#34;http://www.creationline.com/lab/13268&#34;&gt;アナウンス&lt;/a&gt;されましたし、今後AzureをTerraformでコントロールしようという需要は増えそうです。&lt;/p&gt;

&lt;h2 id=&#34;エラーコード429:41e5563e03314499a86e746f2fbd113b&#34;&gt;エラーコード429&lt;/h2&gt;

&lt;p&gt;さて、TerraformでAzureをいじっていると、下記のようなエラーに出くわすことがあります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error applying plan:

1 error(s) occurred:
azurerm_virtual_network.vnet1: autorest:DoErrorUnlessStatusCode 429 PUT https://management.azure.com/subscriptions/my_subscription_id/resourceGroups/mygroup/providers/Microsoft.Network/virtualnetworks/vnet1?api-version=2015-06-15 failed with 429
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;autorestがステータスコード429をキャッチしました。&lt;a href=&#34;https://tools.ietf.org/html/rfc6585#section-4&#34;&gt;RFC上で429は&lt;/a&gt;&amp;ldquo;Too many requests&amp;rdquo;です。何かが多すぎたようです。&lt;/p&gt;

&lt;h2 id=&#34;対処法:41e5563e03314499a86e746f2fbd113b&#34;&gt;対処法&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;もう一度applyしてください&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;冪等性最高。冪等性なんていらない、という人もいますが、こういうときはありがたい。Terraformが作成に失敗したリソースのみ再作成します。&lt;/p&gt;

&lt;h2 id=&#34;背景:41e5563e03314499a86e746f2fbd113b&#34;&gt;背景&lt;/h2&gt;

&lt;p&gt;エラーになった背景ですが、2つの可能性があります。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;APIリクエスト数上限に達した&lt;/li&gt;
&lt;li&gt;リソースの作成や更新に時間がかかっており、Azure側で処理を中断した&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-apiリクエスト数上限に達した:41e5563e03314499a86e746f2fbd113b&#34;&gt;1. APIリクエスト数上限に達した&lt;/h3&gt;

&lt;p&gt;Azure Resource Manager APIには時間当たりのリクエスト数制限があります。読み取り 15,000/時、書き込み1,200/時です。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/azure-subscription-service-limits/&#34;&gt;Azure サブスクリプションとサービスの制限、クォータ、制約&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Terraformは扱うリソースごとにAPIをコールするので、数が多い環境で作って壊してをやると、この上限にひっかかる可能性があります。&lt;/p&gt;

&lt;p&gt;長期的な対処として、Terraformにリトライ/Exponential Backoffロジックなどを実装してもらうのがいいのか、このままユーザ側でシンプルにリトライすべきか、悩ましいところです。&lt;/p&gt;

&lt;p&gt;ひとまずプロダクトの方針は確認したいので、Issueに質問を&lt;a href=&#34;https://github.com/hashicorp/terraform/issues/5704&#34;&gt;あげておきました&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;2-リソースの作成や更新に時間がかかっており-azure側で処理を中断した:41e5563e03314499a86e746f2fbd113b&#34;&gt;2. リソースの作成や更新に時間がかかっており、Azure側で処理を中断した&lt;/h3&gt;

&lt;p&gt;Terraform側ではエラーコードで判断するしかありませんが、Azureの監査ログで詳細が確認できます。&lt;/p&gt;

&lt;p&gt;わたしが経験したエラーの中に、こんなものがありました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cannot proceed with operation since resource /subscriptions/GUID/resourceGroups/xxxx/providers/Microsoft.Network/networkSecurityGroups/yyy allocated to resource /subscriptions/GUID/resourceGroups/***/providers/Microsoft.Network/virtualNetworks/yyy is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is PutSecurityRuleOperation. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Too many requestsというよりは、リソースのアップデートが終わってないので先に進めない、という内容です。&lt;/p&gt;

&lt;p&gt;Too many requestsをどう解釈するかにもよりますが、ちょっと混乱しますね。この問題はFeedbackとして&lt;a href=&#34;https://feedback.azure.com/forums/34192--general-feedback/suggestions/13069563-better-http-status-code-instead-of-429&#34;&gt;あがっています&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;でも安心してください。&lt;strong&gt;もう一度applyしてください&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(2016/3/25 追記) 回避策を&lt;a href=&#34;http://torumakabe.github.io/post/azure_terraform_earlyphase_tips/&#34;&gt;別エントリ&lt;/a&gt;に書きました&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PackerとAnsibleでAzureのGolden Imageを作る(ARM対応)</title>
      <link>http://torumakabe.github.io/post/azure_packer_ansible_arm_sp/</link>
      <pubDate>Thu, 17 Mar 2016 23:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_packer_ansible_arm_sp/</guid>
      <description>

&lt;h2 id=&#34;いつの間に:ebce8e7176cbf58fa7a5804522b325a3&#34;&gt;いつの間に&lt;/h2&gt;

&lt;p&gt;ナイスな感じにイメージを作ってくれるPackerですが、いつの間にか&lt;a href=&#34;https://www.packer.io/docs/builders/azure.html&#34;&gt;Azure ARM対応のBuilder&lt;/a&gt;が出ておりました。0.10からかな。早く言ってください。&lt;/p&gt;

&lt;h2 id=&#34;ansible-localと組み合わせたサンプル:ebce8e7176cbf58fa7a5804522b325a3&#34;&gt;ansible_localと組み合わせたサンプル&lt;/h2&gt;

&lt;p&gt;さっそく試してそつなく動くことを確認しました。サンプルを&lt;a href=&#34;https://github.com/ToruMakabe/Packer_Azure_Sample&#34;&gt;Githubにあげておきます&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;手の込んだ設定もできるように、Provisonerにansible_localを使うサンプルで。&lt;/p&gt;

&lt;h3 id=&#34;前準備:ebce8e7176cbf58fa7a5804522b325a3&#34;&gt;前準備&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;リソースグループとストレージアカウントを作っておいてください。そこにイメージが格納されます。&lt;/li&gt;
&lt;li&gt;認証情報の類は外だしします。builder/variables.sample.jsonを参考にしてください。&lt;/li&gt;
&lt;li&gt;Packerの構成ファイルはOSに合わせて書きます。サンプルのbuilder/ubuntu.jsonはubuntuの例です。

&lt;ul&gt;
&lt;li&gt;Azure ARM BuilderはまだWindowsに対応していません。開発中とのこと。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ansibleはapache2をインストール、サービスEnableするサンプルにしました。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;サンプル:ebce8e7176cbf58fa7a5804522b325a3&#34;&gt;サンプル&lt;/h3&gt;

&lt;p&gt;ubuntu.jsonはこんな感じです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;client_id&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;client_secret&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;resource_group&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;storage_account&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;subscription_id&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;tenant_id&amp;quot;: &amp;quot;&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;azure-arm&amp;quot;,

    &amp;quot;client_id&amp;quot;: &amp;quot;{{user `client_id`}}&amp;quot;,
    &amp;quot;client_secret&amp;quot;: &amp;quot;{{user `client_secret`}}&amp;quot;,
    &amp;quot;resource_group_name&amp;quot;: &amp;quot;{{user `resource_group`}}&amp;quot;,
    &amp;quot;storage_account&amp;quot;: &amp;quot;{{user `storage_account`}}&amp;quot;,
    &amp;quot;subscription_id&amp;quot;: &amp;quot;{{user `subscription_id`}}&amp;quot;,
    &amp;quot;tenant_id&amp;quot;: &amp;quot;{{user `tenant_id`}}&amp;quot;,

    &amp;quot;capture_container_name&amp;quot;: &amp;quot;images&amp;quot;,
    &amp;quot;capture_name_prefix&amp;quot;: &amp;quot;packer&amp;quot;,

    &amp;quot;image_publisher&amp;quot;: &amp;quot;Canonical&amp;quot;,
    &amp;quot;image_offer&amp;quot;: &amp;quot;UbuntuServer&amp;quot;,
    &amp;quot;image_sku&amp;quot;: &amp;quot;14.04.3-LTS&amp;quot;,

    &amp;quot;location&amp;quot;: &amp;quot;Japan West&amp;quot;,
    &amp;quot;vm_size&amp;quot;: &amp;quot;Standard_D1&amp;quot;
  }],
  &amp;quot;provisioners&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
      &amp;quot;scripts&amp;quot;: [
        &amp;quot;../script/ubuntu/provision.sh&amp;quot;
    ]
  },
  {
    &amp;quot;type&amp;quot;: &amp;quot;ansible-local&amp;quot;,
    &amp;quot;playbook_file&amp;quot;: &amp;quot;../ansible/baseimage.yml&amp;quot;,
    &amp;quot;inventory_file&amp;quot;: &amp;quot;../ansible/hosts&amp;quot;,
    &amp;quot;role_paths&amp;quot;: [
      &amp;quot;../ansible/roles/baseimage&amp;quot;
    ]
  },
  {
    &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
      &amp;quot;scripts&amp;quot;: [
        &amp;quot;../script/ubuntu/deprovision.sh&amp;quot;
    ]
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;waagentによるde-provisionはansibleでもできるのですが、他OS対応も考えて、最後に追いshellしてます。他ファイルは&lt;a href=&#34;https://github.com/ToruMakabe/Packer_Azure_Sample&#34;&gt;Github&lt;/a&gt;でご確認を。&lt;/p&gt;

&lt;p&gt;これで手順書&amp;amp;目視&amp;amp;指差し確認でイメージ作るのを、やめられそうですね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terraform &amp; Azure デプロイ設計4原則</title>
      <link>http://torumakabe.github.io/post/azure_tf_fundamental_rules/</link>
      <pubDate>Wed, 09 Mar 2016 16:30:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_tf_fundamental_rules/</guid>
      <description>

&lt;h2 id=&#34;情報がありそうでない:d303628c574d6be5ce0911be72b7a9a0&#34;&gt;情報がありそうでない&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://torumakabe.github.io/post/azure_tf_arm_sp/&#34;&gt;以前のエントリ&lt;/a&gt;で書いたとおり、TerraformでAzureへデプロイする方式をClassicからResource Managerへ移行しているところです。&lt;/p&gt;

&lt;p&gt;今後も継続して試行錯誤するとは思うのですが、ふらふらしないように原則を作りました。この手の情報はありそうでないので、参考になればと思いこのエントリを書いています。&lt;/p&gt;

&lt;p&gt;なお、考え方は他のクラウドやデプロイツールでも応用できるかと。&lt;/p&gt;

&lt;h2 id=&#34;4原則:d303628c574d6be5ce0911be72b7a9a0&#34;&gt;4原則&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;セキュリティファースト&lt;/li&gt;
&lt;li&gt;手順書をなくそう&lt;/li&gt;
&lt;li&gt;分割境界にこだわりすぎない&lt;/li&gt;
&lt;li&gt;早すぎる最適化は悪&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;なお、サンプルのTerraformファイル群を、&lt;a href=&#34;https://github.com/ToruMakabe/Terraform_Azure_Sample&#34;&gt;Githubに置いて&lt;/a&gt;おきました。&lt;/p&gt;

&lt;p&gt;今後ガラガラポンする可能性は大いにありますが、現時点ではこんな構造です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├── .gitignore
├── main.tf
├── availability_set
│   ├── avset_web.tf
│   ├── avset_db.tf
│   └── variables.tf
├── network
│   ├── sg_backend.tf
│   ├── sg_frontend.tf
│   ├── variables.tf
│   └── vnets.tf
├── storage
│   ├── storage_backend.tf
│   ├── storage_frontend.tf
│   └── variables.tf
└── terraform.tfvars
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Availability Setに対するVMのデプロイはTerraformの外でやっています。まだTerraformのAzure RM Providerにない、ということもありますが、VMの増減はアドホックだったり、別ツールを使いたいケースが多いので。&lt;/p&gt;

&lt;h2 id=&#34;1-セキュリティファースト:d303628c574d6be5ce0911be72b7a9a0&#34;&gt;1. セキュリティファースト&lt;/h2&gt;

&lt;p&gt;セキュリティはデザイン時に考慮すべき時代です。機密情報が漏れないように、また、身内がうっかりリソースを壊して泣かないようにしましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;認証情報は変数指定し、設定ファイルから読み込む&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;サブスクリプションIDやOAuth Client ID/Secretなどを、リソースを作るtfファイルに書かない&lt;/li&gt;
&lt;li&gt;terraform.tfvarsなどにまとめて書く&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;認証情報や現物情報が入ったファイルはバージョン管理ツールから除外する&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Gitなら.gitignoreに指定する&lt;/li&gt;
&lt;li&gt;.tfstateなど現物情報(Azure上のIDなど)が入る結果ファイルも除外

&lt;ul&gt;
&lt;li&gt;チームで使う場合はファイルではなく、Consulなどのリモートバックエンドを使うと思いますが、念のため&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RBACで必要最小限の権限を付与する&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Terraformの外の話ですが、サービスプリンシパルを作る時には意識しましょう&lt;/li&gt;
&lt;li&gt;身内がリソースをうっかり壊したら、それは管理者の責任です&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ネットワークセキュリティグループはサブネットに指定しておく&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;個々のVMの管理者に任せず、サブネットで絞っておきましょう

&lt;ul&gt;
&lt;li&gt;VMはアドホックに作られるケースが多く、ルーズになりがちです&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;サンプルではフロントエンドとバックエンドサブネットそれぞれにセキュリティグループを指定しています

&lt;ul&gt;
&lt;li&gt;フロントの受信はPort 80、443、22を許可 (できれば22はソースIP指定)&lt;/li&gt;
&lt;li&gt;バックの受信はフロントサブネットからのみ許可 (Internetからの通信を deny all)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-手順書をなくそう:d303628c574d6be5ce0911be72b7a9a0&#34;&gt;2. 手順書をなくそう&lt;/h2&gt;

&lt;p&gt;どうせなら手順書を無くす心意気でやりましょう。Infrastructure as Codeのメリットのひとつです。コードで手順を語りましょう。わかりやすさ重視です。&lt;/p&gt;

&lt;p&gt;ポリシーや使い方、前提条件をリポジトリのREADMEに書いておけばOK、あとはコードで語る。という世界を目指したいものです。&lt;/p&gt;

&lt;h2 id=&#34;3-分割境界にこだわりすぎない:d303628c574d6be5ce0911be72b7a9a0&#34;&gt;3. 分割境界にこだわりすぎない&lt;/h2&gt;

&lt;p&gt;TerraformのModuleをはじめ、最近のデプロイツールはリソースや処理単位をグルーピングできます。ここがアーキテクトの腕の見せ所です。安易に「ベストプラクティス教えろや」という人は残念ながら残念です。大事なことなので2回言いました。&lt;/p&gt;

&lt;p&gt;グルーピング、分割する目的は、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;main.tfの肥大化を防止し、コードの見通しを良くする&lt;/li&gt;
&lt;li&gt;再利用しやすくする&lt;/li&gt;
&lt;li&gt;責任範囲を明確化し、オーナー意識を醸成する&lt;/li&gt;
&lt;li&gt;権限とコードを一致させる&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;などが挙げられます。規模が小さく関わる人が少ないうちは無理して分割する必要はないですが、大きくなってくるとメリットがあります。&lt;/p&gt;

&lt;p&gt;以下が分割単位、境界ポリシーの例です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;リソースタイプで分割する&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;サンプルはその例

&lt;ul&gt;
&lt;li&gt;ネットワーク、ストレージ、VM Availability Setで分割&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;直観的&lt;/li&gt;
&lt;li&gt;デプロイに関わる人数が少ない間はこれがおすすめ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;組織単位で分割する&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%A1%E3%83%AB%E3%83%B4%E3%82%A3%E3%83%B3%E3%83%BB%E3%82%B3%E3%83%B3%E3%82%A6%E3%82%A7%E3%82%A4&#34;&gt;コンウェイの法則&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;リソースタイプ = 組織 という場合もある

&lt;ul&gt;
&lt;li&gt;ネットワーク管理者が別グループ、など&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;地理的に分割する&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;リージョンやロケーションで分割&lt;/li&gt;
&lt;li&gt;リソースタイプと組み合わせる手もある

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Network_JapanEast&amp;rdquo;など&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;静的なリソースと動的なリソースを分ける&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;変化の頻度で分ける

&lt;ul&gt;
&lt;li&gt;ネットワークが頻繁に変わることはまれ&lt;/li&gt;
&lt;li&gt;VMは増減が激しい&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;動的なリソースは対象から外す、別手段とする手も&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;スカッとしませんが、ひとつのポリシーにこだわらず、複数組み合わせてもいいと思います。そんな世界に僕らは生きています。&lt;/p&gt;

&lt;h2 id=&#34;4-早すぎる最適化は悪:d303628c574d6be5ce0911be72b7a9a0&#34;&gt;4. 早すぎる最適化は悪&lt;/h2&gt;

&lt;p&gt;最適化できる人 = その道のエキスパート です。使いはじめたばかりの段階では、最適化とか無理。また、システムの外部環境や制約がはじめから決まっていることは、まれです。&lt;/p&gt;

&lt;p&gt;なので、はじめから「最強の構成」を目指さないほうがいいでしょう。特に分割方針。きっとすぐに変えたくなります。&lt;/p&gt;

&lt;p&gt;ひとつのmain.tfで動かしながら、まずTerraformやAzureの仕様や挙動を理解しましょう。そして、慣れてきて、システムの外部環境や制約が見えてきた時点で分割方針を決めてもいいのではないか、と思います。&lt;/p&gt;

&lt;p&gt;そして、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;リファクタリングできるなら、する&lt;/li&gt;
&lt;li&gt;リファクタリングできなくても、理解の上で維持し機会を待つ、または、次の機会に活かす&lt;/li&gt;
&lt;li&gt;はじめに作った人へマサカリを投げない&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;完璧を求めずにいきましょう。&lt;/p&gt;

&lt;p&gt;でも、しつこいですが、セキュリティだけは、はじめから意識してくださいね。Security by design。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TerraformをAzure ARMで使う時の認証</title>
      <link>http://torumakabe.github.io/post/azure_tf_arm_sp/</link>
      <pubDate>Sat, 27 Feb 2016 12:30:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_tf_arm_sp/</guid>
      <description>

&lt;h2 id=&#34;高まってまいりました:dfc3556fff242cb82e1ca9532877c49b&#34;&gt;高まってまいりました&lt;/h2&gt;

&lt;p&gt;全国10,000人のTerraformファンのみなさま、こんにちは。applyしてますか。&lt;/p&gt;

&lt;p&gt;Terraformのマイナーバージョンアップのたびに、&lt;a href=&#34;https://www.terraform.io/docs/providers/azurerm/index.html&#34;&gt;Azure Resource Manager Providerのリソース&lt;/a&gt;が追加されているので、ぼちぼちClassic(Service Management)からの移行を考えよう、という人もいるのでは。VMリソースが追加されたら、いよいよ、ですかね。&lt;/p&gt;

&lt;p&gt;そこで、Classicとは認証方式が変わっているので、ご注意を、という話です。&lt;/p&gt;

&lt;h2 id=&#34;client-id-client-secret-って何よ:dfc3556fff242cb82e1ca9532877c49b&#34;&gt;client_id/client_secret って何よ&lt;/h2&gt;

&lt;p&gt;以下がARM向けのProvider設定です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Configure the Azure Resource Manager Provider
provider &amp;quot;azurerm&amp;quot; {
  subscription_id = &amp;quot;...&amp;quot;
  client_id       = &amp;quot;...&amp;quot;
  client_secret   = &amp;quot;...&amp;quot;
  tenant_id       = &amp;quot;...&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;subscription_idは、いつものあれ。tenant_idは普段使わないけどどこかで見た気がする。でも、&lt;strong&gt;client_id/client_secret って何よ&lt;/strong&gt;。ためしにポータルログインで使うID/パスワード指定したら、盛大にコケた。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;The provider needs to be configured with the credentials needed to generate OAuth tokens for the ARM API.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;おっとそういうことか。OAuth。&lt;/p&gt;

&lt;h2 id=&#34;サービスプリンシパルを使おう:dfc3556fff242cb82e1ca9532877c49b&#34;&gt;サービスプリンシパルを使おう&lt;/h2&gt;

&lt;p&gt;Terraformをアプリケーションとして登録し、そのサービスプリンシパルを作成し権限を付与すると、使えるようになります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/active-directory-application-objects/&#34;&gt;&amp;ldquo;アプリケーション オブジェクトおよびサービス プリンシパル オブジェクト&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-authenticate-service-principal/&#34;&gt;&amp;ldquo;Azure リソース マネージャーでのサービス プリンシパルの認証&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;以下、Azure CLIでの実行結果をのせておきます。WindowsでもMacでもLinuxでも手順は同じです。&lt;/p&gt;

&lt;p&gt;まずは、Terraformをアプリとして登録します。&amp;ndash;identifier-urisの存在チェックはないですが、ユニークにしなければいけません。また、&amp;ndash;passwordはclient_secretになるので、おぼえておきましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ azure ad app create --name &amp;quot;My Terraform&amp;quot; --home-page &amp;quot;http://tftest.makabe.info&amp;quot; --identifier-uris &amp;quot;http://tftest.makabe.info&amp;quot; --password pAssw0rd%
info:    Executing command ad app create
+ Creating application My Terraform
data:    AppId:                   AppId-AppId-AppId-AppId-AppId
data:    ObjectId:                AppObjId-AppObjId-AppObjId-AppObjId
data:    DisplayName:             My Terraform
data:    IdentifierUris:          0=http://tftest.makabe.info
data:    ReplyUrls:
data:    AvailableToOtherTenants:  False
data:    AppPermissions:
data:                             claimValue:  user_impersonation
data:                             description:  Allow the application to access My Terraform on behalf of the signed-in user.
data:                             directAccessGrantTypes:
data:                             displayName:  Access My Terraform
data:                             impersonationAccessGrantTypes:  impersonated=User, impersonator=Application
data:                             isDisabled:
data:                             origin:  Application
data:                             permissionId:  AppPermID-AppPermID-AppPermID-AppPermID
data:                             resourceScopeType:  Personal
data:                             userConsentDescription:  Allow the application to access My Terraform on your behalf.
data:                             userConsentDisplayName:  Access My Terraform
data:                             lang:
info:    ad app create command OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次にサービスプリンシパルを作ります。AppIdは先ほどアプリを登録した際に生成されたものです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ azure ad sp create AppId-AppId-AppId-AppId-AppId
info:    Executing command ad sp create
+ Creating service principal for application AppId-AppId-AppId-AppId-AppId
data:    Object Id:               SpObjId-SpObjId-SpObjId-SpObjId
data:    Display Name:            My Terraform
data:    Service Principal Names:
data:                             AppId-AppId-AppId-AppId-AppId
data:                             http://tftest.makabe.info
info:    ad sp create command OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サービスプリンシパルの役割を設定します。&amp;ndash;objectIdは、サービスプリンシパルのObject Idなのでご注意を。アプリのObject Idではありません。&lt;/p&gt;

&lt;p&gt;この例では、サブスクリプションのContributorとして位置づけました。権限設定は慎重に。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ azure role assignment create --objectId SpObjId-SpObjId-SpObjId-SpObjId-SpObjId -o Contributor -c /subscriptions/SubId-SubId-SubId-SubId-SubId/
info:    Executing command role assignment create
+ Finding role with specified name
/data:    RoleAssignmentId     : /subscriptions/SubId-SubId-SubId-SubId-SubId/providers/Microsoft.Authorization/roleAssignments/RoleAsId-RoleAsId-RoleAsId-RoleAsId
data:    RoleDefinitionName   : Contributor
data:    RoleDefinitionId     : RoleDefId-RoleDefId-RoleDefId-RoleDefId-RoleDefId
data:    Scope                : /subscriptions/SubId-SubId-SubId-SubId-SubId
data:    Display Name         : My Terraform
data:    SignInName           :
data:    ObjectId             : SpObjId-SpObjId-SpObjId-SpObjId-SpObjId
data:    ObjectType           : ServicePrincipal
data:
+
info:    role assignment create command OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;サービスプリンシパルまわりの設定は以上です。&lt;/p&gt;

&lt;p&gt;テナントIDを確認しておきましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ azure account list --json
[
  {
    &amp;quot;id&amp;quot;: &amp;quot;SubId-SubId-SubId-SubId-SubId&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;Your Subscription Name&amp;quot;,
    &amp;quot;user&amp;quot;: {
      &amp;quot;name&amp;quot;: &amp;quot;abc@microsoft.com&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;user&amp;quot;
    },
    &amp;quot;tenantId&amp;quot;: &amp;quot;TenantId-TenantId-TenantId-TenantId-TenantId&amp;quot;,
    &amp;quot;state&amp;quot;: &amp;quot;Enabled&amp;quot;,
    &amp;quot;isDefault&amp;quot;: true,
    &amp;quot;registeredProviders&amp;quot;: [],
    &amp;quot;environmentName&amp;quot;: &amp;quot;AzureCloud&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これでようやく.tfファイルが書けます。さくっとリソースグループでも作ってみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Configure the Azure Resource Manager Provider
provider &amp;quot;azurerm&amp;quot; {
  subscription_id = &amp;quot;SubId-SubId-SubId-SubId-SubId&amp;quot;
  client_id       = &amp;quot;AppId-AppId-AppId-AppId-AppId&amp;quot;
  client_secret   = &amp;quot;pAssw0rd%&amp;quot;
  tenant_id       = &amp;quot;TenantId-TenantId-TenantId-TenantId-TenantId&amp;quot;
}

# Create a resource group
resource &amp;quot;azurerm_resource_group&amp;quot; &amp;quot;test&amp;quot; {
    name     = &amp;quot;test&amp;quot;
    location = &amp;quot;Japan West&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;apply。もちろんplanしましたよ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform apply
azurerm_resource_group.test: Creating...
  location: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;japanwest&amp;quot;
  name:     &amp;quot;&amp;quot; =&amp;gt; &amp;quot;test&amp;quot;
azurerm_resource_group.test: Creation complete

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、ARM認証難民がうまれなくなりますように。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure DDoS対策ことはじめ</title>
      <link>http://torumakabe.github.io/post/azure_ddosprotection/</link>
      <pubDate>Mon, 15 Feb 2016 17:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_ddosprotection/</guid>
      <description>

&lt;h2 id=&#34;すこぶるfaq:4a620049922b1b54512a25b34ba773c5&#34;&gt;すこぶるFAQ&lt;/h2&gt;

&lt;p&gt;攻撃者の荒ぶり具合が高まっており、ご相談いただく機会が増えました。「どうすればいいか見当がつかない」というケースも少なくないので、DDoSに絞り、現時点で検討していただきたいことをシンプルにまとめます。&lt;/p&gt;

&lt;h2 id=&#34;公式ホワイトペーパー:4a620049922b1b54512a25b34ba773c5&#34;&gt;公式ホワイトペーパー&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://download.microsoft.com/download/C/A/3/CA3FC5C0-ECE0-4F87-BF4B-D74064A00846/AzureNetworkSecurity_v3_Feb2015.pdf&#34;&gt;Microsoft Azure Network Security Whitepaper V3&lt;/a&gt;が、現時点でのMicrosoft公式見解です。DDoS以外にもセキュリティ関連で考慮すべきことがまとまっています。おすすめです。&lt;/p&gt;

&lt;p&gt;今回はここから、DDoSに言及している部分を抜き出し意訳します。必要に応じて補足も入れます。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2016//3/4 追記 &lt;a href=&#34;http://download.microsoft.com/download/8/0/A/80ABD45E-BF1B-4235-A1C4-C8C43113CE70/AzureNetworkSecurity_v3_Mar2015.pdf&#34;&gt;日本語訳&lt;/a&gt;がありました&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-2-security-management-and-threat-defense-protecting-against-ddos:4a620049922b1b54512a25b34ba773c5&#34;&gt;2.2 Security Management and Threat Defense - Protecting against DDoS&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;To protect Azure platform services, Microsoft provides a distributed denial-of-service (DDoS) defense system that is part of Azure’s continuous monitoring process, and is continually improved through penetration-testing. Azure’s DDoS defense system is designed to not only withstand attacks from the outside, but also from other Azure tenants:&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MicrosoftはDDoSを防ぐ仕組みを提供しています。Azure外部からの攻撃はもちろんのこと、Azure内部で別テナントから攻撃されることも考慮しています。&lt;/p&gt;

&lt;h2 id=&#34;azureがやってくれること:4a620049922b1b54512a25b34ba773c5&#34;&gt;Azureがやってくれること&lt;/h2&gt;

&lt;p&gt;では、具体的に。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;1. Network-layer high volume attacks. These attacks choke network pipes and packet processing capabilities by flooding the network with packets. The Azure DDoS defense technology provides detection and mitigation techniques such as SYN cookies, rate limiting, and connection limits to help ensure that such attacks do not impact customer environments.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ネットワークレイヤで検知できる力押しは、AzureのDDoS防御システムが検知、緩和します。このホワイトペーパーのAppendixで図解されていますが、それはファイヤウォールの前段に配置され、SYN Cookieやレート制限、コネクション制限などのテクニックを使っています。&lt;/p&gt;

&lt;h2 id=&#34;お客様対応が必要なこと:4a620049922b1b54512a25b34ba773c5&#34;&gt;お客様対応が必要なこと&lt;/h2&gt;

&lt;p&gt;ですが、アプリケーションレイヤの攻撃は、AzureのDDoS防御システムだけでは防ぎきれません。お客様のアプリや通信の内容、要件まで踏み込めないからです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;2. Application-layer attacks. These attacks can be launched against a customer VM. Azure does not provide mitigation or actively block network traffic affecting individual customer deployments, because the infrastructure does not interpret the expected behavior of customer applications. In this case, similar to on-premises deployments, mitigations include:&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のような対処が有効です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Running multiple VM instances behind a load-balanced Public IP address.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;攻撃されるポイントを負荷分散装置のパブリックIPに限定し、複数のVMへ負荷を散らします。 攻撃されても、できる限り踏ん張るアプローチです。AzureのDDoS防御システムで緩和しきれなかったトラフィックを受け止め、ダウンしないようにします。攻撃規模は事前に判断できないので、どれだけスケールさせるかは、ダウンした場合のビジネスインパクトとコストの兼ね合いで決める必要があります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Using firewall proxy devices such as Web Application Firewalls (WAFs) that terminate and forward traffic to endpoints running in a VM. This provides some protection against a broad range of DoS and other attacks, such as low-rate, HTTP, and other application-layer threats. Some virtualized solutions, such as Barracuda Networks, are available that perform both intrusion detection and prevention.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;WAFを入れて、通信の中身を見ないとわからない攻撃を検知、緩和します。一見ノーマルなトラフィックでも「ゆっくりと攻撃」するようなケースもあります。たとえば、ゆっくりWebサーバのコネクションを枯渇させるような攻撃などです。Azureでは仮想アプライアンスとして、Barracuda NetworksのWAFなどが使えます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot; Web Server add-ons that protect against certain DoS attacks.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Webサーバへアドインを入れましょう。パッチも適用しましょう。構成も見直しましょう。ちょっと古いですが&lt;a href=&#34;http://blogs.msdn.com/b/friis/archive/2014/12/30/security-guidelines-to-detect-and-prevent-dos-attacks-targeting-iis-azure-web-role-paas.aspx&#34;&gt;ここ&lt;/a&gt;が参考になります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Network ACLs, which can prevent packets from certain IP addresses from reaching VMs.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もしブロックしたいアクセス元IPアドレスがわかるなら、ACLで遮断しましょう。逆に通信可能な範囲のみ指定することもできます。&lt;/p&gt;

&lt;h2 id=&#34;ホワイトペーパーに加えて:4a620049922b1b54512a25b34ba773c5&#34;&gt;ホワイトペーパーに加えて&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/services/cdn/&#34;&gt;CDN&lt;/a&gt;も有効ですので検討ください。2段構えでの負荷分散、防御ができます。Akamaiとの統合ソリューションも今後&lt;a href=&#34;https://azure.microsoft.com/ja-jp/blog/microsoft-and-akamai-bring-cdn-to-azure-customers/&#34;&gt;提供される予定&lt;/a&gt;です。&lt;/p&gt;

&lt;p&gt;CDNは常に世界中からのトラフィックで揉まれているだけあって、DDoS防御四天王で最強の漢が最初に出てくるくらい強力です。&lt;/p&gt;

&lt;p&gt;最後に。攻撃されている感があれば、カスタマーサポートまで。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure Blob Upload ツール別ベンチマーク</title>
      <link>http://torumakabe.github.io/post/azureblobupload_perf/</link>
      <pubDate>Thu, 11 Feb 2016 12:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azureblobupload_perf/</guid>
      <description>

&lt;h2 id=&#34;同じ目的を達成できるツールがたくさん:2c3afc565a3430f70519d9c56354717c&#34;&gt;同じ目的を達成できるツールがたくさん&lt;/h2&gt;

&lt;p&gt;やりたいことがあり、それを達成する手段がたくさん。どう選ぼう。じゃあ特徴を知りましょう。という話です。&lt;/p&gt;

&lt;p&gt;端末からAzureへファイルをアップロードする手段は多くあります。CLIツール、GUIツール、SDKで自作する、etc。&lt;/p&gt;

&lt;p&gt;そして、端末と、そのおかれている環境も多様です。Windows、Mac。有線、無線。&lt;/p&gt;

&lt;p&gt;で、大事なのは平行度。ブロックBlobはブロックを平行に転送する方式がとれるため、ツールが平行転送をサポートしているか? どのくらい効くのか? は重要な評価ポイントです。&lt;/p&gt;

&lt;p&gt;なので、どのツールがおすすめ?と聞かれても、条件抜きでズバっとは答えにくい。そしてこの質問は頻出。なのでこんな記事を書いています。&lt;/p&gt;

&lt;h2 id=&#34;環境と測定方式:2c3afc565a3430f70519d9c56354717c&#34;&gt;環境と測定方式&lt;/h2&gt;

&lt;p&gt;おそらくファイルを送る、という用途でもっとも重視すべき特徴は転送時間でしょう。ではツール、環境別に転送時間を測定してみます。&lt;/p&gt;

&lt;p&gt;環境は以下の通り。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Windows端末

&lt;ul&gt;
&lt;li&gt;Surface Pro 4 Core i7/16GB Memory/802.11ac&lt;/li&gt;
&lt;li&gt;1Gbps Ethernet (USB経由)&lt;/li&gt;
&lt;li&gt;Windows 10 (1511)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Mac端末

&lt;ul&gt;
&lt;li&gt;Macbook 12inch Core M/8GB Memory/802.11ac&lt;/li&gt;
&lt;li&gt;USB-C&amp;hellip; 有線テストは省きます&lt;/li&gt;
&lt;li&gt;El Capitan&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Wi-Fiアクセスポイント/端末間帯域

&lt;ul&gt;
&lt;li&gt;100~200Mbpsでつながっています&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Azureデータセンタまでの接続

&lt;ul&gt;
&lt;li&gt;日本マイクロソフトの品川オフィスから、首都圏にあるAzure Japan Eastリージョンに接続&lt;/li&gt;
&lt;li&gt;よってWAN側の遅延、帯域ともに条件がいい&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;対象ツール

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-use-azcopy/&#34;&gt;AzCopy v5.0.0.27&lt;/a&gt; (Windowsのみ)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/xplat-cli-install/&#34;&gt;Azure CLI v0.9.15&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://storageexplorer.com/&#34;&gt;Azure Storage Explorer - Cross Platform GUI v0.7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;転送ファイル

&lt;ul&gt;
&lt;li&gt;Ubuntu 15.10 ISOイメージ (647MBytes)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そして測定方式。&lt;/p&gt;

&lt;p&gt;AzCopyはPowerShellのMeasure-Commandにて実行時間をとります。NCが平行度指定です。デフォルトの平行度はCPUコア数の8倍です。わしのSurface、OSから4コア見えていますので、32。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Measure-Command {AzCopy /Source:C:\Users\myaccount\work /Dest:https://myaccount.blob.core.windows.net/mycontainer /DestKey:mykey /Pattern:ubuntu-15.10-server-amd64.iso /Y /NC:count}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Azure CLIも同様にMeasure-Commandで。&amp;ndash;concurrenttaskcountで平行度を指定できますが、&lt;a href=&#34;https://github.com/Azure/azure-xplat-cli/blob/dev/lib/util/storage.util._js&#34;&gt;ソース&lt;/a&gt;を確認したところ、平行度のデフォルトは5です。&amp;rdquo;StorageUtil.threadsInOperation = 5;&amp;ldquo;ですね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Measure-Command {azure storage blob upload ./ubuntu-15.10-server-amd64.iso -a myaccount -k mykey mycontainer ubuntu1510 --concurrenttaskcount count}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;残念ながらMacむけAzCopyはありませんので、Azure CLIのみ実行します。timeコマンドで時間をとります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time azure storage blob upload ./ubuntu-15.10-server-amd64.iso -a myaccount -k mykey mycontainer ubuntu1510 --concurrenttaskcount count
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Azure Storage Explorer Cross Platform GUIは、目視+iPhoneのストップウォッチで。&lt;/p&gt;

&lt;h2 id=&#34;結果:2c3afc565a3430f70519d9c56354717c&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;平行度上げても伸びないな、というタイミングまで上げます。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;　実行No　&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;　クライアントOS　&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;　ネットワーク接続　&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;　クライアント　&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;　並行数　&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;　転送時間(秒)　&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:32)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.62&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.28&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.83&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.43&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:5)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49.92&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29.47&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21.05&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20.12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Storage Explorer&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;N/A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50.10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:32)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74.87&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;53.32&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;58.85&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:5)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;57.23&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50.71&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;54.37&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Storage Explorer&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;N/A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;54.63&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mac OS X&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:5)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40.86&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mac OS X&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33.97&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mac OS X&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;58.57&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mac OS X&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Storage Explorer&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;N/A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;58.20&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;考察:2c3afc565a3430f70519d9c56354717c&#34;&gt;考察&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;有線AzCopy早い。単純計算で67MByte/s出ています。それぞれの計測点の解釈の違いでBlobサービス制限の60MBytes/sを超えてしまっていますがw。データセンタまでのボトルネックがなければ、ポテンシャルを引き出せることがわかります。&lt;/li&gt;
&lt;li&gt;平行度は大きく性能に影響します。

&lt;ul&gt;
&lt;li&gt;平行度が高すぎてもだめ

&lt;ul&gt;
&lt;li&gt;無線AzCopyのデフォルト(平行度32)が平行度10、20より時間がかかっていることからわかる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;デフォルトで遅いからといってあきらめず、平行度変えて試してみましょう&lt;/li&gt;
&lt;li&gt;SDK使って自分で作る時も同じ。平行度パラメータを意識してください

&lt;ul&gt;
&lt;li&gt;.NET: BlobRequestOptions&lt;/li&gt;
&lt;li&gt;Java/Android: BlobRequestOptions.setConcurrentRequestCount()&lt;/li&gt;
&lt;li&gt;Node.js: parallelOperationThreadCount&lt;/li&gt;
&lt;li&gt;C++: blob_request_options::set_parallelism_factor&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Azure CLIよりAzCopyが早い。

&lt;ul&gt;
&lt;li&gt;.NETで最適化できているから合点&lt;/li&gt;
&lt;li&gt;Node.jsベースでマルチOS対応のAzure CLIは比べられると分が悪い&lt;/li&gt;
&lt;li&gt;でも、802.11acでも無線がボトルネックになっているので、いまどきのWi-Fi環境では似たような性能になる&lt;/li&gt;
&lt;li&gt;No.18の結果は無線状態がよかったと想定&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Azure Storage Explorer Cross Platform GUIは、現時点で平行度変えられないので性能面では不利。でも直観的なので、使い分け。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WAN条件がいいベンチマークでなので、ぜひみなさんの条件でも試してみてください。遅延の大きなリージョンや途中に帯域ボトルネックがある条件でやると、最適な平行度が変わってくるはずです。&lt;/p&gt;

&lt;p&gt;でも一番言いたかったのは、Macbookの有線アダプタ欲しいということです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux on Azureでファイル共有する方法</title>
      <link>http://torumakabe.github.io/post/fileshare_linuxonazure/</link>
      <pubDate>Sun, 07 Feb 2016 17:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/fileshare_linuxonazure/</guid>
      <description>

&lt;h2 id=&#34;ファイル共有-あまりおすすめしないです:fa176ff87dca43c3d098f48095435bba&#34;&gt;ファイル共有、あまりおすすめしないです&lt;/h2&gt;

&lt;p&gt;いきなりタイトルを否定しました。ロック。&lt;/p&gt;

&lt;p&gt;さて、これからクラウド、というお客様に、よく聞かれる質問があります。それは「NFSとかの、ファイル共有使える?」です。頻出です。クラウド頻出質問選手権では、西東京予選で毎年ベスト8入りするレベルの強豪校です。&lt;/p&gt;

&lt;p&gt;ですが&lt;strong&gt;個人的には&lt;/strong&gt;あまりおすすめしません。クラウドはなるべく共有部分を減らして、スケーラブルに、かつ障害の影響範囲を局所化するべき、と考えるからです。特にストレージはボトルネックや広範囲な障害の要因になりやすい。障害事例が物語ってます。その代わりにオブジェクトストレージなど、クラウド向きの機能がおすすめです。&lt;/p&gt;

&lt;p&gt;でも、否定はしません。アプリの作りを変えられないケースもあるかと思います。&lt;/p&gt;

&lt;p&gt;そこで、もしAzureでファイル共有が必要であれば、&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-introduction/&#34;&gt;Azure File Storage&lt;/a&gt;を検討してみてください。Azureのマネージドサービスなので、わざわざ自分でサーバたてて運用する必要がありません。楽。&lt;/p&gt;

&lt;p&gt;対応プロトコルは、SMB2.1 or 3.0。LinuxからはNFSじゃなくSMBでつついてください。&lt;/p&gt;

&lt;p&gt;使い方は公式ドキュメントを。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-azure-cli/#create-and-manage-file-shares&#34;&gt;&amp;ldquo;Azure Storage での Azure CLI の使用&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-how-to-use-files-linux/&#34;&gt;&amp;ldquo;Linux で Azure File Storage を使用する方法&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;もうちょっと情報欲しいですね。補足のためにわたしも流します。&lt;/p&gt;

&lt;h2 id=&#34;azure-cliでストレージアカウントを作成し-ファイル共有を設定:fa176ff87dca43c3d098f48095435bba&#34;&gt;Azure CLIでストレージアカウントを作成し、ファイル共有を設定&lt;/h2&gt;

&lt;p&gt;ストレージアカウントを作ります。fspocは事前に作っておいたリソースグループです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local$ azure storage account create tomakabefspoc -l &amp;quot;Japan East&amp;quot; --type LRS -g fspoc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ストレージアカウントの接続情報を確認します。必要なのはdata: connectionstring:の行にあるAccountKey=以降の文字列です。このキーを使ってshareの作成、VMからのマウントを行うので、控えておいてください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local$ azure storage account connectionstring show tomakabefspoc -g fspoc
info:    Executing command storage account connectionstring show
+ Getting storage account keys
data:    connectionstring: DefaultEndpointsProtocol=https;AccountName=tomakabefspoc;AccountKey=qwertyuiopasdfghjklzxcvbnm==
info:    storage account connectionstring show command OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;shareを作成します。share名はfspocshareとしました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local$ azure storage share create -a tomakabefspoc -k qwertyuiopasdfghjklzxcvbnm== fspocshare
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エンドポイントを確認しておきましょう。VMからのマウントの際に必要です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local$ azure storage account show tomakabefspoc -g fspoc
[snip]
data:    Primary Endpoints: file https://tomakabefspoc.file.core.windows.net/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;linux-2vmで共有:fa176ff87dca43c3d098f48095435bba&#34;&gt;Linux * 2VMで共有&lt;/h2&gt;

&lt;p&gt;Ubuntuでやりますよ。SMBクライアントとしてcifs-utilsパッケージをインストールします。&lt;a href=&#34;https://azure.microsoft.com/ja-jp/marketplace/partners/canonical/ubuntuserver1404lts/&#34;&gt;Marketplace提供の14.04 LTS&lt;/a&gt;であれば、すでに入ってるはずです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm01:~$ sudo apt-get install cifs-utils
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マウントポイントを作り、マウントします。接続先の指定はエンドポイント+share名で。usernameはストレージアカウント名。パスワードはストレージアカウントのキーです。
パーミッションは要件に合わせてください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm01:~$ sudo mkdir -p /mnt/fspoc
fspocvm01:~$ sudo mount -t cifs //tomakabefspoc.file.core.windows.net/fspocshare /mnt/fspoc -o vers=3.0,username=tomakabefspoc,password=qwertyuiopasdfghjklzxcvbnm==,dir_mode=0777,file_mode=0777
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マウント完了。確認用のファイルを作っておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm01:~$ echo &amp;quot;test&amp;quot; &amp;gt; /mnt/fspoc/test.txt
fspocvm01:~$ cat /mnt/fspoc/test.txt
test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2台目のVMでも同様のマウント作業を。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm02:~$ sudo apt-get install cifs-utils
fspocvm02:~$ sudo mkdir -p /mnt/fspoc
fspocvm02:~$ sudo mount -t cifs //tomakabefspoc.file.core.windows.net/fspocshare /mnt/fspoc -o vers=3.0,username=tomakabefspoc,password=qwertyuiopasdfghjklzxcvbnm==,dir_mode=0777,file_mode=0777
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1台目で作ったファイルが見えますね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm02:~$ ls /mnt/fspoc
test.txt
fspocvm02:~$ cat /mnt/fspoc/test.txt
test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイルをいじりましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm02:~$ echo &amp;quot;onemoretest&amp;quot; &amp;gt;&amp;gt; /mnt/fspoc/test.txt
fspocvm02:~$ cat /mnt/fspoc/test.txt
test
onemoretest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1台目から確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm01:~$ cat /mnt/fspoc/test.txt
test
onemoretest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ご利用は計画的に:fa176ff87dca43c3d098f48095435bba&#34;&gt;ご利用は計画的に&lt;/h2&gt;

&lt;p&gt;2016年2月時点で、Azure File Storageには最大容量:5TB/share、1TB/file、ストレージアカウントあたりの帯域:60MBytes/sという制約があります。これを超えるガチ共有案件では、&lt;a href=&#34;https://azure.microsoft.com/en-us/marketplace/partners/intel/lustre-cloud-edition-evaleval-lustre-2-7/&#34;&gt;Lustre&lt;/a&gt;など別の共有方法を検討してください。&lt;/p&gt;

&lt;p&gt;なおファイルサーバ用途であれば、Azure File Storageではなく、OneDriveなどオンラインストレージSaaSに移行した方が幸せになれると思います。企業向けが使いやすくなってきましたし。運用から解放されるだけじゃなく、便利ですよ。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux on AzureでDisk IO性能を確保する方法</title>
      <link>http://torumakabe.github.io/post/striping_linuxonazure/</link>
      <pubDate>Wed, 27 Jan 2016 00:19:30 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/striping_linuxonazure/</guid>
      <description>

&lt;h2 id=&#34;俺の鉄板-ができるまで:cfa04af83b137faef18a5d4e4444f400&#34;&gt;&amp;ldquo;俺の鉄板&amp;rdquo;ができるまで&lt;/h2&gt;

&lt;p&gt;前半はポエムです。おそらくこのエントリにたどり着く人の期待はLinux on AzureのDisk IO性能についてと思いますが、それは後半に書きます。&lt;/p&gt;

&lt;p&gt;クラウド、Azureに関わらず、技術や製品の組み合わせは頭の痛い問題です。「これとこれ、組み合わせて動くの？サポートされるの？性能出るの？」という、あれです。技術や製品はどんどん進化しますので、同じ組み合わせが使えることは珍しくなってきています。&lt;/p&gt;

&lt;p&gt;ちなみにお客様のシステムを設計する機会が多いわたしは、こんな流れで検討します。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;構成要素全体を俯瞰したうえで、調査が必要な技術や製品、ポイントを整理する

&lt;ul&gt;
&lt;li&gt;やみくもに調べものしないように&lt;/li&gt;
&lt;li&gt;経験あるアーキテクトは実績ある組み合わせや落とし穴を多くストックしているので、ここが早い&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ベンダの公式資料を確認する

&lt;ul&gt;
&lt;li&gt;「この使い方を推奨/サポートしています」と明記されていれば安心&lt;/li&gt;
&lt;li&gt;でも星の数ほどある技術や製品との組み合わせがすべて網羅されているわけではない&lt;/li&gt;
&lt;li&gt;不明確なら早めに問い合わせる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ベンダが運営しているコミュニティ上の情報を確認する

&lt;ul&gt;
&lt;li&gt;ベンダの正式見解ではない場合もあるが、その製品を担当する社員が書いている情報には信ぴょう性がある&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;コミュニティや有識者の情報を確認する

&lt;ul&gt;
&lt;li&gt;OSSでは特に&lt;/li&gt;
&lt;li&gt;専門性を感じるサイト、人はリストしておく&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;動かす

&lt;ul&gt;
&lt;li&gt;やっぱり動かしてみないと&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;提案する

&lt;ul&gt;
&lt;li&gt;リスクがあれば明示します&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;問題なければ実績になる、問題があればリカバリする

&lt;ul&gt;
&lt;li&gt;提案しっぱなしにせずフォローすることで、自信とパターンが増える&lt;/li&gt;
&lt;li&gt;次の案件で活きる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;いまのわたしの課題は4、5です。特にOSS案件。AzureはOSSとの組み合わせを推進していて、ここ半年でぐっと情報増えたのですが、まだ物足りません。断片的な情報を集め、仮説を立て、動かす機会が多い。なので、5を増やして、4の提供者側にならんとなぁ、と。&lt;/p&gt;

&lt;h2 id=&#34;linux-on-azureでdisk-io性能を確保する方法:cfa04af83b137faef18a5d4e4444f400&#34;&gt;Linux on AzureでDisk IO性能を確保する方法&lt;/h2&gt;

&lt;p&gt;さて今回の主題です。&lt;/p&gt;

&lt;p&gt;結論: Linux on AzureでDisk IOを最大化するには、MDによるストライピングがおすすめ。いくつかパラメータを意識する。&lt;/p&gt;

&lt;p&gt;Linux on AzureでDisk IO性能を必要とする案件がありました。検討したアイデアは、SSDを採用したPremium Storageを複数束ねてのストライピングです。Premium Storageはディスクあたり5,000IOPSを期待できます。でも、それで足りない恐れがありました。なので複数並べて平行アクセスし、性能を稼ぐ作戦です。&lt;/p&gt;

&lt;p&gt;サーバ側でのソフトウェアストライピングは古くからあるテクニックで、ハードの能力でブン殴れそうなハイエンドUnixサーバとハイエンドディスクアレイを組み合わせた案件でも、匠の技として使われています。キャッシュやアレイコントローラ頼りではなく、明示的にアクセスを分散することで性能を確保することができます。&lt;/p&gt;

&lt;p&gt;Linuxで使える代表的なストライプ実装は、LVMとMD。&lt;/p&gt;

&lt;p&gt;ではAzure上でどちらがを選択すべきでしょう。この案件では性能が優先事項です。わたしはその時点で判断材料を持っていませんでした。要調査。この絞り込みまでが前半ポエムの1です。&lt;/p&gt;

&lt;p&gt;前半ポエムの2、3はググ、もといBing力が試される段階です。わたしは以下の情報にたどり着きました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-linux-configure-raid/&#34;&gt;&amp;ldquo;Configure Software RAID on Linux&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-premium-storage-preview-portal/&#34;&gt;&amp;ldquo;Premium Storage: Azure 仮想マシン ワークロード向けの高パフォーマンス ストレージ&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blogs.msdn.com/b/igorpag/archive/2014/10/23/azure-storage-secrets-and-linux-i-o-optimizations.aspx&#34;&gt;&amp;ldquo;Azure Storage secrets and Linux I/O optimizations&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;得られた情報の中で大事なのは、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;公式ドキュメントで

&lt;ul&gt;
&lt;li&gt;LVMではなくMDを使った構成例が紹介されている&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;マイクロソフトがホストするブログ(MSDN)で、エキスパートが

&lt;ul&gt;
&lt;li&gt;LVMと比較したうえで、MDをすすめている&lt;/li&gt;
&lt;li&gt;MDのChunkサイズについて推奨値を紹介している&lt;/li&gt;
&lt;li&gt;そのほか、ファイルシステムやスケジューラに関する有益な情報あり&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;なるほど。わたしのこの時点での方針はこうです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LVMを使う必然性はないため、MDに絞る

&lt;ul&gt;
&lt;li&gt;LVMのほうが機能豊富だが、目的はストライピングだけであるため、シンプルなほうを&lt;/li&gt;
&lt;li&gt;物理障害対策はAzureに任せる (3コピー)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;MDのChunkをデフォルトの512KBから64KBに変更する (ここは結果によって調整)&lt;/li&gt;
&lt;li&gt;Premium StorageのキャッシュはReadOnly or Noneにする予定であるため、ファイルシステムのバリアを無効にする&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上記シナリオで、ディスク当たり5,000IOPS、ストライプ数に比例した性能が実際出れば提案価値あり、ということになります。
ですが、ズバリな実績値が見つからない。ダラダラ探すのは時間の無駄。これは自分でやるしかない。&lt;/p&gt;

&lt;p&gt;構成手順は前述のリンク先にありますが、ポイントを抜き出します。OS=Ubuntu、ファイルシステム=ext4の場合です。&lt;/p&gt;

&lt;p&gt;MDでストライプを作る際、チャンクを64KBに変更します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mdadm --create /dev/md127 --level 0 --raid-devices 2  /dev/sdc1 /dev/sdd1 -c 64k
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マウント時にバリアを無効にします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mount /dev/md127 /mnt -o barrier=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では、Premium Storage(P30)をMDで2つ束ねたストライプにfioを実行してみましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;100% Random Read&lt;/li&gt;
&lt;li&gt;キャッシュ効果のないデータをとるため、Premium StorageのキャッシュはNone、fio側もdirect=1&lt;/li&gt;
&lt;li&gt;ブロックサイズは小さめの値が欲しかったので、1K&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;結果。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;randread: (g=0): rw=randread, bs=1K-1K/1K-1K/1K-1K, ioengine=libaio, iodepth=32
fio-2.1.3
Starting 1 process

randread: (groupid=0, jobs=1): err= 0: pid=9193: Tue Jan 26 05:48:09 2016
  read : io=102400KB, bw=9912.9KB/s, iops=9912, runt= 10330msec
[snip]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2本束ねて9,912IOPS。1本あたりほぼ5,000IOPS。ほぼ期待値。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>クラウドは本当に性能不足なのか</title>
      <link>http://torumakabe.github.io/post/doubt_lackofperf_oncloud/</link>
      <pubDate>Sun, 24 Jan 2016 00:19:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/doubt_lackofperf_oncloud/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;このエントリは2016/1/24に書きました。使えるリソースはどんどん増えていくので、適宜その時点で情報をとってください。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;具体的な数値で-正しい理解を:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;具体的な数値で、正しい理解を&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://itpro.nikkeibp.co.jp/atcl/watcher/14/334361/011800463/&#34;&gt;&amp;ldquo;クラウドは性能不足、企業システムが重すぎる&amp;rdquo;&lt;/a&gt;という記事が身の回りで話題になりました。公開から4日たっても「いま読まれている記事」の上位にあり、注目されているようです。&lt;/p&gt;

&lt;p&gt;記事で訴えたかったことは、クラウドを過信しないように、そして、クラウドはクラウドらしい使い方をしよう、ということでしょう。ユーザの声は貴重ですし、同意できるところも多い。でも、「企業システム」とひとくくりにしてしまったこと。タイトルのバイアスが強いこと。そして、具体的な根拠に欠けることから、誤解を招いている印象です。&lt;/p&gt;

&lt;p&gt;どんな技術、製品、サービスにも限界や制約はあります。具体的な数値や仕様で語らないと、そこから都市伝説が生まれます。&lt;/p&gt;

&lt;p&gt;いい機会なので、わたしの主戦場であるAzureを例に、クラウドでどのくらいの性能を期待できるか、まとめてみようと思います。&lt;/p&gt;

&lt;h2 id=&#34;シングルvmでどれだけ:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;シングルVMでどれだけ&lt;/h2&gt;

&lt;p&gt;話題となった記事でも触れられているように、クラウドはその生まれから、分散、スケールアウトな作りのアプリに向いています。ですが世の中には「そうできない」「そうするのが妥当ではない」システムもあります。記事ではそれを「企業システム」とくくっているようです。&lt;/p&gt;

&lt;p&gt;わたしは原理主義者ではないので「クラウドに載せたかったら、そのシステムを作り直せ」とは思いません。作りを大きく変えなくても載せられる、それでクラウドの特徴を活かして幸せになれるのであれば、それでいいです。もちろん最適化するにこしたことはありませんが。&lt;/p&gt;

&lt;p&gt;となると、クラウド活用の検討を進めるか、あきらめるか、判断材料のひとつは「スケールアウトできなくても、性能足りるか?」です。&lt;/p&gt;

&lt;p&gt;この場合、1サーバ、VMあたりの性能上限が制約です。なので、AzureのシングルVM性能が鍵になります。&lt;/p&gt;

&lt;p&gt;では、Azureの仮想マシンの提供リソースを確認しましょう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/virtual-machines-size-specs/&#34;&gt;&amp;ldquo;仮想マシンのサイズ&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ざっくりA、D、Gシリーズに分けられます。Aは初期からあるタイプ。ＤはSSDを採用した現行の主力。Gは昨年後半からUSリージョンで導入がはじまった、大物です。ガンダムだと後半、宇宙に出てから登場するモビルアーマー的な存在。現在、GシリーズがもっともVMあたり多くのリソースを提供できます。&lt;/p&gt;

&lt;p&gt;企業システムではOLTPやIOバウンドなバッチ処理が多いと仮定します。では、Gシリーズ最大サイズ、Standard_GS5の主な仕様から、OLTPやバッチ処理性能の支配要素となるCPU、メモリ、IOPSを見てみましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Standard_GS5の主な仕様

&lt;ul&gt;
&lt;li&gt;32仮想CPUコア&lt;/li&gt;
&lt;li&gt;448GBメモリ&lt;/li&gt;
&lt;li&gt;80,000IOPS&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;メモリはクラウドだからといって特記事項はありません。クラウドの特徴が出るCPUとIOPSについて深掘りしていきます。&lt;/p&gt;

&lt;p&gt;なお、&lt;strong&gt;現時点で&lt;/strong&gt;まだ日本リージョンにはGシリーズが投入されていません。必要に応じ、公開スペックと後述のACUなどを使ってA、Dシリーズと相対評価してください。&lt;/p&gt;

&lt;h2 id=&#34;32仮想cpuコアの規模感:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;32仮想CPUコアの規模感&lt;/h2&gt;

&lt;p&gt;クラウドのCPU性能表記は、なかなか悩ましいです。仮想化していますし、CPUは世代交代していきます。ちなみにAzureでは、ACU(Azure Compute Unit)という単位を使っています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/virtual-machines-size-specs/#-3&#34;&gt;&amp;ldquo;パフォーマンスに関する考慮事項&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ACUはAzure内で相対評価をする場合にはいいのですが、「じゃあAzureの外からシステムもってきたとき、実際どのくらいさばけるのよ。いま持ってる/買えるサーバ製品でいうと、どのくらいよ」という問いには向きません。&lt;/p&gt;

&lt;p&gt;クラウドや仮想化に関わらず、アプリの作りと処理するデータ、ハードの組み合わせで性能は変わります。動かしてみるのが一番です。せっかくイニシャルコストのかからないクラウドです。試しましょう。でもその前に、試す価値があるか判断しなければいけない。なにかしらの参考値が欲しい。予算と組織で動いてますから。わかります。&lt;/p&gt;

&lt;p&gt;では例をあげましょう。&lt;strong&gt;俺のベンチマーク&lt;/strong&gt;を出したいところですが、「それじゃない」と突っ込まれそうです。ここはぐっと我慢して、企業でよく使われているERP、SAPのSAP SDベンチマークにしましょう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://global.sap.com/campaigns/benchmark/appbm_cloud.epx&#34;&gt;&amp;ldquo;SAP Standard Application Benchmarks in Cloud Environments&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://global.sap.com/campaigns/benchmark/index.epx&#34;&gt;&amp;ldquo;SAP Standard Application Benchmarks&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SAPSという値が出てきます。販売管理アプリケーションがその基盤上でどれだけ仕事ができるかという指標です。&lt;/p&gt;

&lt;p&gt;比較のため、3年ほど前の2ソケットマシン、現行2ソケットマシン、現行4ソケットマシンを選びました。単体サーバ性能をみるため、APとDBを1台のサーバにまとめた、2-Tierの値をとります。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;http://download.sap.com/download.epd?context=40E2D9D5E00EEF7C91D3C5AFFF9A4689C82EA97027CDF4A42858AD1610A3F732&#34;&gt;DELL R720&lt;/a&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;http://global.sap.com/campaigns/benchmark/assets/Cert15038.pdf&#34;&gt;Azure VM GS5&lt;/a&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;http://download.sap.com/download.epd?context=40E2D9D5E00EEF7CFDB9CAEA540B6F601993E4359AB45BEF7ED0949D1BFF155D&#34;&gt;NEC R120f-2M&lt;/a&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;http://download.sap.com/download.epd?context=40E2D9D5E00EEF7C14B03FD143D20C6C90E8F6DEAA4E15F8090BA77A6249E1D0&#34;&gt;FUJITSU RX4770 M2&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Date&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;sup&gt;2012&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;sup&gt;2015&lt;/sup&gt;&amp;frasl;&lt;sub&gt;9&lt;/sub&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;sup&gt;2015&lt;/sup&gt;&amp;frasl;&lt;sub&gt;7&lt;/sub&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;sup&gt;2015&lt;/sup&gt;&amp;frasl;&lt;sub&gt;7&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;CPU Type&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Intel Xeon Processor E5-2690&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Intel Xeon Processor E5-2698B v3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Intel Xeon Processor E5-2699 v3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Intel Xeon Processor E7-8890 v3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;CPU Sockets&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;CPU Cores&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;32 (Virtual)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;SD Benchmark Users&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6,500&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7,600&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14,440&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;29,750&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;SAPS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;35,970&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;41,670&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;79,880&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;162,500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;3年前の2ソケットマシンより性能はいい。現行2ソケットマシンの半分程度が期待値でしょうか。ざっくりE5-2699 v3の物理18コアくらい。4ソケットは無理め。&lt;/p&gt;

&lt;p&gt;なお補足ですが、もちろんSAPはAPサーバをスケールアウトする構成もとれます。その性能は&lt;a href=&#34;http://global.sap.com/campaigns/benchmark/appbm_cloud.epx&#34;&gt;3-Tierベンチマーク&lt;/a&gt;で確認できます。&lt;a href=&#34;http://blogs.msdn.com/b/saponsqlserver/archive/2015/10/05/world-record-sap-sales-and-distribution-standard-application-benchmark-for-sap-cloud-deployments-released-using-azure-iaas-vms.aspx&#34;&gt;Azure上で247,880SAPS&lt;/a&gt;出たそうです。&lt;/p&gt;

&lt;h2 id=&#34;80-000iopsの規模感:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;80,000IOPSの規模感&lt;/h2&gt;

&lt;p&gt;IOPS = IO Per Second、秒あたりどれだけIOできるかという指標です。Azure VM GS5では&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-premium-storage-preview-portal/&#34;&gt;Premium Storage&lt;/a&gt;を接続し、VMあたり最大80,000IOPSを提供します。&lt;/p&gt;

&lt;p&gt;一般的に企業で使われているディスクアレイに載っているHDDのIOPSは、1本あたりおおよそ200です。IOPSに影響する要素は回転数で、よく回る15,000rpm FC/SAS HDDでだいたいこのくらい。&lt;/p&gt;

&lt;p&gt;なので80,000 / 200 = 400。よって80,000IOPSを達成しようとすると、HDDを400本並べないといけません。小さくないです。&lt;/p&gt;

&lt;p&gt;もちろんディスクアレイにはキャッシュがあるので、キャッシュヒット次第でIOPSは変わります。ベンダが胸を張って公開している値も、キャッシュに当てまくった数字であることが多いです。ですが誠実な技術者は「水物」なキャッシュヒットを前提にサイジングしません。アプリがアレイを占有できて、扱うデータの量や中身に変化がない場合は別ですが、それはまれでしょう。ヒットしない最悪の場合を考慮するはずです。&lt;/p&gt;

&lt;p&gt;なお、数十万IOPSをこえるディスクアレイがあるのは事実です。でも「桁が違う。クラウドしょぼい」と思わないでください。ディスクアレイ全体の性能と、VMあたりどのくらい提供するかは、別の問題です。ひとつのVMがディスクアレイを占有するのでない限り、VMあたりのIOコントロールは必要です。そうでないと、暴れん坊VMの割を食うVMがでてきます。見えていないだけで、クラウドのバックエンドにはスケーラブルなストレージが鎮座しています。&lt;/p&gt;

&lt;h2 id=&#34;結論:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;結論&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Intel x86 2ソケットモデルサーバで動いているようなシステムの移行であれば検討価値あり&lt;/li&gt;
&lt;li&gt;メモリが448GB以上必要であれば難しい&lt;/li&gt;
&lt;li&gt;サーバあたり80,000IOPS以上必要であれば難しい、でも本当にサーバあたりそれだけ必要か精査すべき&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ちょっと前までオンプレ案件も担当していましたが、ここ数年は2ソケットサーバ案件中心、ときどき、4ソケット以上で興奮。という感覚です。みなさんはいかがでしょう。データはないのでご参考まで。&lt;/p&gt;

&lt;p&gt;なにはともあれ、プロのみなさんは噂に流されず、制約を数値で把握して判断、設計しましょう。Azureではそのほかの制約条件も公開されていますので、ぜひご一読を。上限を緩和できるパラメータも、あります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/azure-subscription-service-limits/&#34;&gt;&amp;ldquo;Azure サブスクリプションとサービスの制限、クォータ、制約&amp;rdquo;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azureでインフラデプロイツールを選ぶ時に考えていること</title>
      <link>http://torumakabe.github.io/post/azure_infradeployment_selection/</link>
      <pubDate>Mon, 11 Jan 2016 00:20:30 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_infradeployment_selection/</guid>
      <description>

&lt;h2 id=&#34;ケースバイケースだけど:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;ケースバイケースだけど&lt;/h2&gt;

&lt;p&gt;Azureを生業にして、3か月たちます。ここまで、もっとも質問や議論が多いのが、デプロイメントの自動化についてです。進化が早いですし、選択肢も豊富。クラウド採用に合わせて自動化に挑戦するケースも増えてますので、自然なことと思います。&lt;/p&gt;

&lt;p&gt;特に話題になるのが「どのツールを選べばいいか」。ツールというのは課題を解決する手段なので、まず課題を掘るべきです。ですが、まだ成熟していない領域で変化が激しいですし、ツールひとつで課題を解決できるとも限らない。複数のツールを組み合わせることも多く、依存関係もありそう。となると、考えるきっかけが欲しいのは、ごもっとも。&lt;/p&gt;

&lt;p&gt;なので「ケースバイケース。以上」とは、言いにくい。&lt;/p&gt;

&lt;p&gt;私見であっても、たたき台となる考え方なりパターンがWebに転がっていれば、参考になるかもしれない。それがこのエントリを書く動機です。わたしは他のプラットフォームからAzureに主戦場を移していますので、新鮮な意見が書けるかも、という背景も、あります。&lt;/p&gt;

&lt;h2 id=&#34;書く前に前提など:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;書く前に前提など&lt;/h2&gt;

&lt;p&gt;対象はインフラレイヤのデプロイメントに絞ります。そして、インフラ = 物理/仮想ハードウェア(サーバ、ストレージ、ネットワーク) + OS + プラットフォームソフト(アプリじゃないもの、Webサーバ、ユーティリティ、etc）と定義します。&lt;/p&gt;

&lt;p&gt;レイヤリングや用語は、 @gosukenator さんの&lt;a href=&#34;http://mizzy.org/blog/2013/10/29/1/&#34;&gt;&amp;ldquo;インフラ系技術の流れ&amp;rdquo;&lt;/a&gt;が参考になるので、合わせて読むと幸せになれるでしょう。このエントリで言うBootstrapping/Configurationレイヤが今回の焦点です。&lt;/p&gt;

&lt;p&gt;では、わたしがツールを選ぶ時にどんなことを考えているのか、脳内をダンプしていきましょう。&lt;/p&gt;

&lt;h2 id=&#34;そもそもツールで自動化すべきかを考える:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;そもそもツールで自動化すべきかを考える&lt;/h2&gt;

&lt;p&gt;いきなり萎えるそもそも論で恐縮ですが、重要です。たとえばあるソフトの試用目的で、同じ構成のサーバのデプロイは今後しなさそう、台数は1台、使うのは自分だけ、なんていう環境のデプロイまで、自動化する必要はないはずです。時短、工数削減、オペレーションミスリスクの軽減、そもそも自動化しないと運用がまわらない、など自動化によって得られる利益がその手間を上回るかを判断します。&lt;/p&gt;

&lt;p&gt;なお「知っている/できる」人でないとその価値、利益はわかりません。やらないという判断は、腕があってはじめてできることです。&lt;/p&gt;

&lt;h2 id=&#34;使い捨てられないかを考える:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;使い捨てられないかを考える&lt;/h2&gt;

&lt;p&gt;次は、ツールによって作った環境がどのように変化するか、変えられるかを検討します。ストレートに言うと、変化のタイミングで捨てられないか？新しいものに置き換えられないか？を考えます。もしこれができるのであれば、方式はとてもシンプルにできます。Immutable Infrastructure、Blue/Green Deploymentなどのやり口が注目されていますが、これらの根っこには「ちまちま変化を加えて複雑化するくらいなら、使い捨て/入れ替えてしまえ」という意識があります。&lt;/p&gt;

&lt;p&gt;ですが、とは言ってもそんな大胆にできない事情もあると思います。Blue/Green Deploymentでは、入れ替えのタイミングでBlue、Green分のリソースが必要になりますし、切り替えにともなうリスクもあります。それを許容できない場合、同じインフラに変化を積んでいくことになります。ChefなどConfigurationレイヤで冪等なオペーレーションができるツールが注目されたのは、この変化を維持しやすいからです。&lt;/p&gt;

&lt;p&gt;変化を積む場合にやるべきでないのは、中途半端に職人が真心こめて手作業してしまうことです。ツールでやると決めたら、少なくともそのカバー範囲はツールに任せましょう。でないといわゆる「手作業汚れ」「スノーフレークサーバ（雪の結晶のように、全部同じように見えて実はそれぞれ違う）」のダークサイドに堕ちます。&lt;/p&gt;

&lt;p&gt;変化を積まないのであれば、インフラデプロイメント用途ではConfigurationレイヤのツールを導入しないという割り切りもできるでしょう。&lt;/p&gt;

&lt;h2 id=&#34;優先事項や制約条件を洗い出す:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;優先事項や制約条件を洗い出す&lt;/h2&gt;

&lt;p&gt;アーキテクトが真っ白なキャンバスに画を描けることはほぼありません。きっと、先になんらかの優先事項や制約条件があるはずです。そして、ほとんどのシステムにおいて、インフラのデプロイは主役ではありません。ツールに合わせてもらえることはまれでしょう。様々な条件を選定にあたって洗い出す必要があります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;社内/プロジェクト標準&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　周知されていないだけで、推奨ツールが決まってたりします。あるある。そのツールの良し悪しは置いておいて、社内ノウハウの蓄積など、大きな目的がある場合には従うべきでしょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;他レイヤでの優先ツール&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　インフラのデプロイに影響がありそうなツールがアプリ開発側で決まっていたりします。最近華やかなのがDockerです。Docker社が出してるツール群は上から下までカバー範囲も広く、デプロイツールと重複しがちです。組み合わせを検討しなければいけません。また、Apache Mesosもインフラとアプリのグレーゾーンに鎮座します。なかなか悩ましいですが、優先せざるをえません。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;規模&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　いきなり1000台とか10000台規模を扱うユーザは多くないと思いますが、その規模になるとツールの性能限界にぶち当たったりします。念のため、意識はしましょう。ちなみに、1000台をひとつのツールの傘に入れずとも、たとえば10*100台にする設計ができないか、事前に考えておくと打ち手が増えます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;チーム or ひとり&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　本番環境のデプロイ自動化はチームプレイになるので、ツールの導入はサーバ上になるでしょうし、構成ファイルの共有、バージョンコントロールなど考慮点は多いです。一方で、開発者が開発、検証用途で端末に導入し実行する使い方では、手軽さが求められます。誤解を恐れず例をあげると、前者にはChefが、後者にはAnsibleやTerraformがフィットしやすいです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Windows or Linux&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　Azure ARM Templateなど、はじめからマルチOS環境を前提に作られているツールはありますが、ほとんどのツールはその生まれがWindows、Linuxに寄っています。マルチOS対応が進んではいますが、活用にあたって、参考となる情報量には大きな差があります。たとえばマルチOS対応のツールであっても、DSCはWindowsの、ChefやAnsibleはLinuxの情報が圧倒的に多いです。これは意識せざるを得ません。使うOSでの十分な情報があるか確認します。&lt;/p&gt;

&lt;h2 id=&#34;マネージドサービス-機能を活用する:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;マネージドサービス、機能を活用する&lt;/h2&gt;

&lt;p&gt;マネージドサービス = プラットフォームが提供している機能です。Azureであれば、今回対象としているレイヤではARMがそれにあたります。デプロイツールは有用ですが、その導入や維持運用には本質的価値はありません。プラットフォームに任せられるのであれば、そうしたほうが楽です。&lt;/p&gt;

&lt;p&gt;また、Azureのインフラは進化が早いため、それに対応するスピードも、本家ツールのほうが期待できます。&lt;/p&gt;

&lt;p&gt;ですが、&lt;a href=&#34;http://torumakabe.github.io/post/arm_idempotent/&#34;&gt;以前のエントリ&lt;/a&gt;で触れたように、本家のツールであっても、すべてのレイヤをカバーできるほど万能ではありません。たとえばARM TemplateはインフラのBootstrappingには向いていますが冪等性が限定的であるため、ソフトウェアパッケージを足す/消す/入れ替えるを頻繁に繰り返す環境のConfiguration用途では、苦しいです。&lt;/p&gt;

&lt;p&gt;よってARM Templateは、Immutableな環境で使う、もしくは、ChefなどのConfigurationツールと組み合わせて使うことを念頭に設計をします。&lt;/p&gt;

&lt;p&gt;ARM Templateでは、ハード(VM、ストレージ、ネットワーク)の割り当て、OSの導入と設定、各種エージェントの導入が基本。それに加え、Immutableな環境ではプラットフォームソフトを導入してしまっていいでしょう。ARM TemplateにはDSCやシェルを実行するエクステンションが使えるので、活用します。&lt;/p&gt;

&lt;p&gt;また、Bootstrapping時点で、Configurationツールを導入できてしまうのであれば、せっかくなので入れてしまいましょう。たとえばChefサーバのインストールは、ここで。&lt;/p&gt;

&lt;p&gt;以上、ちょっとまとまりに欠けますが、ざっとわたしが意識していることを、挙げてみました。&lt;/p&gt;

&lt;h2 id=&#34;汎用的-リファレンスアーキテクチャ:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;汎用的 リファレンスアーキテクチャ&lt;/h2&gt;

&lt;p&gt;具体例があったほうが分かりやすいので、最後に汎用的な組み合わせを紹介します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gallery.technet.microsoft.com/Automating-Deployment-with-84c1549f&#34;&gt;&amp;ldquo;Automating Deployment with Azure &amp;amp; Chef&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ARM TemplateでBootstrapping&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VMを4つ作成、1つはLinux、他はWindows&lt;/li&gt;
&lt;li&gt;ストレージ、ネットワークの作成&lt;/li&gt;
&lt;li&gt;VMのストレージ、ネットワーク設定&lt;/li&gt;
&lt;li&gt;OSの導入&lt;/li&gt;
&lt;li&gt;ドメインコントローラサーバへのソフト導入、各種設定 (DSC/PowerShell Extension)&lt;/li&gt;
&lt;li&gt;他Windowsサーバへのソフト導入、各種設定、ドメイン参加 (PowerShell Extension)&lt;/li&gt;
&lt;li&gt;LinuxへChefサーバを導入、各種設定 (Shell Extension)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ChefでConfiguration&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;各ノードのChef bootstrap(言葉が混同しやすいので注意)&lt;/li&gt;
&lt;li&gt;Chef Clientサービスの起動設定&lt;/li&gt;
&lt;li&gt;DBサーバのDB領域ディスク作成、フォーマット&lt;/li&gt;
&lt;li&gt;DBサーバへSQL Server 2014のインストール&lt;/li&gt;
&lt;li&gt;ChefがDBサーバが設定通りになるよう維持し続ける&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;どうでしょう、役割分担がイメージできたでしょうか。いいドキュメントがあったので、ChefのLinux/Windows混在例を紹介しましたが、Windowsとの親和性や情報量を重視するなら、ChefをAzure Automation DSCに置き換えて挑戦してもいいでしょう。そのまた逆もありで、ChefならLinux染めな環境で、とこだわってもいいと思います。&lt;/p&gt;

&lt;p&gt;書くことが意外に多かったので、また機会があれば、参考例を交えて紹介します。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure ARM Templateによるデプロイと冪等性</title>
      <link>http://torumakabe.github.io/post/arm_idempotent/</link>
      <pubDate>Wed, 06 Jan 2016 00:16:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/arm_idempotent/</guid>
      <description>

&lt;h2 id=&#34;宣言的に-冪等に:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;宣言的に、冪等に&lt;/h2&gt;

&lt;p&gt;ここ数年で生まれたデプロイメント手法、ツールは数多くありますが、似たような特徴があります。それは「より宣言的に、冪等に」です。これまで可読性や再利用性を犠牲にしたシェル芸になりがちだったデプロイの世界。それがいま、あるべき姿を定義しその状態に収束させるように、また、何度ツールを実行しても同じ結果が得られるように変わってきています。&lt;/p&gt;

&lt;p&gt;さて、そんな時流に飛び込んできたデプロイ手法があります。AzureのARM(Azure Resource Manager) Templateによるデプロイです。ARMはAzureのリソース管理の仕組みですが、そのARMに対し、構成を宣言的に書いたJSONを食わせて環境を構築する手法です。Azureの標準機能として、提供されています。&lt;/p&gt;

&lt;h3 id=&#34;azure-リソース-マネージャーの概要-https-azure-microsoft-com-ja-jp-documentation-articles-resource-group-overview:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-overview/&#34;&gt;Azure リソース マネージャーの概要&lt;/a&gt;&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;ソリューションを開発のライフサイクル全体で繰り返しデプロイできます。また、常にリソースが一貫した状態でデプロイされます&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;宣言型のテンプレートを利用し、デプロイメントを定義できます&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;冪等と言い切ってはいませんが、目的は似ています。&lt;/p&gt;

&lt;p&gt;なるほど、期待十分。ではあるのですが、冪等性の実現は簡単ではありません。たとえばChefやAnsibleも、冪等性はリソースやモジュール側で考慮する必要があります。多様なリソースの違いを吸収しなければいけないので、仕方ありません。魔法じゃないです。その辺を理解して使わないと、ハマります。&lt;/p&gt;

&lt;p&gt;残念ながらARMは成長が著しく、情報が多くありません。そこで、今回は実行結果を元に、冪等さ加減を理解していきましょう。&lt;/p&gt;

&lt;h2 id=&#34;増分デプロイと完全デプロイ:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;増分デプロイと完全デプロイ&lt;/h2&gt;

&lt;p&gt;まず、デプロイのコマンド例を見ていきましょう。今回はPowerShellを使いますが、Mac/Linux/Winで使える&lt;a href=&#34;https://github.com/Azure/azure-xplat-cli&#34;&gt;クロスプラットフォームCLI&lt;/a&gt;もあります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName YourRGName -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ワンライナーです。これだけで環境ができあがります。-TemplateFileでリソース定義を記述したJSONファイルを指定します。また、-TemplateParameterFileにパラメータを外だしできます。&lt;/p&gt;

&lt;p&gt;今回は冪等さがテーマであるため詳細は省きます。関心のあるかたは、別途&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-template-deploy/&#34;&gt;ドキュメント&lt;/a&gt;で確認してください。&lt;/p&gt;

&lt;p&gt;さて、ワンライナーで環境ができあがるわけですが、その後が重要です。環境変更の際にJSONで定義を変更し、同じコマンドを再投入したとしても、破たんなく使えなければ冪等とは言えません。&lt;/p&gt;

&lt;p&gt;コマンド投入には2つのモードがあります。増分(Incremental)と完全(Complete)です。まずは増分から見ていきましょう。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;・リソース グループに存在するが、テンプレートに指定されていないリソースを変更せず、そのまま残します&lt;/p&gt;

&lt;p&gt;・テンプレートに指定されているが、リソース グループに存在しないリソースを追加します&lt;/p&gt;

&lt;p&gt;・テンプレートに定義されている同じ条件でリソース グループに存在するリソースを再プロビジョニングしません&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;すでに存在するリソースには手を入れず、JSONへ新たに追加されたリソースのみを追加します。&lt;/p&gt;

&lt;p&gt;いっぽうで、完全モードです。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;・リソース グループに存在するが、テンプレートに指定されていないリソースを削除します&lt;/p&gt;

&lt;p&gt;・テンプレートに指定されているが、リソース グループに存在しないリソースを追加します&lt;/p&gt;

&lt;p&gt;・テンプレートに定義されている同じ条件でリソース グループに存在するリソースを再プロビジョニングしません&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;2、3番目は増分と同じです。1番目が違います。JSONから定義を消されたリソースを削除するかどうかが、ポイントです。完全モードはスッキリするけどリスクも高そう、そんな印象を受けるのはわたしだけではないでしょう。&lt;/p&gt;

&lt;h2 id=&#34;動きをつかむ:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;動きをつかむ&lt;/h2&gt;

&lt;p&gt;では動きを見ていきましょう。テンプレートはGithubに公開されている&lt;a href=&#34;https://github.com/Azure/azure-quickstart-templates/tree/master/101-vm-simple-linux&#34;&gt;Very simple deployment of an Linux VM&lt;/a&gt;を使います。詳細は説明しませんので、読み進める前にリソース定義テンプレートファイル(azuredeploy.json)を&lt;a href=&#34;https://github.com/Azure/azure-quickstart-templates/blob/master/101-vm-simple-linux/azuredeploy.json&#34;&gt;リンク先&lt;/a&gt;でざっと確認してください。&lt;/p&gt;

&lt;p&gt;パラメータファイル(azuredeploy.parameters.json)は以下とします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;$schema&amp;quot;: &amp;quot;http://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#&amp;quot;,
  &amp;quot;contentVersion&amp;quot;: &amp;quot;1.0.0.0&amp;quot;,
  &amp;quot;parameters&amp;quot;: {
    &amp;quot;adminUsername&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;azureUser&amp;quot;
    },
    &amp;quot;adminPassword&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;password1234!&amp;quot;
    },
    &amp;quot;dnsLabelPrefix&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;armpocps&amp;quot;
    },
    &amp;quot;ubuntuOSVersion&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;14.04.2-LTS&amp;quot;
    }    
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず、1回目の実行です。リソースグループ &amp;ldquo;ARMEval&amp;rdquo;に対しデプロイします。このリソースグループは前もって作っておいた空の箱です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json 

DeploymentName    : azuredeploy
ResourceGroupName : ARMEval
ProvisioningState : Succeeded
Timestamp         : 2016/01/04 11:46:41
Mode              : Incremental
TemplateLink      :
Parameters        :
                Name             Type                       Value
                ===============  =========================  ==========
                adminUsername    String                     azureUser
                adminPassword    SecureString
                dnsLabelPrefix   String                     armpocps
                ubuntuOSVersion  String                     14.04.2-LTS

Outputs           :
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できあがりです。空のリソースグループ にLinux VM、ストレージ、仮想ネットワーク、パブリックIPなどがデプロイされました。Modeを指定しない場合は増分(Incremental)となります。&lt;/p&gt;

&lt;p&gt;この環境にじわじわと変更を入れていきましょう。まずはazuredeploy.parameter.json上のパラメータ、DNS名のPrefix(dnsLabelPrefix)をarmpocps -&amp;gt; armpocps2と変えます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;dnsLabelPrefix&amp;quot;: {
  &amp;quot;value&amp;quot;: &amp;quot;armpocps2&amp;quot;
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では再投入です。パラメータファイルの内容は変えましたが、コマンドは同じです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json 
[snip]
Parameters        :
                Name             Type                       Value
                ===============  =========================  ==========
                adminUsername    String                     azureUser
                adminPassword    SecureString
                dnsLabelPrefix   String                     armpocps2
                ubuntuOSVersion  String                     14.04.2-LTS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;変更内容の確認です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; Get-AzureRmPublicIpAddress
[snip]
DnsSettings              : {
                             &amp;quot;DomainNameLabel&amp;quot;: &amp;quot;armpocps2&amp;quot;,
                             &amp;quot;Fqdn&amp;quot;: &amp;quot;armpocps2.japanwest.cloudapp.azure.com&amp;quot;
                           }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;問題なく変わっていますね。冪等チックです。この例ではシンプルにDNS名のPrefixを変えましたが、VMインスタンス数やsubnet名を変えたりもできます。関心のある方は&lt;a href=&#34;https://gallery.technet.microsoft.com/Cloud-Consistency-with-0b79b775&#34;&gt;ドキュメント&lt;/a&gt;を。&lt;/p&gt;

&lt;p&gt;増分モードによる変更は期待できそうです。が、さて、ここからが探検です。リソース削除が可能な完全モードを試してみましょう。
リソース定義ファイル(azuredeploy.json)から、大胆にVMの定義を削ってみます。下記リソースをファイルからごっそり消します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;apiVersion&amp;quot;: &amp;quot;[variables(&#39;apiVersion&#39;)]&amp;quot;,
  &amp;quot;type&amp;quot;: &amp;quot;Microsoft.Compute/virtualMachines&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;[variables(&#39;vmName&#39;)]&amp;quot;,
[snip]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では、完全モード &amp;ldquo;-Mode complete&amp;rdquo;付きでコマンドを再投入します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json  -Mode complete

確認
Are you sure you want to use the complete deployment mode? Resources in the resource group &#39;ARMEval&#39; which are not included in the template will be deleted.
[Y] はい(Y)  [N] いいえ(N)  [S] 中断(S)  [?] ヘルプ (既定値は &amp;quot;Y&amp;quot;): Y

DeploymentName    : azuredeploy
ResourceGroupName : ARMEval
ProvisioningState : Succeeded
Timestamp         : 2016/01/04 12:01:00
Mode              : Complete
TemplateLink      :
Parameters        :
                Name             Type                       Value
                ===============  =========================  ==========
                adminUsername    String                     azureUser
                adminPassword    SecureString
                dnsLabelPrefix   String                     armpocps2
                ubuntuOSVersion  String                     14.04.2-LTS

Outputs           :
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あっさり完了しました。本当にVMが消えているが確認します。出力が冗長ですがご容赦ください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; Find-AzureRmResource -ResourceGroupNameContains ARMEval

Name              : myPublicIP
ResourceId        :     /subscriptions/your-subscription-id/resourceGroups/ARMEval/providers/Microsoft.Network/publicIPAddresses/myPublicIP
ResourceName      : myPublicIP
ResourceType      : Microsoft.Network/publicIPAddresses
ResourceGroupName : ARMEval
Location          : japanwest
SubscriptionId    : your-subscription-id

Name              : myVMNic
ResourceId        : /subscriptions/your-subscription-id/resourceGroups/ARMEval/providers/Microsoft.Network/networkInterfaces/myVMNic
ResourceName      : myVMNic
ResourceType      : Microsoft.Network/networkInterfaces
ResourceGroupName : ARMEval
Location          : japanwest
SubscriptionId    : your-subscription-id

Name              : MyVNET
ResourceId        : /subscriptions/your-subscription-id/resourceGroups/ARMEval/providers/Microsoft.Network/virtualNetworks/MyVNET
ResourceName      : MyVNET
ResourceType      : Microsoft.Network/virtualNetworks
ResourceGroupName : ARMEval
Location          : japanwest
SubscriptionId    : your-subscription-id

Name              : yourstorageaccount
ResourceId        : /subscriptions/your-subscription-id/resourceGroups/ARMEval/providers/Microsoft.Storage/storageAccounts/yourstorageaccount
ResourceName      : yourstorageaccount
ResourceType      : Microsoft.Storage/storageAccounts
ResourceGroupName : ARMEval
Location          : japanwest
SubscriptionId    : your-subscription-id
Tags              : {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VMだけが消えています。定義からリソースがなくなれば、存在するリソースも消す、これが完全モードです。&lt;/p&gt;

&lt;p&gt;さらに検証。冪等さを求めるのであれば、またリソース定義にVMを加えて再投入したら、涼しい顔で復活してほしい。先ほどazuredeploy.jsonから消したVMリソース定義を、そのまま書き戻して再投入してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json  -Mode complete

確認
Are you sure you want to use the complete deployment mode? Resources in the resource group &#39;ARMEval&#39; which are not included in the template will be deleted.
[Y] はい(Y)  [N] いいえ(N)  [S] 中断(S)  [?] ヘルプ (既定値は &amp;quot;Y&amp;quot;): Y

New-AzureRmResourceGroupDeployment : 21:05:52 - Resource Microsoft.Compute/virtualMachines &#39;MyUbuntuVM&#39; failed with message &#39;The resource operation completed with terminal provisioning state &#39;Failed&#39;.&#39;
[snip]
New-AzureRmResourceGroupDeployment : 21:05:52 - One or more errors occurred while preparing VM disks. See disk instance view for details.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;残念ながら失敗しました。どうやらdiskまわりのエラーが発生したようです。&lt;/p&gt;

&lt;p&gt;これは、完全モードでのリソース削除の仕様が原因です。ARMは該当のVMリソースは消すのですが、VMが格納されているストレージを削除しません。リソース作成時は依存関係が考慮されますが、削除時は異なります。&lt;/p&gt;

&lt;p&gt;試しにストレージを消して再実行してみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json  -Mode complete

[snip]
ProvisioningState : Succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定義通りの環境になりました。依存関係をたどって消してほしいのが人情ですが、残したほうがいいケースもあるので、今後の改善を期待しましょう。&lt;/p&gt;

&lt;h2 id=&#34;使い方:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;使い方&lt;/h2&gt;

&lt;p&gt;冪等であると言い切れないものの、リソース定義と実行モードを理解したうえで使えば有用。ただ、完全モードによる削除は使い方が難しい。現状ではそんな印象です。&lt;/p&gt;

&lt;p&gt;そこで、ARM Templateをデプロイに組み込む際、ARMによるデプロイはBootstrap用途に限定し、より構成頻度が高いConfiguration用途には、冪等性を持った別のツールを組み合わせるのが現実解と考えます。&lt;/p&gt;

&lt;p&gt;Bootstrap用途では、プラットフォームの提供機能を使ったほうが、機能も多いし最適化されています。Azureで今後この層を担当していくのはARMです。そして、この用途ではChefやAnsibleなど汎用ツールに物足りなさがあります。&lt;/p&gt;

&lt;p&gt;また、Bootstrapは1回切りであるケースが多いので、失敗したらリソースグループをばっさり消して再作成する、と割り切りやすいです。それならば冪等でなくともいいでしょう。&lt;/p&gt;

&lt;p&gt;長くなったので、デプロイツールの組み合わせについては、あたらめて書きたいと思います。&lt;/p&gt;

&lt;p&gt;参考: &lt;a href=&#34;http://mizzy.org/blog/2013/10/29/1/&#34;&gt;インフラ系技術の流れ Bootstrapping/Configuration/Orchestration&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStackとAzureにDocker Swarmをかぶせてみた</title>
      <link>http://torumakabe.github.io/post/azure_openstack_swarm/</link>
      <pubDate>Sat, 19 Dec 2015 00:01:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_openstack_swarm/</guid>
      <description>

&lt;h2 id=&#34;どこいってもいじられる:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;どこいってもいじられる&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.adventar.org/calendars/968&#34;&gt;OpenStack Advent Calendar 2015&lt;/a&gt; 参加作品、19夜目のエントリです。&lt;/p&gt;

&lt;p&gt;OpenStackの最前線から離れて3か月がたちました。OpenStackつながりな方にお会いするたび、マイルドなかわいがりをうけます。ほんとうにありがとうございます。仕事としては専門でなくなりましたが、ユーザ会副会長の任期はまだ残っているので、積極的にいじられに行く所存です。でも笑いながら蹴ったりするのはやめてください。&lt;/p&gt;

&lt;p&gt;さて、毎年参加しているOpenStack Advent Calendarですが、せっかくだからいまの専門とOpenStackを組み合わせたいと思います。ここはひとつ、OpenStackとAzureを組み合わせて何かやってみましょう。&lt;/p&gt;

&lt;h2 id=&#34;乗るしかないこのdockerウェーブに:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;乗るしかないこのDockerウェーブに&lt;/h2&gt;

&lt;p&gt;どうせなら注目されている技術でフュージョンしたいですね。2015年を振り返って、ビッグウェーブ感が高かったのはなんでしょう。はい、Dockerです。Dockerを使ってOpenStackとAzureを組み合わせてみます。あまり難しいことをせず、シンプルにサクッとできることを。年末ですし、「正月休みにやってみっか」というニーズにこたえます。&lt;/p&gt;

&lt;p&gt;ところでOpenStack環境はどうやって調達しましょう。ちょっと前までは身の回りに売るほどあったのですが。探さないといけないですね。せっかくなので日本のサービスを探してみましょう。&lt;/p&gt;

&lt;p&gt;条件はAPIを公開していること。じゃないと、Dockerの便利なツール群が使えません。Linuxが動くサービスであれば、Docker環境をしみじみ手作業で夜なべして作れなくもないですが、嫌ですよね。正月休みは修行じゃなくて餅食って酒飲みたい。安心してください、わかってます。人力主義では、せっかくサクサク使えるDockerが台無しです。&lt;/p&gt;

&lt;p&gt;あと、当然ですが個人で気軽にオンラインで契約できることも条件です。&lt;/p&gt;

&lt;p&gt;そうすると、ほぼ一択。&lt;a href=&#34;https://www.conoha.jp/&#34;&gt;Conoha&lt;/a&gt;です。かわいらしい座敷童の&lt;a href=&#34;https://www.conoha.jp/conohadocs/?btn_id=top_footer_conotsu&#34;&gt;&amp;ldquo;このは&amp;rdquo;&lt;/a&gt;がイメージキャラのサービスです。作っているのは手練れなOSSANたちですが。&lt;/p&gt;

&lt;p&gt;では、AzureとConohaにDocker環境をサクッと作り、どちらにもサクッと同じコンテナを作る。もちろん同じCLIから。ということをしてみようと思います。&lt;/p&gt;

&lt;p&gt;今回大活躍するDoker Machine、Swarmの説明はしませんが、関心のある方は&lt;a href=&#34;http://www.slideshare.net/zembutsu/whats-new-aobut-docker-2015-network-and-orchestration&#34;&gt;前佛さんの資料&lt;/a&gt;を参考にしてください。&lt;/p&gt;

&lt;h2 id=&#34;ローカル環境:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;ローカル環境&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Mac OS X (El Capitan)

&lt;ul&gt;
&lt;li&gt;Docker Toolbox 1.9.1&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ローカル、Azure、ConohaすべてのDocker環境はDocker Machineでサクッと作ります。
また、Swarmのマスタはローカルに配置します。&lt;/p&gt;

&lt;h2 id=&#34;いざ実行:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;いざ実行&lt;/h2&gt;

&lt;p&gt;まず、Docker Machineにクラウドの諸設定を食わせます。&lt;/p&gt;

&lt;p&gt;Azure向けにサブスクリプションIDとCertファイルの場所を指定します。詳細は&lt;a href=&#34;https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-docker-machine/&#34;&gt;ここ&lt;/a&gt;を。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export AZURE_SUBSCRIPTION_ID=hoge-fuga-hoge-fuga-hoge
$ export AZURE_SUBSCRIPTION_CERT=~/.ssh/yourcert.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Conoha向けにOpenStack関連の環境変数をセットします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export OS_USERNAME=yourname
$ export OS_TENANT_NAME=yourtenantname
$ export OS_PASSWORD=yourpass
$ export OS_AUTH_URL=https://identity.tyo1.conoha.io/v2.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次はローカルコンテナ環境を整えます。&lt;/p&gt;

&lt;p&gt;Swarmコンテナを起動し、ディスカバリトークンを生成します。このトークンがSwarmクラスタの識別子です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create -d virtualbox local
$ eval &amp;quot;$(docker-machine env local)&amp;quot;
$ docker run swarm create    
Status: Downloaded newer image for swarm:latest
tokentokentokentoken
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このトークンは控えておきましょう。&lt;/p&gt;

&lt;p&gt;ではSwarmのマスタをローカルに作ります。先ほど生成したトークン指定を忘れずに。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://tokentokentokentoken head
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SwarmのエージェントをAzureに作ります。VMを作って、OSとDockerをインストールして、なんて不要です。Docker Machineがやってくれます。ここでもトークン指定を忘れずに。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval &amp;quot;$(docker-machine env head)&amp;quot;
$ docker-machine create -d azure --swarm --swarm-discovery token://tokentokentokentoken worker-azure01 --azure-location &amp;quot;East Asia&amp;quot; worker-azure00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Conohaにも同様に。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create -d openstack --openstack-flavor-name g-1gb --openstack-image-name vmi-ubuntu-14.04-amd64 --openstack-sec-groups &amp;quot;default,gncs-ipv4-all&amp;quot; --swarm --swarm-discovery token://tokentokentokentoken worker-conoha00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さあ環境がサクッと出来上がりました。これ以降はSwarmクラスタ全体を操作対象にします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval &amp;quot;$(docker-machine env --swarm head)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;環境をチラ見してみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker info
Containers: 4
Images: 3
 Role: primary
 Strategy: spread
 Filters: health, port, dependency, affinity, constraint
 Nodes: 3
 head: 192.168.99.101:2376
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.021 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Dec 18 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
 worker-azure00: xxx.cloudapp.net:2376
  └ Containers: 1
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.721 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=3.13.0-36-generic, operatingsystem=Ubuntu 14.04.1 LTS, provider=azure, storagedriver=aufs
 worker-conoha00: www.xxx.yyy.zzz:2376
  └ Containers: 1
  └ Reserved CPUs: 0 / 2
  └ Reserved Memory: 0 B / 1.019 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=3.16.0-51-generic, operatingsystem=Ubuntu 14.04.3 LTS, provider=openstack, storagedriver=aufs
CPUs: 4
Total Memory: 3.761 GiB
Name: 1234abcd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どこにどんな環境が作られたかが分かりますね。出力結果の4行目&amp;rdquo;Strategy: spread&amp;rdquo;を覚えておいてください。&lt;/p&gt;

&lt;p&gt;ではコンテナを作ってみましょう。Nginxコンテナ三連星です。どの環境に作るか、という指定はしません。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in `seq 1 3`; do docker run -d -p 80:80 nginx; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どんな具合でしょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                NAMES
9cc2f5594fa5        nginx               &amp;quot;nginx -g &#39;daemon off&amp;quot;   5 seconds ago       Up 4 seconds        192.168.99.101:80-&amp;gt;80/tcp, 443/tcp   head/goofy_goldberg
b9d54d794a85        nginx               &amp;quot;nginx -g &#39;daemon off&amp;quot;   32 seconds ago      Up 31 seconds       www.xxx.yyy.zzz:80-&amp;gt;80/tcp, 443/tcp   worker-conoha00/clever_chandrasekhar
19e9d0e229a2        nginx               &amp;quot;nginx -g &#39;daemon off&amp;quot;   45 seconds ago      Up 42 seconds       zzz.yyy.xxx.www:80-&amp;gt;80/tcp, 443/tcp    worker-azure00/reverent_bhaskara
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nginxコンテナがきれいに散らばっているのが分かります。これは先ほど覚えた&amp;rdquo;Strategy: spread&amp;rdquo;が効いているからです。StrategyはSwarmのコンテナ配置ポリシーで、speradを指定すると散らしにいきます。Strategyをbinpackにしておけば、ノードを埋めようとします。埋まったら他、です。randomであれば、ランダムに。&lt;/p&gt;

&lt;p&gt;まだシンプルですが、今後このStrategyやリソース管理が賢くなると、「ローカルが埋まったら、リモートを使う」とか、使い道が広がりそうですね。最近Docker社が買収した&lt;a href=&#34;https://www.tutum.co/&#34;&gt;Tutum&lt;/a&gt;との関係、今後どう進化していくのか、注目です。&lt;/p&gt;

&lt;h2 id=&#34;ツールから入るハイブリッドクラウドも-またよし:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;ツールから入るハイブリッドクラウドも、またよし&lt;/h2&gt;

&lt;p&gt;ハイブリッドクラウドはまだ言葉先行です。まだクラウドを使ってない、使いこなしていない段階でツールの話だけが先行することも多いです。ナイフとフォークしか使ったことのない人が、お箸を使う和食や中華を選ぶ前に「どんなお箸がいいかねぇ」と議論している感じ。僕は、そうじゃなくて、その前に食べたいもの = クラウドを選びましょうよ、というスタンスでした。&lt;/p&gt;

&lt;p&gt;でも、コンテナ+Dockerって、お箸に弁当ついてきたような感じなんですよね。お箸が使える人であれば、弁当持ち込める場所さえ確保すればいい。インパクトでかいです。ちょっと考えを改めました。&lt;/p&gt;

&lt;p&gt;もちろん、だからクラウドは何でもいい、と言っているわけではありません。弁当持ち込みとしても、スペースが広い、個室で静か、お茶がうまい、お茶がタダ、揚げたてのから揚げを出してくれる、などなど、特徴は出てくるでしょう。APIを公開していないような「持ち込みやめて」のクラウドは、先々心配ですが。&lt;/p&gt;

&lt;p&gt;簡単 = 正義です。簡単であれば使う人が増えて、要望が増えて、育ちます。かっちり感は後からついてくる。もしDockerで複数のクラウド環境を簡単に使いこなせるようになるのであれば、順番が逆ではありますが、お箸、Dockerというツールから入るのもいいかもしれません。&lt;/p&gt;

&lt;p&gt;まずは開発、検証環境など、リスク低いところから試して慣れていくのがおすすめです。触っていくうちに、いろいろ見えてくるでしょう。Dockerはもちろんですが、それぞれのクラウドの特徴も。&lt;/p&gt;

&lt;p&gt;OpenStackもAzureも、特徴を活かし、うまく使いこなしてほしいと思っております。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>