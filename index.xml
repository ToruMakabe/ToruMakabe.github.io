<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>re-imagine</title>
    <link>http://torumakabe.github.io/</link>
    <description>Recent content on re-imagine</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Mon, 15 Feb 2016 17:00:00 +0900</lastBuildDate>
    <atom:link href="http://torumakabe.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Azure DDoS対策ことはじめ</title>
      <link>http://torumakabe.github.io/post/azure_ddosprotection/</link>
      <pubDate>Mon, 15 Feb 2016 17:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_ddosprotection/</guid>
      <description>

&lt;h2 id=&#34;すこぶるfaq:4a620049922b1b54512a25b34ba773c5&#34;&gt;すこぶるFAQ&lt;/h2&gt;

&lt;p&gt;攻撃者の荒ぶり具合が高まっており、ご相談いただく機会が増えました。「どうすればいいか見当がつかない」というケースも少なくないので、DDoSに絞り、現時点で検討していただきたいことをシンプルにまとめます。&lt;/p&gt;

&lt;h2 id=&#34;公式ホワイトペーパー:4a620049922b1b54512a25b34ba773c5&#34;&gt;公式ホワイトペーパー&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://download.microsoft.com/download/C/A/3/CA3FC5C0-ECE0-4F87-BF4B-D74064A00846/AzureNetworkSecurity_v3_Feb2015.pdf&#34;&gt;Microsoft Azure Network Security Whitepaper V3&lt;/a&gt;が、現時点でのMicrosoft公式見解です。DDoS以外にもセキュリティ関連で考慮すべきことがまとまっています。おすすめです。&lt;/p&gt;

&lt;p&gt;今回はここから、DDoSに言及している部分を抜き出し意訳します。必要に応じて補足も入れます。&lt;/p&gt;

&lt;h3 id=&#34;2-2-security-management-and-threat-defense-protecting-against-ddos:4a620049922b1b54512a25b34ba773c5&#34;&gt;2.2 Security Management and Threat Defense - Protecting against DDoS&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;To protect Azure platform services, Microsoft provides a distributed denial-of-service (DDoS) defense system that is part of Azure’s continuous monitoring process, and is continually improved through penetration-testing. Azure’s DDoS defense system is designed to not only withstand attacks from the outside, but also from other Azure tenants:&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MicrosoftはDDoSを防ぐ仕組み提供しており、Azure外部からの攻撃はもちろんのこと、Azure内部で別テナントから攻撃されることも考慮しています。&lt;/p&gt;

&lt;h2 id=&#34;azureがやってくれること:4a620049922b1b54512a25b34ba773c5&#34;&gt;Azureがやってくれること&lt;/h2&gt;

&lt;p&gt;では、具体的に。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;1. Network-layer high volume attacks. These attacks choke network pipes and packet processing capabilities by flooding the network with packets. The Azure DDoS defense technology provides detection and mitigation techniques such as SYN cookies, rate limiting, and connection limits to help ensure that such attacks do not impact customer environments.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ネットワークレイヤで検知できる力押しは、AzureのDDoS防御システムが検知、緩和します。このホワイトペーパーのAppendixで図解されていますが、IDS/IPSがその中心です。SYN Cookieやレート制限、コネクション制限などのテクニックを使います。&lt;/p&gt;

&lt;h2 id=&#34;お客様対応が必要なこと:4a620049922b1b54512a25b34ba773c5&#34;&gt;お客様対応が必要なこと&lt;/h2&gt;

&lt;p&gt;ですが、アプリケーションレイヤの攻撃は、AzureのDDoS防御システムだけでは防ぎきれません。お客様のアプリや通信の内容、要件まで踏み込めないからです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;2. Application-layer attacks. These attacks can be launched against a customer VM. Azure does not provide mitigation or actively block network traffic affecting individual customer deployments, because the infrastructure does not interpret the expected behavior of customer applications. In this case, similar to on-premises deployments, mitigations include:&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のような対処が有効です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Running multiple VM instances behind a load-balanced Public IP address.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;攻撃されるポイントを負荷分散装置のパブリックIPに限定し、複数のVMへ負荷を散らします。 攻撃されても、できる限り踏ん張るアプローチです。AzureのIDS/IPSで緩和しきれなかったトラフィックを受け止め、ダウンしないようにします。攻撃規模は事前に判断できないので、どれだけスケールさせるかは、ダウンした場合のビジネスインパクトとコストの兼ね合いで決める必要があります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Using firewall proxy devices such as Web Application Firewalls (WAFs) that terminate and forward traffic to endpoints running in a VM. This provides some protection against a broad range of DoS and other attacks, such as low-rate, HTTP, and other application-layer threats. Some virtualized solutions, such as Barracuda Networks, are available that perform both intrusion detection and prevention.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;WAFを入れて、通信の中身を見ないとわからない攻撃を検知、緩和します。一見ノーマルなトラフィックでも「ゆっくりと攻撃」するようなケースもあります。たとえば、ゆっくりWebサーバのコネクションを枯渇させるような攻撃など。Azureでは仮想アプライアンスとして、Barracuda NetworksのWAFなどが使えます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot; Web Server add-ons that protect against certain DoS attacks.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Webサーバへアドインを入れましょう。パッチも適用しましょう。構成も見直しましょう。ちょっと古いですが&lt;a href=&#34;http://blogs.msdn.com/b/friis/archive/2014/12/30/security-guidelines-to-detect-and-prevent-dos-attacks-targeting-iis-azure-web-role-paas.aspx&#34;&gt;ここ&lt;/a&gt;が参考になります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Network ACLs, which can prevent packets from certain IP addresses from reaching VMs.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もしブロックしたいアクセス元IPアドレスがわかるなら、ACLで遮断しましょう。逆に通信可能な範囲のみ指定することもできます。&lt;/p&gt;

&lt;h2 id=&#34;ホワイトペーパーに加えて:4a620049922b1b54512a25b34ba773c5&#34;&gt;ホワイトペーパーに加えて&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/services/cdn/&#34;&gt;CDN&lt;/a&gt;も有効ですので検討ください。2段構えでの負荷分散、防御ができます。Akamaiとの統合ソリューションも今後&lt;a href=&#34;https://azure.microsoft.com/ja-jp/blog/microsoft-and-akamai-bring-cdn-to-azure-customers/&#34;&gt;提供される予定&lt;/a&gt;です。&lt;/p&gt;

&lt;p&gt;CDNは常に世界中からのトラフィックで揉まれているだけあって、DDoS防御四天王で最強の漢が最初に出てくるくらい強力です。&lt;/p&gt;

&lt;p&gt;最後に。攻撃されている感があれば、カスタマーサポートまで。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure Blob Upload ツール別ベンチマーク</title>
      <link>http://torumakabe.github.io/post/azureblobupload_perf/</link>
      <pubDate>Thu, 11 Feb 2016 12:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azureblobupload_perf/</guid>
      <description>

&lt;h2 id=&#34;同じ目的を達成できるツールがたくさん:2c3afc565a3430f70519d9c56354717c&#34;&gt;同じ目的を達成できるツールがたくさん&lt;/h2&gt;

&lt;p&gt;やりたいことがあり、それを達成する手段がたくさん。どう選ぼう。じゃあ特徴を知りましょう。という話です。&lt;/p&gt;

&lt;p&gt;端末からAzureへファイルをアップロードする手段は多くあります。CLIツール、GUIツール、SDKで自作する、etc。&lt;/p&gt;

&lt;p&gt;そして、端末と、そのおかれている環境も多様です。Windows、Mac。有線、無線。&lt;/p&gt;

&lt;p&gt;で、大事なのは平行度。ブロックBlobはブロックを平行に転送する方式がとれるため、ツールが平行転送をサポートしているか? どのくらい効くのか? は重要な評価ポイントです。&lt;/p&gt;

&lt;p&gt;なので、どのツールがおすすめ?と聞かれても、条件抜きでズバっとは答えにくい。そしてこの質問は頻出。なのでこんな記事を書いています。&lt;/p&gt;

&lt;h2 id=&#34;環境と測定方式:2c3afc565a3430f70519d9c56354717c&#34;&gt;環境と測定方式&lt;/h2&gt;

&lt;p&gt;おそらくファイルを送る、という用途でもっとも重視すべき特徴は転送時間でしょう。ではツール、環境別に転送時間を測定してみます。&lt;/p&gt;

&lt;p&gt;環境は以下の通り。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Windows端末

&lt;ul&gt;
&lt;li&gt;Surface Pro 4 Core i7/16GB Memory/802.11ac&lt;/li&gt;
&lt;li&gt;1Gbps Ethernet (USB経由)&lt;/li&gt;
&lt;li&gt;Windows 10 (1511)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Mac端末

&lt;ul&gt;
&lt;li&gt;Macbook 12inch Core M/8GB Memory/802.11ac&lt;/li&gt;
&lt;li&gt;USB-C&amp;hellip; 有線テストは省きます&lt;/li&gt;
&lt;li&gt;El Capitan&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Wi-Fiアクセスポイント/端末間帯域

&lt;ul&gt;
&lt;li&gt;100~200Mbpsでつながっています&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Azureデータセンタまでの接続

&lt;ul&gt;
&lt;li&gt;日本マイクロソフトの品川オフィスから、首都圏にあるAzure Japan Eastリージョンに接続&lt;/li&gt;
&lt;li&gt;よってWAN側の遅延、帯域ともに条件がいい&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;対象ツール

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-use-azcopy/&#34;&gt;AzCopy v5.0.0.27&lt;/a&gt; (Windowsのみ)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/xplat-cli-install/&#34;&gt;Azure CLI v0.9.15&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://storageexplorer.com/&#34;&gt;Azure Storage Explorer - Cross Platform GUI v0.7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;転送ファイル

&lt;ul&gt;
&lt;li&gt;Ubuntu 15.10 ISOイメージ (647MBytes)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そして測定方式。&lt;/p&gt;

&lt;p&gt;AzCopyはPowerShellのMeasure-Commandにて実行時間をとります。NCが平行度指定です。デフォルトの平行度はCPUコア数の8倍です。わしのSurface、OSから4コア見えていますので、32。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Measure-Command {AzCopy /Source:C:\Users\myaccount\work /Dest:https://myaccount.blob.core.windows.net/mycontainer /DestKey:mykey /Pattern:ubuntu-15.10-server-amd64.iso /Y /NC:count}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Azure CLIも同様にMeasure-Commandで。&amp;ndash;concurrenttaskcountで平行度を指定できますが、&lt;a href=&#34;https://github.com/Azure/azure-xplat-cli/blob/dev/lib/util/storage.util._js&#34;&gt;ソース&lt;/a&gt;を確認したところ、平行度のデフォルトは5です。&amp;rdquo;StorageUtil.threadsInOperation = 5;&amp;ldquo;ですね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Measure-Command {azure storage blob upload ./ubuntu-15.10-server-amd64.iso -a myaccount -k mykey mycontainer ubuntu1510 --concurrenttaskcount count}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;残念ながらMacむけAzCopyはありませんので、Azure CLIのみ実行します。timeコマンドで時間をとります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time azure storage blob upload ./ubuntu-15.10-server-amd64.iso -a myaccount -k mykey mycontainer ubuntu1510 --concurrenttaskcount count
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Azure Storage Explorer Cross Platform GUIは、目視+iPhoneのストップウォッチで。&lt;/p&gt;

&lt;h2 id=&#34;結果:2c3afc565a3430f70519d9c56354717c&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;平行度上げても伸びないな、というタイミングまで上げます。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;　実行No　&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;　クライアントOS　&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;　ネットワーク接続　&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;　クライアント　&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;　並行数　&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;　転送時間(秒)　&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:32)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.62&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.28&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.83&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.43&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:5)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49.92&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29.47&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21.05&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20.12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1Gbps Ethernet&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Storage Explorer&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;N/A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50.10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:32)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74.87&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;53.32&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AzCopy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;58.85&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:5)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;57.23&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50.71&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;54.37&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Windows 10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Storage Explorer&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;N/A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;54.63&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mac OS X&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;(default:5)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40.86&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mac OS X&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33.97&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mac OS X&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Azure CLI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;58.57&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mac OS X&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;802.11ac&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Storage Explorer&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;N/A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;58.20&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;考察:2c3afc565a3430f70519d9c56354717c&#34;&gt;考察&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;有線AzCopy早い。単純計算で67MByte/s出ています。それぞれの計測点の解釈の違いでBlobサービス制限の60MBytes/sを超えてしまっていますがw。データセンタまでのボトルネックがなければ、ポテンシャルを引き出せることがわかります。&lt;/li&gt;
&lt;li&gt;平行度は大きく性能に影響します。

&lt;ul&gt;
&lt;li&gt;平行度が高すぎてもだめ

&lt;ul&gt;
&lt;li&gt;無線AzCopyのデフォルト(平行度32)が平行度10、20より時間がかかっていることからわかる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;デフォルトで遅いからといってあきらめず、平行度変えて試してみましょう&lt;/li&gt;
&lt;li&gt;SDK使って自分で作る時も同じ。平行度パラメータを意識してください

&lt;ul&gt;
&lt;li&gt;.NET: BlobRequestOptions&lt;/li&gt;
&lt;li&gt;Java/Android: BlobRequestOptions.setConcurrentRequestCount()&lt;/li&gt;
&lt;li&gt;Node.js: parallelOperationThreadCount&lt;/li&gt;
&lt;li&gt;C++: blob_request_options::set_parallelism_factor&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Azure CLIよりAzCopyが早い。

&lt;ul&gt;
&lt;li&gt;.NETで最適化できているから合点&lt;/li&gt;
&lt;li&gt;Node.jsベースでマルチOS対応のAzure CLIは比べられると分が悪い&lt;/li&gt;
&lt;li&gt;でも、802.11acでも無線がボトルネックになっているので、いまどきのWi-Fi環境では似たような性能になる&lt;/li&gt;
&lt;li&gt;No.18の結果は無線状態がよかったと想定&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Azure Storage Explorer Cross Platform GUIは、現時点で平行度変えられないので性能面では不利。でも直観的なので、使い分け。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WAN条件がいいベンチマークでなので、ぜひみなさんの条件でも試してみてください。遅延の大きなリージョンや途中に帯域ボトルネックがある条件でやると、最適な平行度が変わってくるはずです。&lt;/p&gt;

&lt;p&gt;でも一番言いたかったのは、Macbookの有線アダプタ欲しいということです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux on Azureでファイル共有する方法</title>
      <link>http://torumakabe.github.io/post/fileshare_linuxonazure/</link>
      <pubDate>Sun, 07 Feb 2016 17:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/fileshare_linuxonazure/</guid>
      <description>

&lt;h2 id=&#34;ファイル共有-あまりおすすめしないです:fa176ff87dca43c3d098f48095435bba&#34;&gt;ファイル共有、あまりおすすめしないです&lt;/h2&gt;

&lt;p&gt;いきなりタイトルを否定しました。ロック。&lt;/p&gt;

&lt;p&gt;さて、これからクラウド、というお客様に、よく聞かれる質問があります。それは「NFSとかの、ファイル共有使える?」です。頻出です。クラウド頻出質問選手権では、西東京予選で毎年ベスト8入りするレベルの強豪校です。&lt;/p&gt;

&lt;p&gt;ですが&lt;strong&gt;個人的には&lt;/strong&gt;あまりおすすめしません。クラウドはなるべく共有部分を減らして、スケーラブルに、かつ障害の影響範囲を局所化するべき、と考えるからです。特にストレージはボトルネックや広範囲な障害の要因になりやすい。障害事例が物語ってます。その代わりにオブジェクトストレージなど、クラウド向きの機能がおすすめです。&lt;/p&gt;

&lt;p&gt;でも、否定はしません。アプリの作りを変えられないケースもあるかと思います。&lt;/p&gt;

&lt;p&gt;そこで、もしAzureでファイル共有が必要であれば、&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-introduction/&#34;&gt;Azure File Storage&lt;/a&gt;を検討してみてください。Azureのマネージドサービスなので、わざわざ自分でサーバたてて運用する必要がありません。楽。&lt;/p&gt;

&lt;p&gt;対応プロトコルは、SMB2.1 or 3.0。LinuxからはNFSじゃなくSMBでつついてください。&lt;/p&gt;

&lt;p&gt;使い方は公式ドキュメントを。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-azure-cli/#create-and-manage-file-shares&#34;&gt;&amp;ldquo;Azure Storage での Azure CLI の使用&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-how-to-use-files-linux/&#34;&gt;&amp;ldquo;Linux で Azure File Storage を使用する方法&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;もうちょっと情報欲しいですね。補足のためにわたしも流します。&lt;/p&gt;

&lt;h2 id=&#34;azure-cliでストレージアカウントを作成し-ファイル共有を設定:fa176ff87dca43c3d098f48095435bba&#34;&gt;Azure CLIでストレージアカウントを作成し、ファイル共有を設定&lt;/h2&gt;

&lt;p&gt;ストレージアカウントを作ります。fspocは事前に作っておいたリソースグループです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local$ azure storage account create tomakabefspoc -l &amp;quot;Japan East&amp;quot; --type LRS -g fspoc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ストレージアカウントの接続情報を確認します。必要なのはdata: connectionstring:の行にあるAccountKey=以降の文字列です。このキーを使ってshareの作成、VMからのマウントを行うので、控えておいてください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local$ azure storage account connectionstring show tomakabefspoc -g fspoc
info:    Executing command storage account connectionstring show
+ Getting storage account keys
data:    connectionstring: DefaultEndpointsProtocol=https;AccountName=tomakabefspoc;AccountKey=qwertyuiopasdfghjklzxcvbnm==
info:    storage account connectionstring show command OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;shareを作成します。share名はfspocshareとしました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local$ azure storage share create -a tomakabefspoc -k qwertyuiopasdfghjklzxcvbnm== fspocshare
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;エンドポイントを確認しておきましょう。VMからのマウントの際に必要です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;local$ azure storage account show tomakabefspoc -g fspoc
[snip]
data:    Primary Endpoints: file https://tomakabefspoc.file.core.windows.net/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;linux-2vmで共有:fa176ff87dca43c3d098f48095435bba&#34;&gt;Linux * 2VMで共有&lt;/h2&gt;

&lt;p&gt;Ubuntuでやりますよ。SMBクライアントとしてcifs-utilsパッケージをインストールします。&lt;a href=&#34;https://azure.microsoft.com/ja-jp/marketplace/partners/canonical/ubuntuserver1404lts/&#34;&gt;Marketplace提供の14.04 LTS&lt;/a&gt;であれば、すでに入ってるはずです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm01:~$ sudo apt-get install cifs-utils
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マウントポイントを作り、マウントします。接続先の指定はエンドポイント+share名で。usernameはストレージアカウント名。パスワードはストレージアカウントのキーです。
パーミッションは要件に合わせてください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm01:~$ sudo mkdir -p /mnt/fspoc
fspocvm01:~$ sudo mount -t cifs //tomakabefspoc.file.core.windows.net/fspocshare /mnt/fspoc -o vers=3.0,username=tomakabefspoc,password=qwertyuiopasdfghjklzxcvbnm==,dir_mode=0777,file_mode=0777
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マウント完了。確認用のファイルを作っておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm01:~$ echo &amp;quot;test&amp;quot; &amp;gt; /mnt/fspoc/test.txt
fspocvm01:~$ cat /mnt/fspoc/test.txt
test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2台目のVMでも同様のマウント作業を。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm02:~$ sudo apt-get install cifs-utils
fspocvm02:~$ sudo mkdir -p /mnt/fspoc
fspocvm02:~$ sudo mount -t cifs //tomakabefspoc.file.core.windows.net/fspocshare /mnt/fspoc -o vers=3.0,username=tomakabefspoc,password=qwertyuiopasdfghjklzxcvbnm==,dir_mode=0777,file_mode=0777
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1台目で作ったファイルが見えますね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm02:~$ ls /mnt/fspoc
test.txt
fspocvm02:~$ cat /mnt/fspoc/test.txt
test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ファイルをいじりましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm02:~$ echo &amp;quot;onemoretest&amp;quot; &amp;gt;&amp;gt; /mnt/fspoc/test.txt
fspocvm02:~$ cat /mnt/fspoc/test.txt
test
onemoretest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1台目から確認。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fspocvm01:~$ cat /mnt/fspoc/test.txt
test
onemoretest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ご利用は計画的に:fa176ff87dca43c3d098f48095435bba&#34;&gt;ご利用は計画的に&lt;/h2&gt;

&lt;p&gt;2016年2月時点で、Azure File Storageには最大容量:5TB/share、1TB/file、ストレージアカウントあたりの帯域:60MBytes/sという制約があります。これを超えるガチ共有案件では、&lt;a href=&#34;https://azure.microsoft.com/en-us/marketplace/partners/intel/lustre-cloud-edition-evaleval-lustre-2-7/&#34;&gt;Lustre&lt;/a&gt;など別の共有方法を検討してください。&lt;/p&gt;

&lt;p&gt;なおファイルサーバ用途であれば、Azure File Storageではなく、OneDriveなどオンラインストレージSaaSに移行した方が幸せになれると思います。企業向けが使いやすくなってきましたし。運用から解放されるだけじゃなく、便利ですよ。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux on AzureでDisk IO性能を確保する方法</title>
      <link>http://torumakabe.github.io/post/striping_linuxonazure/</link>
      <pubDate>Wed, 27 Jan 2016 00:19:30 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/striping_linuxonazure/</guid>
      <description>

&lt;h2 id=&#34;俺の鉄板-ができるまで:cfa04af83b137faef18a5d4e4444f400&#34;&gt;&amp;ldquo;俺の鉄板&amp;rdquo;ができるまで&lt;/h2&gt;

&lt;p&gt;前半はポエムです。おそらくこのエントリにたどり着く人の期待はLinux on AzureのDisk IO性能についてと思いますが、それは後半に書きます。&lt;/p&gt;

&lt;p&gt;クラウド、Azureに関わらず、技術や製品の組み合わせは頭の痛い問題です。「これとこれ、組み合わせて動くの？サポートされるの？性能出るの？」という、あれです。技術や製品はどんどん進化しますので、同じ組み合わせが使えることは珍しくなってきています。&lt;/p&gt;

&lt;p&gt;ちなみにお客様のシステムを設計する機会が多いわたしは、こんな流れで検討します。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;構成要素全体を俯瞰したうえで、調査が必要な技術や製品、ポイントを整理する

&lt;ul&gt;
&lt;li&gt;やみくもに調べものしないように&lt;/li&gt;
&lt;li&gt;経験あるアーキテクトは実績ある組み合わせや落とし穴を多くストックしているので、ここが早い&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ベンダの公式資料を確認する

&lt;ul&gt;
&lt;li&gt;「この使い方を推奨/サポートしています」と明記されていれば安心&lt;/li&gt;
&lt;li&gt;でも星の数ほどある技術や製品との組み合わせがすべて網羅されているわけではない&lt;/li&gt;
&lt;li&gt;不明確なら早めに問い合わせる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ベンダが運営しているコミュニティ上の情報を確認する

&lt;ul&gt;
&lt;li&gt;ベンダの正式見解ではない場合もあるが、その製品を担当する社員が書いている情報には信ぴょう性がある&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;コミュニティや有識者の情報を確認する

&lt;ul&gt;
&lt;li&gt;OSSでは特に&lt;/li&gt;
&lt;li&gt;専門性を感じるサイト、人はリストしておく&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;動かす

&lt;ul&gt;
&lt;li&gt;やっぱり動かしてみないと&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;提案する

&lt;ul&gt;
&lt;li&gt;リスクがあれば明示します&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;問題なければ実績になる、問題があればリカバリする

&lt;ul&gt;
&lt;li&gt;提案しっぱなしにせずフォローすることで、自信とパターンが増える&lt;/li&gt;
&lt;li&gt;次の案件で活きる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;いまのわたしの課題は4、5です。特にOSS案件。AzureはOSSとの組み合わせを推進していて、ここ半年でぐっと情報増えたのですが、まだ物足りません。断片的な情報を集め、仮説を立て、動かす機会が多い。なので、5を増やして、4の提供者側にならんとなぁ、と。&lt;/p&gt;

&lt;h2 id=&#34;linux-on-azureでdisk-io性能を確保する方法:cfa04af83b137faef18a5d4e4444f400&#34;&gt;Linux on AzureでDisk IO性能を確保する方法&lt;/h2&gt;

&lt;p&gt;さて今回の主題です。&lt;/p&gt;

&lt;p&gt;結論: Linux on AzureでDisk IOを最大化するには、MDによるストライピングがおすすめ。いくつかパラメータを意識する。&lt;/p&gt;

&lt;p&gt;Linux on AzureでDisk IO性能を必要とする案件がありました。検討したアイデアは、SSDを採用したPremium Storageを複数束ねてのストライピングです。Premium Storageはディスクあたり5,000IOPSを期待できます。でも、それで足りない恐れがありました。なので複数並べて平行アクセスし、性能を稼ぐ作戦です。&lt;/p&gt;

&lt;p&gt;サーバ側でのソフトウェアストライピングは古くからあるテクニックで、ハードの能力でブン殴れそうなハイエンドUnixサーバとハイエンドディスクアレイを組み合わせた案件でも、匠の技として使われています。キャッシュやアレイコントローラ頼りではなく、明示的にアクセスを分散することで性能を確保することができます。&lt;/p&gt;

&lt;p&gt;Linuxで使える代表的なストライプ実装は、LVMとMD。&lt;/p&gt;

&lt;p&gt;ではAzure上でどちらがを選択すべきでしょう。この案件では性能が優先事項です。わたしはその時点で判断材料を持っていませんでした。要調査。この絞り込みまでが前半ポエムの1です。&lt;/p&gt;

&lt;p&gt;前半ポエムの2、3はググ、もといBing力が試される段階です。わたしは以下の情報にたどり着きました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-linux-configure-raid/&#34;&gt;&amp;ldquo;Configure Software RAID on Linux&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-premium-storage-preview-portal/&#34;&gt;&amp;ldquo;Premium Storage: Azure 仮想マシン ワークロード向けの高パフォーマンス ストレージ&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blogs.msdn.com/b/igorpag/archive/2014/10/23/azure-storage-secrets-and-linux-i-o-optimizations.aspx&#34;&gt;&amp;ldquo;Azure Storage secrets and Linux I/O optimizations&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;得られた情報の中で大事なのは、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;公式ドキュメントで

&lt;ul&gt;
&lt;li&gt;LVMではなくMDを使った構成例が紹介されている&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;マイクロソフトがホストするブログ(MSDN)で、エキスパートが

&lt;ul&gt;
&lt;li&gt;LVMと比較したうえで、MDをすすめている&lt;/li&gt;
&lt;li&gt;MDのChunkサイズについて推奨値を紹介している&lt;/li&gt;
&lt;li&gt;そのほか、ファイルシステムやスケジューラに関する有益な情報あり&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;なるほど。わたしのこの時点での方針はこうです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LVMを使う必然性はないため、MDに絞る

&lt;ul&gt;
&lt;li&gt;LVMのほうが機能豊富だが、目的はストライピングだけであるため、シンプルなほうを&lt;/li&gt;
&lt;li&gt;物理障害対策はAzureに任せる (3コピー)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;MDのChunkをデフォルトの512KBから64KBに変更する (ここは結果によって調整)&lt;/li&gt;
&lt;li&gt;Premium StorageのキャッシュはReadOnly or Noneにする予定であるため、ファイルシステムのバリアを無効にする&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上記シナリオで、ディスク当たり5,000IOPS、ストライプ数に比例した性能が実際出れば提案価値あり、ということになります。
ですが、ズバリな実績値が見つからない。ダラダラ探すのは時間の無駄。これは自分でやるしかない。&lt;/p&gt;

&lt;p&gt;構成手順は前述のリンク先にありますが、ポイントを抜き出します。OS=Ubuntu、ファイルシステム=ext4の場合です。&lt;/p&gt;

&lt;p&gt;MDでストライプを作る際、チャンクを64KBに変更します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mdadm --create /dev/md127 --level 0 --raid-devices 2  /dev/sdc1 /dev/sdd1 -c 64k
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;マウント時にバリアを無効にします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mount /dev/md127 /mnt -o barrier=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では、Premium Storage(P30)をMDで2つ束ねたストライプにfioを実行してみましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;100% Random Read&lt;/li&gt;
&lt;li&gt;キャッシュ効果のないデータをとるため、Premium StorageのキャッシュはNone、fio側もdirect=1&lt;/li&gt;
&lt;li&gt;ブロックサイズは小さめの値が欲しかったので、1K&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;結果。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;randread: (g=0): rw=randread, bs=1K-1K/1K-1K/1K-1K, ioengine=libaio, iodepth=32
fio-2.1.3
Starting 1 process

randread: (groupid=0, jobs=1): err= 0: pid=9193: Tue Jan 26 05:48:09 2016
  read : io=102400KB, bw=9912.9KB/s, iops=9912, runt= 10330msec
[snip]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2本束ねて9,912IOPS。1本あたりほぼ5,000IOPS。ほぼ期待値。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>クラウドは本当に性能不足なのか</title>
      <link>http://torumakabe.github.io/post/doubt_lackofperf_oncloud/</link>
      <pubDate>Sun, 24 Jan 2016 00:19:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/doubt_lackofperf_oncloud/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;このエントリは2016/1/24に書きました。使えるリソースはどんどん増えていくので、適宜その時点で情報をとってください。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;具体的な数値で-正しい理解を:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;具体的な数値で、正しい理解を&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://itpro.nikkeibp.co.jp/atcl/watcher/14/334361/011800463/&#34;&gt;&amp;ldquo;クラウドは性能不足、企業システムが重すぎる&amp;rdquo;&lt;/a&gt;という記事が身の回りで話題になりました。公開から4日たっても「いま読まれている記事」の上位にあり、注目されているようです。&lt;/p&gt;

&lt;p&gt;記事で訴えたかったことは、クラウドを過信しないように、そして、クラウドはクラウドらしい使い方をしよう、ということでしょう。ユーザの声は貴重ですし、同意できるところも多い。でも、「企業システム」とひとくくりにしてしまったこと。タイトルのバイアスが強いこと。そして、具体的な根拠に欠けることから、誤解を招いている印象です。&lt;/p&gt;

&lt;p&gt;どんな技術、製品、サービスにも限界や制約はあります。具体的な数値や仕様で語らないと、そこから都市伝説が生まれます。&lt;/p&gt;

&lt;p&gt;いい機会なので、わたしの主戦場であるAzureを例に、クラウドでどのくらいの性能を期待できるか、まとめてみようと思います。&lt;/p&gt;

&lt;h2 id=&#34;シングルvmでどれだけ:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;シングルVMでどれだけ&lt;/h2&gt;

&lt;p&gt;話題となった記事でも触れられているように、クラウドはその生まれから、分散、スケールアウトな作りのアプリに向いています。ですが世の中には「そうできない」「そうするのが妥当ではない」システムもあります。記事ではそれを「企業システム」とくくっているようです。&lt;/p&gt;

&lt;p&gt;わたしは原理主義者ではないので「クラウドに載せたかったら、そのシステムを作り直せ」とは思いません。作りを大きく変えなくても載せられる、それでクラウドの特徴を活かして幸せになれるのであれば、それでいいです。もちろん最適化するにこしたことはありませんが。&lt;/p&gt;

&lt;p&gt;となると、クラウド活用の検討を進めるか、あきらめるか、判断材料のひとつは「スケールアウトできなくても、性能足りるか?」です。&lt;/p&gt;

&lt;p&gt;この場合、1サーバ、VMあたりの性能上限が制約です。なので、AzureのシングルVM性能が鍵になります。&lt;/p&gt;

&lt;p&gt;では、Azureの仮想マシンの提供リソースを確認しましょう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/virtual-machines-size-specs/&#34;&gt;&amp;ldquo;仮想マシンのサイズ&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ざっくりA、D、Gシリーズに分けられます。Aは初期からあるタイプ。ＤはSSDを採用した現行の主力。Gは昨年後半からUSリージョンで導入がはじまった、大物です。ガンダムだと後半、宇宙に出てから登場するモビルアーマー的な存在。現在、GシリーズがもっともVMあたり多くのリソースを提供できます。&lt;/p&gt;

&lt;p&gt;企業システムではOLTPやIOバウンドなバッチ処理が多いと仮定します。では、Gシリーズ最大サイズ、Standard_GS5の主な仕様から、OLTPやバッチ処理性能の支配要素となるCPU、メモリ、IOPSを見てみましょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Standard_GS5の主な仕様

&lt;ul&gt;
&lt;li&gt;32仮想CPUコア&lt;/li&gt;
&lt;li&gt;448GBメモリ&lt;/li&gt;
&lt;li&gt;80,000IOPS&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;メモリはクラウドだからといって特記事項はありません。クラウドの特徴が出るCPUとIOPSについて深掘りしていきます。&lt;/p&gt;

&lt;p&gt;なお、&lt;strong&gt;現時点で&lt;/strong&gt;まだ日本リージョンにはGシリーズが投入されていません。必要に応じ、公開スペックと後述のACUなどを使ってA、Dシリーズと相対評価してください。&lt;/p&gt;

&lt;h2 id=&#34;32仮想cpuコアの規模感:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;32仮想CPUコアの規模感&lt;/h2&gt;

&lt;p&gt;クラウドのCPU性能表記は、なかなか悩ましいです。仮想化していますし、CPUは世代交代していきます。ちなみにAzureでは、ACU(Azure Compute Unit)という単位を使っています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/virtual-machines-size-specs/#-3&#34;&gt;&amp;ldquo;パフォーマンスに関する考慮事項&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ACUはAzure内で相対評価をする場合にはいいのですが、「じゃあAzureの外からシステムもってきたとき、実際どのくらいさばけるのよ。いま持ってる/買えるサーバ製品でいうと、どのくらいよ」という問いには向きません。&lt;/p&gt;

&lt;p&gt;クラウドや仮想化に関わらず、アプリの作りと処理するデータ、ハードの組み合わせで性能は変わります。動かしてみるのが一番です。せっかくイニシャルコストのかからないクラウドです。試しましょう。でもその前に、試す価値があるか判断しなければいけない。なにかしらの参考値が欲しい。予算と組織で動いてますから。わかります。&lt;/p&gt;

&lt;p&gt;では例をあげましょう。&lt;strong&gt;俺のベンチマーク&lt;/strong&gt;を出したいところですが、「それじゃない」と突っ込まれそうです。ここはぐっと我慢して、企業でよく使われているERP、SAPのSAP SDベンチマークにしましょう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://global.sap.com/campaigns/benchmark/appbm_cloud.epx&#34;&gt;&amp;ldquo;SAP Standard Application Benchmarks in Cloud Environments&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://global.sap.com/campaigns/benchmark/index.epx&#34;&gt;&amp;ldquo;SAP Standard Application Benchmarks&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SAPSという値が出てきます。販売管理アプリケーションがその基盤上でどれだけ仕事ができるかという指標です。&lt;/p&gt;

&lt;p&gt;比較のため、3年ほど前の2ソケットマシン、現行2ソケットマシン、現行4ソケットマシンを選びました。単体サーバ性能をみるため、APとDBを1台のサーバにまとめた、2-Tierの値をとります。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;http://download.sap.com/download.epd?context=40E2D9D5E00EEF7C91D3C5AFFF9A4689C82EA97027CDF4A42858AD1610A3F732&#34;&gt;DELL R720&lt;/a&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;http://global.sap.com/campaigns/benchmark/assets/Cert15038.pdf&#34;&gt;Azure VM GS5&lt;/a&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;http://download.sap.com/download.epd?context=40E2D9D5E00EEF7CFDB9CAEA540B6F601993E4359AB45BEF7ED0949D1BFF155D&#34;&gt;NEC R120f-2M&lt;/a&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;http://download.sap.com/download.epd?context=40E2D9D5E00EEF7C14B03FD143D20C6C90E8F6DEAA4E15F8090BA77A6249E1D0&#34;&gt;FUJITSU RX4770 M2&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Date&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;sup&gt;2012&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;sup&gt;2015&lt;/sup&gt;&amp;frasl;&lt;sub&gt;9&lt;/sub&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;sup&gt;2015&lt;/sup&gt;&amp;frasl;&lt;sub&gt;7&lt;/sub&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;sup&gt;2015&lt;/sup&gt;&amp;frasl;&lt;sub&gt;7&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;CPU Type&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Intel Xeon Processor E5-2690&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Intel Xeon Processor E5-2698B v3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Intel Xeon Processor E5-2699 v3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Intel Xeon Processor E7-8890 v3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;CPU Sockets&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;CPU Cores&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;32 (Virtual)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;SD Benchmark Users&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6,500&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7,600&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14,440&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;29,750&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;SAPS&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;35,970&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;41,670&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;79,880&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;162,500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;3年前の2ソケットマシンより性能はいい。現行2ソケットマシンの半分程度が期待値でしょうか。ざっくりE5-2699 v3の物理18コアくらい。4ソケットは無理め。&lt;/p&gt;

&lt;p&gt;なお補足ですが、もちろんSAPはAPサーバをスケールアウトする構成もとれます。その性能は&lt;a href=&#34;http://global.sap.com/campaigns/benchmark/appbm_cloud.epx&#34;&gt;3-Tierベンチマーク&lt;/a&gt;で確認できます。&lt;a href=&#34;http://blogs.msdn.com/b/saponsqlserver/archive/2015/10/05/world-record-sap-sales-and-distribution-standard-application-benchmark-for-sap-cloud-deployments-released-using-azure-iaas-vms.aspx&#34;&gt;Azure上で247,880SAPS&lt;/a&gt;出たそうです。&lt;/p&gt;

&lt;h2 id=&#34;80-000iopsの規模感:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;80,000IOPSの規模感&lt;/h2&gt;

&lt;p&gt;IOPS = IO Per Second、秒あたりどれだけIOできるかという指標です。Azure VM GS5では&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/storage-premium-storage-preview-portal/&#34;&gt;Premium Storage&lt;/a&gt;を接続し、VMあたり最大80,000IOPSを提供します。&lt;/p&gt;

&lt;p&gt;一般的に企業で使われているディスクアレイに載っているHDDのIOPSは、1本あたりおおよそ200です。IOPSに影響する要素は回転数で、よく回る15,000rpm FC/SAS HDDでだいたいこのくらい。&lt;/p&gt;

&lt;p&gt;なので80,000 / 200 = 400。よって80,000IOPSを達成しようとすると、HDDを400本並べないといけません。小さくないです。&lt;/p&gt;

&lt;p&gt;もちろんディスクアレイにはキャッシュがあるので、キャッシュヒット次第でIOPSは変わります。ベンダが胸を張って公開している値も、キャッシュに当てまくった数字であることが多いです。ですが誠実な技術者は「水物」なキャッシュヒットを前提にサイジングしません。アプリがアレイを占有できて、扱うデータの量や中身に変化がない場合は別ですが、それはまれでしょう。ヒットしない最悪の場合を考慮するはずです。&lt;/p&gt;

&lt;p&gt;なお、数十万IOPSをこえるディスクアレイがあるのは事実です。でも「桁が違う。クラウドしょぼい」と思わないでください。ディスクアレイ全体の性能と、VMあたりどのくらい提供するかは、別の問題です。ひとつのVMがディスクアレイを占有するのでない限り、VMあたりのIOコントロールは必要です。そうでないと、暴れん坊VMの割を食うVMがでてきます。見えていないだけで、クラウドのバックエンドにはスケーラブルなストレージが鎮座しています。&lt;/p&gt;

&lt;h2 id=&#34;結論:d3d20b8a9dfb8ebe2c80e0d21980dbd3&#34;&gt;結論&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Intel x86 2ソケットモデルサーバで動いているようなシステムの移行であれば検討価値あり&lt;/li&gt;
&lt;li&gt;メモリが448GB以上必要であれば難しい&lt;/li&gt;
&lt;li&gt;サーバあたり80,000IOPS以上必要であれば難しい、でも本当にサーバあたりそれだけ必要か精査すべき&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ちょっと前までオンプレ案件も担当していましたが、ここ数年は2ソケットサーバ案件中心、ときどき、4ソケット以上で興奮。という感覚です。みなさんはいかがでしょう。データはないのでご参考まで。&lt;/p&gt;

&lt;p&gt;なにはともあれ、プロのみなさんは噂に流されず、制約を数値で把握して判断、設計しましょう。Azureではそのほかの制約条件も公開されていますので、ぜひご一読を。上限を緩和できるパラメータも、あります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/azure-subscription-service-limits/&#34;&gt;&amp;ldquo;Azure サブスクリプションとサービスの制限、クォータ、制約&amp;rdquo;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azureでインフラデプロイツールを選ぶ時に考えていること</title>
      <link>http://torumakabe.github.io/post/azure_infradeployment_selection/</link>
      <pubDate>Mon, 11 Jan 2016 00:20:30 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_infradeployment_selection/</guid>
      <description>

&lt;h2 id=&#34;ケースバイケースだけど:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;ケースバイケースだけど&lt;/h2&gt;

&lt;p&gt;Azureを生業にして、3か月たちます。ここまで、もっとも質問や議論が多いのが、デプロイメントの自動化についてです。進化が早いですし、選択肢も豊富。クラウド採用に合わせて自動化に挑戦するケースも増えてますので、自然なことと思います。&lt;/p&gt;

&lt;p&gt;特に話題になるのが「どのツールを選べばいいか」。ツールというのは課題を解決する手段なので、まず課題を掘るべきです。ですが、まだ成熟していない領域で変化が激しいですし、ツールひとつで課題を解決できるとも限らない。複数のツールを組み合わせることも多く、依存関係もありそう。となると、考えるきっかけが欲しいのは、ごもっとも。&lt;/p&gt;

&lt;p&gt;なので「ケースバイケース。以上」とは、言いにくい。&lt;/p&gt;

&lt;p&gt;私見であっても、たたき台となる考え方なりパターンがWebに転がっていれば、参考になるかもしれない。それがこのエントリを書く動機です。わたしは他のプラットフォームからAzureに主戦場を移していますので、新鮮な意見が書けるかも、という背景も、あります。&lt;/p&gt;

&lt;h2 id=&#34;書く前に前提など:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;書く前に前提など&lt;/h2&gt;

&lt;p&gt;対象はインフラレイヤのデプロイメントに絞ります。そして、インフラ = 物理/仮想ハードウェア(サーバ、ストレージ、ネットワーク) + OS + プラットフォームソフト(アプリじゃないもの、Webサーバ、ユーティリティ、etc）と定義します。&lt;/p&gt;

&lt;p&gt;レイヤリングや用語は、 @gosukenator さんの&lt;a href=&#34;http://mizzy.org/blog/2013/10/29/1/&#34;&gt;&amp;ldquo;インフラ系技術の流れ&amp;rdquo;&lt;/a&gt;が参考になるので、合わせて読むと幸せになれるでしょう。このエントリで言うBootstrapping/Configurationレイヤが今回の焦点です。&lt;/p&gt;

&lt;p&gt;では、わたしがツールを選ぶ時にどんなことを考えているのか、脳内をダンプしていきましょう。&lt;/p&gt;

&lt;h2 id=&#34;そもそもツールで自動化すべきかを考える:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;そもそもツールで自動化すべきかを考える&lt;/h2&gt;

&lt;p&gt;いきなり萎えるそもそも論で恐縮ですが、重要です。たとえばあるソフトの試用目的で、同じ構成のサーバのデプロイは今後しなさそう、台数は1台、使うのは自分だけ、なんていう環境のデプロイまで、自動化する必要はないはずです。時短、工数削減、オペレーションミスリスクの軽減、そもそも自動化しないと運用がまわらない、など自動化によって得られる利益がその手間を上回るかを判断します。&lt;/p&gt;

&lt;p&gt;なお「知っている/できる」人でないとその価値、利益はわかりません。やらないという判断は、腕があってはじめてできることです。&lt;/p&gt;

&lt;h2 id=&#34;使い捨てられないかを考える:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;使い捨てられないかを考える&lt;/h2&gt;

&lt;p&gt;次は、ツールによって作った環境がどのように変化するか、変えられるかを検討します。ストレートに言うと、変化のタイミングで捨てられないか？新しいものに置き換えられないか？を考えます。もしこれができるのであれば、方式はとてもシンプルにできます。Immutable Infrastructure、Blue/Green Deploymentなどのやり口が注目されていますが、これらの根っこには「ちまちま変化を加えて複雑化するくらいなら、使い捨て/入れ替えてしまえ」という意識があります。&lt;/p&gt;

&lt;p&gt;ですが、とは言ってもそんな大胆にできない事情もあると思います。Blue/Green Deploymentでは、入れ替えのタイミングでBlue、Green分のリソースが必要になりますし、切り替えにともなうリスクもあります。それを許容できない場合、同じインフラに変化を積んでいくことになります。ChefなどConfigurationレイヤで冪等なオペーレーションができるツールが注目されたのは、この変化を維持しやすいからです。&lt;/p&gt;

&lt;p&gt;変化を積む場合にやるべきでないのは、中途半端に職人が真心こめて手作業してしまうことです。ツールでやると決めたら、少なくともそのカバー範囲はツールに任せましょう。でないといわゆる「手作業汚れ」「スノーフレークサーバ（雪の結晶のように、全部同じように見えて実はそれぞれ違う）」のダークサイドに堕ちます。&lt;/p&gt;

&lt;p&gt;変化を積まないのであれば、インフラデプロイメント用途ではConfigurationレイヤのツールを導入しないという割り切りもできるでしょう。&lt;/p&gt;

&lt;h2 id=&#34;優先事項や制約条件を洗い出す:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;優先事項や制約条件を洗い出す&lt;/h2&gt;

&lt;p&gt;アーキテクトが真っ白なキャンバスに画を描けることはほぼありません。きっと、先になんらかの優先事項や制約条件があるはずです。そして、ほとんどのシステムにおいて、インフラのデプロイは主役ではありません。ツールに合わせてもらえることはまれでしょう。様々な条件を選定にあたって洗い出す必要があります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;社内/プロジェクト標準&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　周知されていないだけで、推奨ツールが決まってたりします。あるある。そのツールの良し悪しは置いておいて、社内ノウハウの蓄積など、大きな目的がある場合には従うべきでしょう。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;他レイヤでの優先ツール&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　インフラのデプロイに影響がありそうなツールがアプリ開発側で決まっていたりします。最近華やかなのがDockerです。Docker社が出してるツール群は上から下までカバー範囲も広く、デプロイツールと重複しがちです。組み合わせを検討しなければいけません。また、Apache Mesosもインフラとアプリのグレーゾーンに鎮座します。なかなか悩ましいですが、優先せざるをえません。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;規模&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　いきなり1000台とか10000台規模を扱うユーザは多くないと思いますが、その規模になるとツールの性能限界にぶち当たったりします。念のため、意識はしましょう。ちなみに、1000台をひとつのツールの傘に入れずとも、たとえば10*100台にする設計ができないか、事前に考えておくと打ち手が増えます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;チーム or ひとり&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　本番環境のデプロイ自動化はチームプレイになるので、ツールの導入はサーバ上になるでしょうし、構成ファイルの共有、バージョンコントロールなど考慮点は多いです。一方で、開発者が開発、検証用途で端末に導入し実行する使い方では、手軽さが求められます。誤解を恐れず例をあげると、前者にはChefが、後者にはAnsibleやTerraformがフィットしやすいです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Windows or Linux&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　Azure ARM Templateなど、はじめからマルチOS環境を前提に作られているツールはありますが、ほとんどのツールはその生まれがWindows、Linuxに寄っています。マルチOS対応が進んではいますが、活用にあたって、参考となる情報量には大きな差があります。たとえばマルチOS対応のツールであっても、DSCはWindowsの、ChefやAnsibleはLinuxの情報が圧倒的に多いです。これは意識せざるを得ません。使うOSでの十分な情報があるか確認します。&lt;/p&gt;

&lt;h2 id=&#34;マネージドサービス-機能を活用する:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;マネージドサービス、機能を活用する&lt;/h2&gt;

&lt;p&gt;マネージドサービス = プラットフォームが提供している機能です。Azureであれば、今回対象としているレイヤではARMがそれにあたります。デプロイツールは有用ですが、その導入や維持運用には本質的価値はありません。プラットフォームに任せられるのであれば、そうしたほうが楽です。&lt;/p&gt;

&lt;p&gt;また、Azureのインフラは進化が早いため、それに対応するスピードも、本家ツールのほうが期待できます。&lt;/p&gt;

&lt;p&gt;ですが、&lt;a href=&#34;http://torumakabe.github.io/post/arm_idempotent/&#34;&gt;以前のエントリ&lt;/a&gt;で触れたように、本家のツールであっても、すべてのレイヤをカバーできるほど万能ではありません。たとえばARM TemplateはインフラのBootstrappingには向いていますが冪等性が限定的であるため、ソフトウェアパッケージを足す/消す/入れ替えるを頻繁に繰り返す環境のConfiguration用途では、苦しいです。&lt;/p&gt;

&lt;p&gt;よってARM Templateは、Immutableな環境で使う、もしくは、ChefなどのConfigurationツールと組み合わせて使うことを念頭に設計をします。&lt;/p&gt;

&lt;p&gt;ARM Templateでは、ハード(VM、ストレージ、ネットワーク)の割り当て、OSの導入と設定、各種エージェントの導入が基本。それに加え、Immutableな環境ではプラットフォームソフトを導入してしまっていいでしょう。ARM TemplateにはDSCやシェルを実行するエクステンションが使えるので、活用します。&lt;/p&gt;

&lt;p&gt;また、Bootstrapping時点で、Configurationツールを導入できてしまうのであれば、せっかくなので入れてしまいましょう。たとえばChefサーバのインストールは、ここで。&lt;/p&gt;

&lt;p&gt;以上、ちょっとまとまりに欠けますが、ざっとわたしが意識していることを、挙げてみました。&lt;/p&gt;

&lt;h2 id=&#34;汎用的-リファレンスアーキテクチャ:d8f24c1ecd76ea2b63a3969342359091&#34;&gt;汎用的 リファレンスアーキテクチャ&lt;/h2&gt;

&lt;p&gt;具体例があったほうが分かりやすいので、最後に汎用的な組み合わせを紹介します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gallery.technet.microsoft.com/Automating-Deployment-with-84c1549f&#34;&gt;&amp;ldquo;Automating Deployment with Azure &amp;amp; Chef&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ARM TemplateでBootstrapping&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VMを4つ作成、1つはLinux、他はWindows&lt;/li&gt;
&lt;li&gt;ストレージ、ネットワークの作成&lt;/li&gt;
&lt;li&gt;VMのストレージ、ネットワーク設定&lt;/li&gt;
&lt;li&gt;OSの導入&lt;/li&gt;
&lt;li&gt;ドメインコントローラサーバへのソフト導入、各種設定 (DSC/PowerShell Extension)&lt;/li&gt;
&lt;li&gt;他Windowsサーバへのソフト導入、各種設定、ドメイン参加 (PowerShell Extension)&lt;/li&gt;
&lt;li&gt;LinuxへChefサーバを導入、各種設定 (Shell Extension)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ChefでConfiguration&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;各ノードのChef bootstrap(言葉が混同しやすいので注意)&lt;/li&gt;
&lt;li&gt;Chef Clientサービスの起動設定&lt;/li&gt;
&lt;li&gt;DBサーバのDB領域ディスク作成、フォーマット&lt;/li&gt;
&lt;li&gt;DBサーバへSQL Server 2014のインストール&lt;/li&gt;
&lt;li&gt;ChefがDBサーバが設定通りになるよう維持し続ける&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;どうでしょう、役割分担がイメージできたでしょうか。いいドキュメントがあったので、ChefのLinux/Windows混在例を紹介しましたが、Windowsとの親和性や情報量を重視するなら、ChefをAzure Automation DSCに置き換えて挑戦してもいいでしょう。そのまた逆もありで、ChefならLinux染めな環境で、とこだわってもいいと思います。&lt;/p&gt;

&lt;p&gt;書くことが意外に多かったので、また機会があれば、参考例を交えて紹介します。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure ARM Templateによるデプロイと冪等性</title>
      <link>http://torumakabe.github.io/post/arm_idempotent/</link>
      <pubDate>Wed, 06 Jan 2016 00:16:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/arm_idempotent/</guid>
      <description>

&lt;h2 id=&#34;宣言的に-冪等に:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;宣言的に、冪等に&lt;/h2&gt;

&lt;p&gt;ここ数年で生まれたデプロイメント手法、ツールは数多くありますが、似たような特徴があります。それは「より宣言的に、冪等に」です。これまで可読性や再利用性を犠牲にしたシェル芸になりがちだったデプロイの世界。それがいま、あるべき姿を定義しその状態に収束させるように、また、何度ツールを実行しても同じ結果が得られるように変わってきています。&lt;/p&gt;

&lt;p&gt;さて、そんな時流に飛び込んできたデプロイ手法があります。AzureのARM(Azure Resource Manager) Templateによるデプロイです。ARMはAzureのリソース管理の仕組みですが、そのARMに対し、構成を宣言的に書いたJSONを食わせて環境を構築する手法です。Azureの標準機能として、提供されています。&lt;/p&gt;

&lt;h3 id=&#34;azure-リソース-マネージャーの概要-https-azure-microsoft-com-ja-jp-documentation-articles-resource-group-overview:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-overview/&#34;&gt;Azure リソース マネージャーの概要&lt;/a&gt;&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;ソリューションを開発のライフサイクル全体で繰り返しデプロイできます。また、常にリソースが一貫した状態でデプロイされます&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;宣言型のテンプレートを利用し、デプロイメントを定義できます&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;冪等と言い切ってはいませんが、目的は似ています。&lt;/p&gt;

&lt;p&gt;なるほど、期待十分。ではあるのですが、冪等性の実現は簡単ではありません。たとえばChefやAnsibleも、冪等性はリソースやモジュール側で考慮する必要があります。多様なリソースの違いを吸収しなければいけないので、仕方ありません。魔法じゃないです。その辺を理解して使わないと、ハマります。&lt;/p&gt;

&lt;p&gt;残念ながらARMは成長が著しく、情報が多くありません。そこで、今回は実行結果を元に、冪等さ加減を理解していきましょう。&lt;/p&gt;

&lt;h2 id=&#34;増分デプロイと完全デプロイ:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;増分デプロイと完全デプロイ&lt;/h2&gt;

&lt;p&gt;まず、デプロイのコマンド例を見ていきましょう。今回はPowerShellを使いますが、Mac/Linux/Winで使える&lt;a href=&#34;https://github.com/Azure/azure-xplat-cli&#34;&gt;クロスプラットフォームCLI&lt;/a&gt;もあります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName YourRGName -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ワンライナーです。これだけで環境ができあがります。-TemplateFileでリソース定義を記述したJSONファイルを指定します。また、-TemplateParameterFileにパラメータを外だしできます。&lt;/p&gt;

&lt;p&gt;今回は冪等さがテーマであるため詳細は省きます。関心のあるかたは、別途&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/resource-group-template-deploy/&#34;&gt;ドキュメント&lt;/a&gt;で確認してください。&lt;/p&gt;

&lt;p&gt;さて、ワンライナーで環境ができあがるわけですが、その後が重要です。環境変更の際にJSONで定義を変更し、同じコマンドを再投入したとしても、破たんなく使えなければ冪等とは言えません。&lt;/p&gt;

&lt;p&gt;コマンド投入には2つのモードがあります。増分(Incremental)と完全(Complete)です。まずは増分から見ていきましょう。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;・リソース グループに存在するが、テンプレートに指定されていないリソースを変更せず、そのまま残します&lt;/p&gt;

&lt;p&gt;・テンプレートに指定されているが、リソース グループに存在しないリソースを追加します&lt;/p&gt;

&lt;p&gt;・テンプレートに定義されている同じ条件でリソース グループに存在するリソースを再プロビジョニングしません&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;すでに存在するリソースには手を入れず、JSONへ新たに追加されたリソースのみを追加します。&lt;/p&gt;

&lt;p&gt;いっぽうで、完全モードです。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;・リソース グループに存在するが、テンプレートに指定されていないリソースを削除します&lt;/p&gt;

&lt;p&gt;・テンプレートに指定されているが、リソース グループに存在しないリソースを追加します&lt;/p&gt;

&lt;p&gt;・テンプレートに定義されている同じ条件でリソース グループに存在するリソースを再プロビジョニングしません&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;2、3番目は増分と同じです。1番目が違います。JSONから定義を消されたリソースを削除するかどうかが、ポイントです。完全モードはスッキリするけどリスクも高そう、そんな印象を受けるのはわたしだけではないでしょう。&lt;/p&gt;

&lt;h2 id=&#34;動きをつかむ:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;動きをつかむ&lt;/h2&gt;

&lt;p&gt;では動きを見ていきましょう。テンプレートはGithubに公開されている&lt;a href=&#34;https://github.com/Azure/azure-quickstart-templates/tree/master/101-vm-simple-linux&#34;&gt;Very simple deployment of an Linux VM&lt;/a&gt;を使います。詳細は説明しませんので、読み進める前にリソース定義テンプレートファイル(azuredeploy.json)を&lt;a href=&#34;https://github.com/Azure/azure-quickstart-templates/blob/master/101-vm-simple-linux/azuredeploy.json&#34;&gt;リンク先&lt;/a&gt;でざっと確認してください。&lt;/p&gt;

&lt;p&gt;パラメータファイル(azuredeploy.parameters.json)は以下とします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;$schema&amp;quot;: &amp;quot;http://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#&amp;quot;,
  &amp;quot;contentVersion&amp;quot;: &amp;quot;1.0.0.0&amp;quot;,
  &amp;quot;parameters&amp;quot;: {
    &amp;quot;adminUsername&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;azureUser&amp;quot;
    },
    &amp;quot;adminPassword&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;password1234!&amp;quot;
    },
    &amp;quot;dnsLabelPrefix&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;armpocps&amp;quot;
    },
    &amp;quot;ubuntuOSVersion&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;14.04.2-LTS&amp;quot;
    }    
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;まず、1回目の実行です。リソースグループ &amp;ldquo;ARMEval&amp;rdquo;に対しデプロイします。このリソースグループは前もって作っておいた空の箱です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json 

DeploymentName    : azuredeploy
ResourceGroupName : ARMEval
ProvisioningState : Succeeded
Timestamp         : 2016/01/04 11:46:41
Mode              : Incremental
TemplateLink      :
Parameters        :
                Name             Type                       Value
                ===============  =========================  ==========
                adminUsername    String                     azureUser
                adminPassword    SecureString
                dnsLabelPrefix   String                     armpocps
                ubuntuOSVersion  String                     14.04.2-LTS

Outputs           :
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;できあがりです。空のリソースグループ にLinux VM、ストレージ、仮想ネットワーク、パブリックIPなどがデプロイされました。Modeを指定しない場合は増分(Incremental)となります。&lt;/p&gt;

&lt;p&gt;この環境にじわじわと変更を入れていきましょう。まずはazuredeploy.parameter.json上のパラメータ、DNS名のPrefix(dnsLabelPrefix)をarmpocps -&amp;gt; armpocps2と変えます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;dnsLabelPrefix&amp;quot;: {
  &amp;quot;value&amp;quot;: &amp;quot;armpocps2&amp;quot;
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では再投入です。パラメータファイルの内容は変えましたが、コマンドは同じです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json 
[snip]
Parameters        :
                Name             Type                       Value
                ===============  =========================  ==========
                adminUsername    String                     azureUser
                adminPassword    SecureString
                dnsLabelPrefix   String                     armpocps2
                ubuntuOSVersion  String                     14.04.2-LTS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;変更内容の確認です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; Get-AzureRmPublicIpAddress
[snip]
DnsSettings              : {
                             &amp;quot;DomainNameLabel&amp;quot;: &amp;quot;armpocps2&amp;quot;,
                             &amp;quot;Fqdn&amp;quot;: &amp;quot;armpocps2.japanwest.cloudapp.azure.com&amp;quot;
                           }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;問題なく変わっていますね。冪等チックです。この例ではシンプルにDNS名のPrefixを変えましたが、VMインスタンス数やsubnet名を変えたりもできます。関心のある方は&lt;a href=&#34;https://gallery.technet.microsoft.com/Cloud-Consistency-with-0b79b775&#34;&gt;ドキュメント&lt;/a&gt;を。&lt;/p&gt;

&lt;p&gt;増分モードによる変更は期待できそうです。が、さて、ここからが探検です。リソース削除が可能な完全モードを試してみましょう。
リソース定義ファイル(azuredeploy.json)から、大胆にVMの定義を削ってみます。下記リソースをファイルからごっそり消します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;apiVersion&amp;quot;: &amp;quot;[variables(&#39;apiVersion&#39;)]&amp;quot;,
  &amp;quot;type&amp;quot;: &amp;quot;Microsoft.Compute/virtualMachines&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;[variables(&#39;vmName&#39;)]&amp;quot;,
[snip]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;では、完全モード &amp;ldquo;-Mode complete&amp;rdquo;付きでコマンドを再投入します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json  -Mode complete

確認
Are you sure you want to use the complete deployment mode? Resources in the resource group &#39;ARMEval&#39; which are not included in the template will be deleted.
[Y] はい(Y)  [N] いいえ(N)  [S] 中断(S)  [?] ヘルプ (既定値は &amp;quot;Y&amp;quot;): Y

DeploymentName    : azuredeploy
ResourceGroupName : ARMEval
ProvisioningState : Succeeded
Timestamp         : 2016/01/04 12:01:00
Mode              : Complete
TemplateLink      :
Parameters        :
                Name             Type                       Value
                ===============  =========================  ==========
                adminUsername    String                     azureUser
                adminPassword    SecureString
                dnsLabelPrefix   String                     armpocps2
                ubuntuOSVersion  String                     14.04.2-LTS

Outputs           :
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あっさり完了しました。本当にVMが消えているが確認します。出力が冗長ですがご容赦ください。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; Find-AzureRmResource -ResourceGroupNameContains ARMEval

Name              : myPublicIP
ResourceId        :     /subscriptions/your-subscription-id/resourceGroups/ARMEval/providers/Microsoft.Network/publicIPAddresses/myPublicIP
ResourceName      : myPublicIP
ResourceType      : Microsoft.Network/publicIPAddresses
ResourceGroupName : ARMEval
Location          : japanwest
SubscriptionId    : your-subscription-id

Name              : myVMNic
ResourceId        : /subscriptions/your-subscription-id/resourceGroups/ARMEval/providers/Microsoft.Network/networkInterfaces/myVMNic
ResourceName      : myVMNic
ResourceType      : Microsoft.Network/networkInterfaces
ResourceGroupName : ARMEval
Location          : japanwest
SubscriptionId    : your-subscription-id

Name              : MyVNET
ResourceId        : /subscriptions/your-subscription-id/resourceGroups/ARMEval/providers/Microsoft.Network/virtualNetworks/MyVNET
ResourceName      : MyVNET
ResourceType      : Microsoft.Network/virtualNetworks
ResourceGroupName : ARMEval
Location          : japanwest
SubscriptionId    : your-subscription-id

Name              : yourstorageaccount
ResourceId        : /subscriptions/your-subscription-id/resourceGroups/ARMEval/providers/Microsoft.Storage/storageAccounts/yourstorageaccount
ResourceName      : yourstorageaccount
ResourceType      : Microsoft.Storage/storageAccounts
ResourceGroupName : ARMEval
Location          : japanwest
SubscriptionId    : your-subscription-id
Tags              : {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VMだけが消えています。定義からリソースがなくなれば、存在するリソースも消す、これが完全モードです。&lt;/p&gt;

&lt;p&gt;さらに検証。冪等さを求めるのであれば、またリソース定義にVMを加えて再投入したら、涼しい顔で復活してほしい。先ほどazuredeploy.jsonから消したVMリソース定義を、そのまま書き戻して再投入してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json  -Mode complete

確認
Are you sure you want to use the complete deployment mode? Resources in the resource group &#39;ARMEval&#39; which are not included in the template will be deleted.
[Y] はい(Y)  [N] いいえ(N)  [S] 中断(S)  [?] ヘルプ (既定値は &amp;quot;Y&amp;quot;): Y

New-AzureRmResourceGroupDeployment : 21:05:52 - Resource Microsoft.Compute/virtualMachines &#39;MyUbuntuVM&#39; failed with message &#39;The resource operation completed with terminal provisioning state &#39;Failed&#39;.&#39;
[snip]
New-AzureRmResourceGroupDeployment : 21:05:52 - One or more errors occurred while preparing VM disks. See disk instance view for details.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;残念ながら失敗しました。どうやらdiskまわりのエラーが発生したようです。&lt;/p&gt;

&lt;p&gt;これは、完全モードでのリソース削除の仕様が原因です。ARMは該当のVMリソースは消すのですが、VMが格納されているストレージを削除しません。リソース作成時は依存関係が考慮されますが、削除時は異なります。&lt;/p&gt;

&lt;p&gt;試しにストレージを消して再実行してみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Workspace&amp;gt; New-AzureRmResourceGroupDeployment -ResourceGroupName ARMEval -TemplateFile .\azuredeploy.json -TemplateParameterFile .\azuredeploy.parameters.json  -Mode complete

[snip]
ProvisioningState : Succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定義通りの環境になりました。依存関係をたどって消してほしいのが人情ですが、残したほうがいいケースもあるので、今後の改善を期待しましょう。&lt;/p&gt;

&lt;h2 id=&#34;使い方:7f9d18b141fe8baff11274b2e0ae3943&#34;&gt;使い方&lt;/h2&gt;

&lt;p&gt;冪等であると言い切れないものの、リソース定義と実行モードを理解したうえで使えば有用。ただ、完全モードによる削除は使い方が難しい。現状ではそんな印象です。&lt;/p&gt;

&lt;p&gt;そこで、ARM Templateをデプロイに組み込む際、ARMによるデプロイはBootstrap用途に限定し、より構成頻度が高いConfiguration用途には、冪等性を持った別のツールを組み合わせるのが現実解と考えます。&lt;/p&gt;

&lt;p&gt;Bootstrap用途では、プラットフォームの提供機能を使ったほうが、機能も多いし最適化されています。Azureで今後この層を担当していくのはARMです。そして、この用途ではChefやAnsibleなど汎用ツールに物足りなさがあります。&lt;/p&gt;

&lt;p&gt;また、Bootstrapは1回切りであるケースが多いので、失敗したらリソースグループをばっさり消して再作成する、と割り切りやすいです。それならば冪等でなくともいいでしょう。&lt;/p&gt;

&lt;p&gt;長くなったので、デプロイツールの組み合わせについては、あたらめて書きたいと思います。&lt;/p&gt;

&lt;p&gt;参考: &lt;a href=&#34;http://mizzy.org/blog/2013/10/29/1/&#34;&gt;インフラ系技術の流れ Bootstrapping/Configuration/Orchestration&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStackとAzureにDocker Swarmをかぶせてみた</title>
      <link>http://torumakabe.github.io/post/azure_openstack_swarm/</link>
      <pubDate>Sat, 19 Dec 2015 00:01:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_openstack_swarm/</guid>
      <description>

&lt;h2 id=&#34;どこいってもいじられる:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;どこいってもいじられる&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.adventar.org/calendars/968&#34;&gt;OpenStack Advent Calendar 2015&lt;/a&gt; 参加作品、19夜目のエントリです。&lt;/p&gt;

&lt;p&gt;OpenStackの最前線から離れて3か月がたちました。OpenStackつながりな方にお会いするたび、マイルドなかわいがりをうけます。ほんとうにありがとうございます。仕事としては専門でなくなりましたが、ユーザ会副会長の任期はまだ残っているので、積極的にいじられに行く所存です。でも笑いながら蹴ったりするのはやめてください。&lt;/p&gt;

&lt;p&gt;さて、毎年参加しているOpenStack Advent Calendarですが、せっかくだからいまの専門とOpenStackを組み合わせたいと思います。ここはひとつ、OpenStackとAzureを組み合わせて何かやってみましょう。&lt;/p&gt;

&lt;h2 id=&#34;乗るしかないこのdockerウェーブに:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;乗るしかないこのDockerウェーブに&lt;/h2&gt;

&lt;p&gt;どうせなら注目されている技術でフュージョンしたいですね。2015年を振り返って、ビッグウェーブ感が高かったのはなんでしょう。はい、Dockerです。Dockerを使ってOpenStackとAzureを組み合わせてみます。あまり難しいことをせず、シンプルにサクッとできることを。年末ですし、「正月休みにやってみっか」というニーズにこたえます。&lt;/p&gt;

&lt;p&gt;ところでOpenStack環境はどうやって調達しましょう。ちょっと前までは身の回りに売るほどあったのですが。探さないといけないですね。せっかくなので日本のサービスを探してみましょう。&lt;/p&gt;

&lt;p&gt;条件はAPIを公開していること。じゃないと、Dockerの便利なツール群が使えません。Linuxが動くサービスであれば、Docker環境をしみじみ手作業で夜なべして作れなくもないですが、嫌ですよね。正月休みは修行じゃなくて餅食って酒飲みたい。安心してください、わかってます。人力主義では、せっかくサクサク使えるDockerが台無しです。&lt;/p&gt;

&lt;p&gt;あと、当然ですが個人で気軽にオンラインで契約できることも条件です。&lt;/p&gt;

&lt;p&gt;そうすると、ほぼ一択。&lt;a href=&#34;https://www.conoha.jp/&#34;&gt;Conoha&lt;/a&gt;です。かわいらしい座敷童の&lt;a href=&#34;https://www.conoha.jp/conohadocs/?btn_id=top_footer_conotsu&#34;&gt;&amp;ldquo;このは&amp;rdquo;&lt;/a&gt;がイメージキャラのサービスです。作っているのは手練れなOSSANたちですが。&lt;/p&gt;

&lt;p&gt;では、AzureとConohaにDocker環境をサクッと作り、どちらにもサクッと同じコンテナを作る。もちろん同じCLIから。ということをしてみようと思います。&lt;/p&gt;

&lt;p&gt;今回大活躍するDoker Machine、Swarmの説明はしませんが、関心のある方は&lt;a href=&#34;http://www.slideshare.net/zembutsu/whats-new-aobut-docker-2015-network-and-orchestration&#34;&gt;前佛さんの資料&lt;/a&gt;を参考にしてください。&lt;/p&gt;

&lt;h2 id=&#34;ローカル環境:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;ローカル環境&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Mac OS X (El Capitan)

&lt;ul&gt;
&lt;li&gt;Docker Toolbox 1.9.1&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ローカル、Azure、ConohaすべてのDocker環境はDocker Machineでサクッと作ります。
また、Swarmのマスタはローカルに配置します。&lt;/p&gt;

&lt;h2 id=&#34;いざ実行:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;いざ実行&lt;/h2&gt;

&lt;p&gt;まず、Docker Machineにクラウドの諸設定を食わせます。&lt;/p&gt;

&lt;p&gt;Azure向けにサブスクリプションIDとCertファイルの場所を指定します。詳細は&lt;a href=&#34;https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-docker-machine/&#34;&gt;ここ&lt;/a&gt;を。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export AZURE_SUBSCRIPTION_ID=hoge-fuga-hoge-fuga-hoge
$ export AZURE_SUBSCRIPTION_CERT=~/.ssh/yourcert.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Conoha向けにOpenStack関連の環境変数をセットします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export OS_USERNAME=yourname
$ export OS_TENANT_NAME=yourtenantname
$ export OS_PASSWORD=yourpass
$ export OS_AUTH_URL=https://identity.tyo1.conoha.io/v2.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次はローカルコンテナ環境を整えます。&lt;/p&gt;

&lt;p&gt;Swarmコンテナを起動し、ディスカバリトークンを生成します。このトークンがSwarmクラスタの識別子です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create -d virtualbox local
$ eval &amp;quot;$(docker-machine env local)&amp;quot;
$ docker run swarm create    
Status: Downloaded newer image for swarm:latest
tokentokentokentoken
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このトークンは控えておきましょう。&lt;/p&gt;

&lt;p&gt;ではSwarmのマスタをローカルに作ります。先ほど生成したトークン指定を忘れずに。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://tokentokentokentoken head
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SwarmのエージェントをAzureに作ります。VMを作って、OSとDockerをインストールして、なんて不要です。Docker Machineがやってくれます。ここでもトークン指定を忘れずに。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval &amp;quot;$(docker-machine env head)&amp;quot;
$ docker-machine create -d azure --swarm --swarm-discovery token://tokentokentokentoken worker-azure01 --azure-location &amp;quot;East Asia&amp;quot; worker-azure00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Conohaにも同様に。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create -d openstack --openstack-flavor-name g-1gb --openstack-image-name vmi-ubuntu-14.04-amd64 --openstack-sec-groups &amp;quot;default,gncs-ipv4-all&amp;quot; --swarm --swarm-discovery token://tokentokentokentoken worker-conoha00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;さあ環境がサクッと出来上がりました。これ以降はSwarmクラスタ全体を操作対象にします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval &amp;quot;$(docker-machine env --swarm head)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;環境をチラ見してみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker info
Containers: 4
Images: 3
 Role: primary
 Strategy: spread
 Filters: health, port, dependency, affinity, constraint
 Nodes: 3
 head: 192.168.99.101:2376
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.021 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Dec 18 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
 worker-azure00: xxx.cloudapp.net:2376
  └ Containers: 1
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.721 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=3.13.0-36-generic, operatingsystem=Ubuntu 14.04.1 LTS, provider=azure, storagedriver=aufs
 worker-conoha00: www.xxx.yyy.zzz:2376
  └ Containers: 1
  └ Reserved CPUs: 0 / 2
  └ Reserved Memory: 0 B / 1.019 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=3.16.0-51-generic, operatingsystem=Ubuntu 14.04.3 LTS, provider=openstack, storagedriver=aufs
CPUs: 4
Total Memory: 3.761 GiB
Name: 1234abcd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どこにどんな環境が作られたかが分かりますね。出力結果の4行目&amp;rdquo;Strategy: spread&amp;rdquo;を覚えておいてください。&lt;/p&gt;

&lt;p&gt;ではコンテナを作ってみましょう。Nginxコンテナ三連星です。どの環境に作るか、という指定はしません。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in `seq 1 3`; do docker run -d -p 80:80 nginx; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どんな具合でしょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                NAMES
9cc2f5594fa5        nginx               &amp;quot;nginx -g &#39;daemon off&amp;quot;   5 seconds ago       Up 4 seconds        192.168.99.101:80-&amp;gt;80/tcp, 443/tcp   head/goofy_goldberg
b9d54d794a85        nginx               &amp;quot;nginx -g &#39;daemon off&amp;quot;   32 seconds ago      Up 31 seconds       www.xxx.yyy.zzz:80-&amp;gt;80/tcp, 443/tcp   worker-conoha00/clever_chandrasekhar
19e9d0e229a2        nginx               &amp;quot;nginx -g &#39;daemon off&amp;quot;   45 seconds ago      Up 42 seconds       zzz.yyy.xxx.www:80-&amp;gt;80/tcp, 443/tcp    worker-azure00/reverent_bhaskara
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nginxコンテナがきれいに散らばっているのが分かります。これは先ほど覚えた&amp;rdquo;Strategy: spread&amp;rdquo;が効いているからです。StrategyはSwarmのコンテナ配置ポリシーで、speradを指定すると散らしにいきます。Strategyをbinpackにしておけば、ノードを埋めようとします。埋まったら他、です。randomであれば、ランダムに。&lt;/p&gt;

&lt;p&gt;まだシンプルですが、今後このStrategyやリソース管理が賢くなると、「ローカルが埋まったら、リモートを使う」とか、使い道が広がりそうですね。最近Docker社が買収した&lt;a href=&#34;https://www.tutum.co/&#34;&gt;Tutum&lt;/a&gt;との関係、今後どう進化していくのか、注目です。&lt;/p&gt;

&lt;h2 id=&#34;ツールから入るハイブリッドクラウドも-またよし:9e7f40e1d4e6f185223966639b28e39a&#34;&gt;ツールから入るハイブリッドクラウドも、またよし&lt;/h2&gt;

&lt;p&gt;ハイブリッドクラウドはまだ言葉先行です。まだクラウドを使ってない、使いこなしていない段階でツールの話だけが先行することも多いです。ナイフとフォークしか使ったことのない人が、お箸を使う和食や中華を選ぶ前に「どんなお箸がいいかねぇ」と議論している感じ。僕は、そうじゃなくて、その前に食べたいもの = クラウドを選びましょうよ、というスタンスでした。&lt;/p&gt;

&lt;p&gt;でも、コンテナ+Dockerって、お箸に弁当ついてきたような感じなんですよね。お箸が使える人であれば、弁当持ち込める場所さえ確保すればいい。インパクトでかいです。ちょっと考えを改めました。&lt;/p&gt;

&lt;p&gt;もちろん、だからクラウドは何でもいい、と言っているわけではありません。弁当持ち込みとしても、スペースが広い、個室で静か、お茶がうまい、お茶がタダ、揚げたてのから揚げを出してくれる、などなど、特徴は出てくるでしょう。APIを公開していないような「持ち込みやめて」のクラウドは、先々心配ですが。&lt;/p&gt;

&lt;p&gt;簡単 = 正義です。簡単であれば使う人が増えて、要望が増えて、育ちます。かっちり感は後からついてくる。もしDockerで複数のクラウド環境を簡単に使いこなせるようになるのであれば、順番が逆ではありますが、お箸、Dockerというツールから入るのもいいかもしれません。&lt;/p&gt;

&lt;p&gt;まずは開発、検証環境など、リスク低いところから試して慣れていくのがおすすめです。触っていくうちに、いろいろ見えてくるでしょう。Dockerはもちろんですが、それぞれのクラウドの特徴も。&lt;/p&gt;

&lt;p&gt;OpenStackもAzureも、特徴を活かし、うまく使いこなしてほしいと思っております。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Azure Docker VM Extensionを使う3つの理由</title>
      <link>http://torumakabe.github.io/post/azure_docker_extension/</link>
      <pubDate>Thu, 05 Nov 2015 15:40:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/azure_docker_extension/</guid>
      <description>

&lt;h2 id=&#34;まずはじめに:488dcbba59f3c8d3d94b3ed8ace3af66&#34;&gt;まずはじめに&lt;/h2&gt;

&lt;p&gt;先月からMicrosoftで働いてます。Azure担当のソリューションアーキテクトになりました。これからAzureネタが増えると思いますが、ひとつよろしくお願いします。Microsoftテクノロジーとオープンソースの間あたりを、積極的にこすっていく所存です。&lt;/p&gt;

&lt;p&gt;もちろん、技術者個人として、中立的に、公開できるネタを書きます。&lt;/p&gt;

&lt;p&gt;AzureはMicrosoftテクノロジーとオープンソースの交差点です。できないと思っていたことが、実はできたりします。いまだに「AzureでLinux動くのね、知らなかった」と言われたり。また、その逆もしかり。SDKが色々あるからできると思っていたら、制約があった、とか。&lt;/p&gt;

&lt;p&gt;なので、小ネタであっても、実践的な情報には価値があります。今後、公式ドキュメントでカバーされなかったり、細かすぎて伝わりづらいなことを、書いていこうかと。&lt;/p&gt;

&lt;h2 id=&#34;azure-docker-vm-extension-を使う3つの理由:488dcbba59f3c8d3d94b3ed8ace3af66&#34;&gt;Azure Docker VM Extension を使う3つの理由&lt;/h2&gt;

&lt;p&gt;さて、今回は話題沸騰のDocker関連のネタ、&lt;a href=&#34;https://github.com/Azure/azure-docker-extension&#34;&gt;Azure Docker VM Extension&lt;/a&gt;について。名前通り、Azure上でDockerをのせたVMを動かすときに便利な拡張機能です。&lt;/p&gt;

&lt;p&gt;このDocker VM Extension、AzureのARMテンプレートによく登場します。なんとなくおすすめっぽいです。ですが「自分でDockerをインストールするのと何が違うのよ」という疑問も、あるかと思います。実際、よく聞かれます。&lt;/p&gt;

&lt;p&gt;ずばり、答えはGithubの&lt;a href=&#34;https://github.com/Azure/azure-docker-extension&#34;&gt;README&lt;/a&gt;にまとまっています。この拡張機能のうれしさは、&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Docker EngineのStable最新版をインストールしてくれる&lt;/li&gt;
&lt;li&gt;Docker デーモンの起動オプションや認証まわりを設定できる (オプション)

&lt;ul&gt;
&lt;li&gt;ポートマッピング、認証まわり、Docker Registoryサーバの定義など&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Docker Composeのパラメータを渡すことができる (オプション)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上です。2と3はJSONで記述できます。要するに、毎度山ほどオプションつけてdockerコマンド打つよりは、宣言的にDockerを楽に使えますよ、ということです。必須ではありません。また、山ほどあるDockerのオプションを隅々まで網羅しているわけではありません。カバー範囲は基本的なところです。&lt;/p&gt;

&lt;p&gt;Dockerの環境構築、はじめはコマンドを打つことをおすすめします。オプションがいろいろあるので、その中身を理解することには意味があります。&lt;/p&gt;

&lt;p&gt;ですが、一度理解したあとは、かったるいことこの上ないので、この手のツールはあったほうがいいですね。&lt;/p&gt;

&lt;p&gt;Dockerは本家のみならずエコシステムも急激に変化しているので、まだ環境構築ツールのファイナルアンサーはないでしょう。どれを学ぶか悩ましいところです。ですが、この拡張は気軽に使えますし、依存性も低いので、おすすめです。&lt;/p&gt;

&lt;p&gt;なお、このDocker拡張、ARM属性で言うpublisherは&amp;rdquo;Microsoft.Azure.Extensions&amp;rdquo;ですが、古い&amp;rdquo;MSOpenTech.Extensions&amp;rdquo;を指定しているARMテンプレートがまだあったりします。拡張のインストール時に「そんなのねぇよ」と怒られたら、疑ってみてください。伝統を重んじるUSのリージョンでは動いて、Japanで動かないテンプレートでは、MSOpenTechが指定されているかもしれません。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugoへ移行</title>
      <link>http://torumakabe.github.io/post/migrate-to-hugo/</link>
      <pubDate>Sun, 20 Sep 2015 15:27:03 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/migrate-to-hugo/</guid>
      <description>

&lt;h2 id=&#34;jekyllからhugoへ移行:63d64c61b0a30fb30dcadfbaac2823c1&#34;&gt;JekyllからHugoへ移行&lt;/h2&gt;

&lt;p&gt;サイトジェネレータをJekyllからHugoに変えました。深い理由はありません。気分転換です。Githubでソース管理、Werckerで自動ビルド、最後にGithub Pagesにデプロイするフローを作りました。&lt;/p&gt;

&lt;p&gt;移行にあたり、Jekyllの前(Blogger)に使っていたフォーマットを変換するのが面倒だったので、その時代のエントリーをえいっと削除しました。リンクいただいたみなさん、すいません。内容も古くなっていたので、リフレッシュのいい機会ということで、ご容赦を。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>いきなり Terraform OpenStack Provider</title>
      <link>http://torumakabe.github.io/post/terraform-openstack-minimum/</link>
      <pubDate>Sat, 04 Apr 2015 00:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/terraform-openstack-minimum/</guid>
      <description>

&lt;h3 id=&#34;terraform-0-4でopenstack-providerリリース:5f9dbf3eb73e084c7453e28119859d69&#34;&gt;Terraform 0.4でOpenStack Providerリリース&lt;/h3&gt;

&lt;p&gt;以前からOpenStack対応は表明されていたのですが、いよいよ&lt;a href=&#34;https://hashicorp.com/blog/terraform-0-4.html&#34;&gt;v0.4&lt;/a&gt;でリリースされました。&lt;/p&gt;

&lt;h3 id=&#34;小さくはじめましょう:5f9dbf3eb73e084c7453e28119859d69&#34;&gt;小さくはじめましょう&lt;/h3&gt;

&lt;p&gt;この手のツールを試すときは、はじめから欲張ると苦労します。最小限の設定でひとまず動かすとクイックに幸せが訪れます。目標は10分。&lt;/p&gt;

&lt;h3 id=&#34;テストした環境:5f9dbf3eb73e084c7453e28119859d69&#34;&gt;テストした環境&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Terraform 0.4&lt;/li&gt;
&lt;li&gt;Mac OS 10.10.2&lt;/li&gt;
&lt;li&gt;HP Helion Public Cloud&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;openstackerのみだしなみ-環境変数:5f9dbf3eb73e084c7453e28119859d69&#34;&gt;OpenStackerのみだしなみ、環境変数&lt;/h3&gt;

&lt;p&gt;下記、環境変数はセットされてますよね。要確認。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OS_AUTH_URL&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;OS_USERNAME&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;OS_PASSWORD&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;OS_REGION_NAME&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;OS_TENANT_NAME&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;最小限の構成ファイル:5f9dbf3eb73e084c7453e28119859d69&#34;&gt;最小限の構成ファイル&lt;/h3&gt;

&lt;p&gt;&lt;script type=&#34;text/javascript&#34; src=&#34;http://gist.github.com/977209064bcfda66d085.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;これだけ。Providerの設定は書かなくていいです。Terraformは環境変数を見に行きます。Resource部は、最小限ということで、まずはインスタンスを起動し、Floating IPをつけるとこまで持っていきましょう。&lt;/p&gt;

&lt;h3 id=&#34;さあ実行:5f9dbf3eb73e084c7453e28119859d69&#34;&gt;さあ実行&lt;/h3&gt;

&lt;p&gt;まずはterraform planコマンドで、実行計画を確認します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan
Refreshing Terraform state prior to plan...


The Terraform execution plan has been generated and is shown below.
Resources are shown in alphabetical order for quick scanning. Green resources
will be created (or destroyed and then created if an existing resource exists), yellow resources are being changed in-place, and red resources will be destroyed.

Note: You didn&#39;t specify an &amp;quot;-out&amp;quot; parameter to save this plan, so when &amp;quot;apply&amp;quot; is called, Terraform can&#39;t guarantee this is what will execute.

+ openstack_compute_instance_v2.sample-server
    access_ip_v4:      &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    access_ip_v6:      &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    flavor_id:         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_flavor_id&amp;quot;
    flavor_name:       &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    floating_ip:       &amp;quot;&amp;quot; =&amp;gt; &amp;quot;aaa.bbb.ccc.ddd&amp;quot;
    image_id:          &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_image_id&amp;quot;
    image_name:        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    key_pair:          &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_keypair&amp;quot;
    name:              &amp;quot;&amp;quot; =&amp;gt; &amp;quot;tf-sample&amp;quot;
    network.#:         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    region:            &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_region&amp;quot;
    security_groups.#: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    security_groups.0: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_sg&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定義通りに動きそうですね。では実行。applyです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform apply  
openstack_compute_instance_v2.sample-server: Creating...  
    access_ip_v4:      &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;  
    access_ip_v6:      &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;  
    flavor_id:         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_flavor&amp;quot;  
    flavor_name:       &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;  
    floating_ip:       &amp;quot;&amp;quot; =&amp;gt; &amp;quot;aaa.bbb.ccc.ddd&amp;quot;  
    image_id:          &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_image_id&amp;quot;  
    image_name:        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;  
    key_pair:          &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_keypair&amp;quot;  
    name:              &amp;quot;&amp;quot; =&amp;gt; &amp;quot;tf-sample&amp;quot;  
    network.#:         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;  
    region:            &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_region&amp;quot;
    security_groups.#: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    security_groups.0: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;my_sg&amp;quot;
openstack_compute_instance_v2.test-server: Creation complete

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.

The state of your infrastructure has been saved to the path below. This state is required to modify and destroy your infrastructure, so keep it safe. To inspect the complete state use the `terraform show` command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;とても楽ちんですね。あとはオプションを追加して込み入った構成に挑戦してみてください。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>君はOpenStack Monascaを知っているか</title>
      <link>http://torumakabe.github.io/post/monasca/</link>
      <pubDate>Fri, 12 Dec 2014 00:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/monasca/</guid>
      <description>

&lt;p&gt;このエントリーは、&lt;a href=&#34;http://www.adventar.org/calendars/602&#34;&gt;OpenStack (2枚目) Advent Calendar 2014&lt;/a&gt;の12夜目担当作品です。&lt;/p&gt;

&lt;h3 id=&#34;monitoring-as-a-service:a2dc20a10b2175cd92893d87c6bb4e06&#34;&gt;Monitoring as a Service&lt;/h3&gt;

&lt;p&gt;監視をサービスとして提供するって、どういうことでしょうか。&lt;/p&gt;

&lt;p&gt;[Monitoring]&lt;br /&gt;
従来の監視。担当者が事前に監視項目を定義する。静的。&lt;/p&gt;

&lt;p&gt;[Monitoring as a Service]
監視機能をサービスとして提供する。不特定多数のユーザーが、自分の監視したい測定項目を定義し、自分の好きなタイミングでチェックする。GUIはもちろん、APIでデータ取得できる。動的。&lt;/p&gt;

&lt;p&gt;まあ、AWSのCloudWatchみたいなものです。先に言うべきでしたね、すいません。&lt;/p&gt;

&lt;p&gt;このMonitoring as a Service、技術的なハードルは結構高いんです。刻々と上がってくるイベントをさばき、蓄積し、APIをバシバシ叩くユーザーリクエストに応えなきゃいけない。監視というと裏方のイメージがありますが、これは、対価をいただくに値する、立派なサービスです。&lt;/p&gt;

&lt;p&gt;そこでOpenStackのMonitoring as a Service事情はどうでしょうか。一見、それを実現できそうなCeilometerがあります。ただ、もともとCeilomerは課金のための利用情報収集をする、という生まれなので、マルチテナントで、ユーザーが自らメトリックを定義し、チェックするという使い方に向いていません。ユーザー向けというより、管理者向けなんです。&lt;/p&gt;

&lt;p&gt;そこで&lt;a href=&#34;https://wiki.openstack.org/wiki/Monasca&#34;&gt;Monasca&lt;/a&gt;の登場です。まだ正式機能ではありませんが、いずれ昇格するのでは、と個人的に期待しています。&lt;/p&gt;

&lt;p&gt;では、アーキテクチャーを見てみましょう。&lt;br /&gt;
&lt;img src=&#34;https://wiki.openstack.org/w/images/4/4a/Monasca-arch-component-diagram.png&#34; alt=&#34;MonascaArc&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;ひゃー、ワクワクしますがちょっと重いですね。特にイベントを処理するメッセージキュー、イベントを貯めるDBは工夫が要りそうです。現時点で、キューにはApache Kafka、DBにはカラムナーDBのVerticaや、時系列DBのInflux DBがサポートされています。正直、無理目のスタックです。&lt;/p&gt;

&lt;p&gt;と思っていたら。&lt;/p&gt;

&lt;p&gt;なんと、&lt;a href=&#34;https://github.com/stackforge/monasca-vagrant&#34;&gt;Monasca-Vagrant&lt;/a&gt;なんてものができているじゃありませんか。VagrantとAnsibleでサクっと環境を作れるとな。まじか。本当か。本当だった。1時間くらいでできた。&lt;/p&gt;

&lt;h3 id=&#34;気をつけること:a2dc20a10b2175cd92893d87c6bb4e06&#34;&gt;気をつけること&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;動作実績のあるわたしの環境は、MacBook Pro Late 2013 / 2.3 GHz Intel Core i7、メモリ16GB、Yosemite。&lt;/li&gt;
&lt;li&gt;Vagrantfileを見る限り、メモリ7GBと6GBのVMを作る。ここいじって動くかは要検証。&lt;/li&gt;
&lt;li&gt;git cloneしたディレクトリ直下にansibleのrequirementファイルが置かれるので、そこで作業&lt;/li&gt;
&lt;li&gt;vagrant upで2つのVM、devstackとmini-monが作られる、ここは時間と帯域がいるので、スタバな人は要注意&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;気をつけるのはこれくらいです。レッツトライ。&lt;/p&gt;

&lt;p&gt;年末年始休暇のお楽しみが増えましたね。&lt;/p&gt;

&lt;p&gt;これでわたしの2014年Advent Calendarシリーズは完了です。メリークリスマス &amp;amp; 良いお年を。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStackと長期バージョン固定</title>
      <link>http://torumakabe.github.io/post/longtermsupport/</link>
      <pubDate>Tue, 09 Dec 2014 00:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/longtermsupport/</guid>
      <description>

&lt;p&gt;このエントリーは、&lt;a href=&#34;http://www.adventar.org/calendars/602&#34;&gt;OpenStack (2枚目) Advent Calendar 2014&lt;/a&gt;の9夜目担当作品です。&lt;/p&gt;

&lt;h3 id=&#34;ソフトウェア-バージョン-サポート:e4bf6752a3e6bdd894e5fbbe3136fda0&#34;&gt;ソフトウェア、バージョン、サポート&lt;/h3&gt;

&lt;p&gt;たいていのソフトウェアには、バージョンがあります。そしてそれぞれのソフトウェアには「直近2バージョンをサポートする。ユーザーがそれよりも古いバージョンを使いたい場合、ベストエフォートで対応する。サポート対象外のバージョンで不具合対応ができるかどうかは、場合による。」なんていうポリシーがあったりします。&lt;/p&gt;

&lt;h3 id=&#34;進化著しいソフト-openstackでは:e4bf6752a3e6bdd894e5fbbe3136fda0&#34;&gt;進化著しいソフト、OpenStackでは&lt;/h3&gt;

&lt;p&gt;OpenStackは現在、半年ごとにアップデートします。進化が早いです。そして&lt;a href=&#34;https://wiki.openstack.org/wiki/Releases&#34;&gt;公式サイト&lt;/a&gt;を見て分かるとおり、直近2バージョンがサポート対象です。ちょっと短いですね。長期サポートよりも新規開発を優先しているわけですが、「もうちょっと長くサポートしてくれんか」というのが人情でしょう。&lt;/p&gt;

&lt;h3 id=&#34;でも-長期バージョン固定するとどうなるか:e4bf6752a3e6bdd894e5fbbe3136fda0&#34;&gt;でも、長期バージョン固定するとどうなるか&lt;/h3&gt;

&lt;p&gt;では仮に「そのバージョンがリリースされてから3年間、同じバージョンで運用する」というポリシーでクラウドを作ったとしましょう。その間に、5〜6バージョン、進化してしまうわけですが。以下、ちょっと未来の想像です。&lt;/p&gt;

&lt;p&gt;[とあるクラウド その1]&lt;br /&gt;
- (Dev)  今度のシステムでAっちゅうライブラリ使いたいんだけど、OpenStackだと、サポートがLからなんだよね。&lt;br /&gt;
- (Ops) あー、うちの環境Jよ。&lt;br /&gt;
- (Dev) そうすか。じゃあ他のにするわ。&lt;/p&gt;

&lt;p&gt;使われないクラウド。悲しい。これからOpenStackに対応したアプリやライブラリ、たくさん出てきそうなのに。&lt;/p&gt;

&lt;p&gt;[とあるクラウド その2]&lt;br /&gt;
- (Ops) うちはJで3年間バージョン固定、長期サポートです!! アップデート作業のために環境を止めたりしません!!&lt;br /&gt;
- (Dev) おーいいね。決定。3年のんびりするわ。&lt;br /&gt;
〜3年後〜&lt;br /&gt;
- (Ops) 約束の3年です。長年放置したのでバージョンアップは大手術です。システム止めます!!&lt;br /&gt;
- (Dev) いやいやいやいや、アプリも運用も、そんな準備できてないし。&lt;/p&gt;

&lt;p&gt;リスクの先送りと大噴火。「小さな変更をこまめに行い、リスクを最小化する。人もプロセスも、アプリの作りも、変化に強くなる。」という、最近のDevOpsなりCI/CDといったトレンドとは逆のやり口です。&lt;/p&gt;

&lt;h3 id=&#34;アップデートの仕組みに投資したほうが建設的と思う:e4bf6752a3e6bdd894e5fbbe3136fda0&#34;&gt;アップデートの仕組みに投資したほうが建設的と思う&lt;/h3&gt;

&lt;p&gt;もちろん、OpenStackの開発が落ち着いてきたら、長期のバージョン固定サポートは価値が高いと思います。ただし、イノベーションを求めて活発に開発しているソフトでは、結局それはユーザーにとって不利益になるのではないでしょうか。&lt;/p&gt;

&lt;p&gt;それよりは、アップデーターの開発、複数コントロールプレーンの平行運用の確立、アプリや運用でも対応するなど、「変化を受け入れる」ほうが建設的なのではと考える次第です。&lt;/p&gt;

&lt;p&gt;最後に、&lt;a href=&#34;http://superuser.openstack.org/articles/openstack-user-survey-insights-november-2014&#34;&gt;最新のOpenStack User Survey&lt;/a&gt;を紹介します。注目はBusiness Driverです。OpenStackを使う、動機です。&lt;/p&gt;

&lt;p&gt;OpenStackのBusiness Driverとして、最もユーザーが重視しているのは、&amp;rdquo;Ability to innovate&amp;rdquo;なんですよね。
あまり変化なく、3年とか5年とか、言葉は悪いですが、塩漬けで使うような従来型システムとは、優先すべきところが違うのではなかろうかと。&lt;/p&gt;

&lt;p&gt;メインフレームから、クライアント/サーバー、そしてWebと、テクノロジーリフレッシュの機会が、これまではありました。そろそろ、リフレッシュしてみませんか。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ハンサムOpenStack</title>
      <link>http://torumakabe.github.io/post/handsome-openstack/</link>
      <pubDate>Sat, 06 Dec 2014 00:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/handsome-openstack/</guid>
      <description>

&lt;p&gt;このエントリーは、&lt;a href=&#34;http://www.adventar.org/calendars/602&#34;&gt;OpenStack (2枚目) Advent Calendar 2014&lt;/a&gt;の6夜目担当作品です。&lt;/p&gt;

&lt;h3 id=&#34;出オチ:69265e72de8632f3d558928e3a79ce26&#34;&gt;出オチ&lt;/h3&gt;

&lt;p&gt;OpenStackも人気が出て、Advent Calendarが1枚ではおさまさなくなりました。2枚目です。ハンサムです。だからハンサムOpenStackです。&lt;/p&gt;

&lt;p&gt;こんなテーマで何か書けるんでしょうか? 何をおっしゃる、芸術とは制約から生まれるのです。&lt;/p&gt;

&lt;h3 id=&#34;そもそも2枚目とは:69265e72de8632f3d558928e3a79ce26&#34;&gt;そもそも2枚目とは&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;「二枚目」という用語は、歌舞伎用語をもとに、江戸時代に生まれた。歌舞伎の看板は、通常は8枚から成っていた。一枚目の看板は「書き出し」と言われ、主役の名が書かれ、二枚目の看板には若い色男の役者の名が書かれることになっていた。また、三枚目の看板には道化役の名が書かれることになっていた。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://ja.wikipedia.org/wiki/%E4%BA%8C%E6%9E%9A%E7%9B%AE&#34;&gt;「二枚目」（2013年5月28日 (火) 02:17 UTCの版）『ウィキペディア日本語版』&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;8枚あるらしいぞ-いじってみよう:69265e72de8632f3d558928e3a79ce26&#34;&gt;8枚あるらしいぞ いじってみよう&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;一枚目：主役：そのまま主役。「一枚看板」という用法もある。&lt;br /&gt;
&lt;em&gt;Novaですね。主役です。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;二枚目：色男：優男で色事担当&lt;br /&gt;
&lt;em&gt;これはあとにとっておきましょう。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;三枚目：道化：お笑い担当&lt;br /&gt;
&lt;em&gt;Glanceですね。何も変なことしてないのにネタにされる。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;四枚目：中軸：中堅役者　まとめ役&lt;br /&gt;
&lt;em&gt;Cinderでしょうか。主役のNovaを活かす名脇役。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;五枚目：敵役：一般的な敵役&lt;br /&gt;
&lt;em&gt;Heatかな。はじめのCloudFormation形式ってのが気に入らなかった。HOTが出てきたので許す。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;六枚目：実敵：憎めない善要素のある敵役&lt;br /&gt;
&lt;em&gt;Ceilometerです。重いです。絶賛チューニング中です。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;七枚目：実悪：巨悪　ラスボス　全ての悪事の黒幕&lt;br /&gt;
&lt;em&gt;Neutron。でもまあ、Neutronに罪はないか。取り巻きが良くなかったのよきっと。これから良くなるよ。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;八枚目：座長：元締め&lt;br /&gt;
&lt;em&gt;Swiftで決まり。ほとばしる安定感。というかAWSに依存したS3互換製品とかやめてみんなオープンなSwift互換にするといいよ。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;じゃあ二枚目は:69265e72de8632f3d558928e3a79ce26&#34;&gt;じゃあ二枚目は?&lt;/h3&gt;

&lt;p&gt;*Trove*です。若さと期待の大きさを込めてキャスティングしました。というか&lt;a href=&#34;http://www.publickey1.jp/blog/14/paasdbaasapaas12amazonidc_japan.html&#34;&gt;これ&lt;/a&gt;を見ても分かるとおり、当面PaaSと言えばDBaaSです。DBの構築とか運用面倒ですものね。Troveはレプリケーション機能が追加されたり、いよいよこれから本格化と思います。&lt;/p&gt;

&lt;p&gt;2枚目のカレンダーなので、ネタ感あふれる副音声モードでお届けしました。ではメリークリスマス。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenStackのツール環境をImmutableに整える</title>
      <link>http://torumakabe.github.io/post/openstack-tools/</link>
      <pubDate>Sun, 14 Sep 2014 00:00:00 +0900</pubDate>
      
      <guid>http://torumakabe.github.io/post/openstack-tools/</guid>
      <description>

&lt;h3 id=&#34;タイトルは釣りです:06c978f415868c5d089a8460c0068f0d&#34;&gt;タイトルは釣りです&lt;/h3&gt;

&lt;p&gt;すいません。でも、日本のどこかに、わたしを待ってる、理解し合える人がいらっしゃると思います。&lt;/p&gt;

&lt;h3 id=&#34;なぜ必要か:06c978f415868c5d089a8460c0068f0d&#34;&gt;なぜ必要か?&lt;/h3&gt;

&lt;p&gt;いけてるOpenStackerは、相手にするOpenStack環境がオンプレであろうがパブリッククラウドであろうが、すぐにコマンド叩いて「なるほどこの環境は。。。ニヤリ」とできるものです。そういうものです。&lt;/p&gt;

&lt;h3 id=&#34;やりたいこと:06c978f415868c5d089a8460c0068f0d&#34;&gt;やりたいこと&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;OpenStack CLIなどのツールを詰め込んだ環境を、必要な時に、すぐ使いたい・作りたい&lt;/li&gt;
&lt;li&gt;Windows、Macどちらでも同様の環境にしたい&lt;/li&gt;
&lt;li&gt;相手にするOpenStackがオンプレでも、パブリッククラウドでも、また、ツールがぶら下がっているネットワーク環境の違いも、設定やスクリプトで吸収&lt;/li&gt;
&lt;li&gt;Windows、Mac環境を汚さない、また、汚されない&lt;/li&gt;
&lt;li&gt;コマンド2、3発程度で、気軽に作って消せる&lt;/li&gt;
&lt;li&gt;VMできたらすぐログイン、即OpenStack CLIが使える&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;方針:06c978f415868c5d089a8460c0068f0d&#34;&gt;方針&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;OpenStackの各種ツールを動かすOSはLinuxとし、VM上に作る&lt;/li&gt;
&lt;li&gt;VagrantでWindows/Macの違いを吸収する&lt;/li&gt;
&lt;li&gt;VMイメージをこねくり回さず、常にまっさらなベースOSに対し構成管理ツールでプロビジョニングを行う&lt;/li&gt;
&lt;li&gt;構成管理ツールはAnsibleを使う(本を買ったので、使いたかっただけ)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;前提条件:06c978f415868c5d089a8460c0068f0d&#34;&gt;前提条件&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Windows 8.1 &amp;amp; VMware Worksation 10.0.3&lt;/li&gt;
&lt;li&gt;OSX 10.9.4 &amp;amp; VirtualBox 4.3.16&lt;/li&gt;
&lt;li&gt;Vagrant 1.6.5  (VMware用ライセンス買いました)&lt;/li&gt;
&lt;li&gt;ひとまずOpenStack CLIを使えるところまで作る&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;ではvagrantfileを見てみましょう:06c978f415868c5d089a8460c0068f0d&#34;&gt;ではVagrantfileを見てみましょう&lt;/h3&gt;

&lt;p&gt;&lt;script type=&#34;text/javascript&#34; src=&#34;http://gist.github.com/a470e86a1477cd76d4f4.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;これがわたしが作ったVagrantfileです。見ての通りですが、以下に補足します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VMwareとVirtualBoxでなるべく環境を合わせるため、opscodeの&lt;a href=&#34;https://github.com/opscode/bento&#34;&gt;Bento&lt;/a&gt;で、事前にboxファイルを作ってます。ubuntu14.04としました。&lt;/li&gt;
&lt;li&gt;実行ディレクトリにprovision.shを置きます。&lt;/li&gt;
&lt;li&gt;provision.shでubuntuへansibleをインストールし、追って入れたてホヤホヤのansibleで環境を整えます。&lt;/li&gt;
&lt;li&gt;実行ディレクトリ内のansibleディレクトリに、ansibleのplaybook(site.yml)と変数定義ファイル(vars/env.yml)を置きます。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;hostsファイルには以下のようにlocalhostを定義します。&lt;/p&gt;

&lt;p&gt;[localhost]&lt;br /&gt;
127.0.0.1 ansible_connection=local&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;provision-sh解説:06c978f415868c5d089a8460c0068f0d&#34;&gt;provision.sh解説&lt;/h4&gt;

&lt;p&gt;&lt;script type=&#34;text/javascript&#34; src=&#34;http://gist.github.com/57ae9f8edbe6cf30cd16.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;ansibleのインストールとplaybookの実行。playbookの実行が回りくどい感じなのは、Vagrantのフォルダ同期機能でパーミッションが正しく設定できなかったゆえのワークアラウンドです。&lt;/p&gt;

&lt;h4 id=&#34;playbook-site-yml-解説:06c978f415868c5d089a8460c0068f0d&#34;&gt;playbook(site.yml)解説&lt;/h4&gt;

&lt;p&gt;&lt;script type=&#34;text/javascript&#34; src=&#34;http://gist.github.com/6c5d8ae296948b8d4070.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;varsディレクトリ配下に、環境変数を定義したenv.ymlを置きます。ここで対象のOpenStack環境を指定します。&lt;/p&gt;

&lt;p&gt;OS_TENANT_NAME: your_tenant_name&lt;br /&gt;
OS_USERNAME: your_username&lt;br /&gt;
&amp;hellip;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;という感じで並べてください。.bashrcに追加されます。
- タイムゾーンをAsia/Tokyoにします。
- 必要なパッケージ、pipの導入後、OpenStack CLI群をインストールします。&lt;/p&gt;

&lt;h3 id=&#34;windowsでの実行例:06c978f415868c5d089a8460c0068f0d&#34;&gt;Windowsでの実行例&lt;/h3&gt;

&lt;p&gt;Vagrant &amp;amp; AnsibleはMacの情報が多いので、ここではWindowsでの実行例を。PowerShellを管理者権限で起動し、Vagrantfileやprovision.sh、ansible関連ファイルが住むディレクトリでvagrant up。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Users\hoge&amp;gt; vagrant up
Bringing machine &#39;default&#39; up with &#39;vmware_workstation&#39; provider...
==&amp;gt; default: Cloning VMware VM: &#39;opscode-ubuntu1404&#39;. This can take some time...
(snip)
==&amp;gt; default: TASK: [install OpenStack CLIs] ************************************************
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-neutronclient)
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-novaclient)
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-cinderclient)
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-keystoneclient)
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-swiftclient)
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-keystoneclient)
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-glanceclient)
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-troveclient)
==&amp;gt; default: changed: [127.0.0.1] =&amp;gt; (item=python-designateclient)
==&amp;gt; default:
==&amp;gt; default: PLAY RECAP ********************************************************************
==&amp;gt; default: 127.0.0.1                  : ok=8    changed=7    unreachable=0    failed=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;うまく動いたようです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Users\hoge&amp;gt; vagrant ssh
cygwin warning:
  MS-DOS style path detected: C:/Users/hoge/.vagrant.d/insecure_private_key
  Preferred POSIX equivalent is: /cygdrive/c/Users/hoge/.vagrant.d/insecure_private_key
  CYGWIN environment variable option &amp;quot;nodosfilewarning&amp;quot; turns off this warning.
  Consult the user&#39;s guide for more details about POSIX paths:
    http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
Welcome to Ubuntu 14.04 LTS (GNU/Linux 3.13.0-24-generic x86_64)

 * Documentation:  https://help.ubuntu.com/
Last login: Sun Apr 20 02:21:46 2014 from 172.16.230.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;vagrant sshでサクッとログイン。ちなみに、これだけのためにcygwin入れてます。負けは認めます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vagrant@vagrant:~$ nova list
+----+------+--------+------------+-------------+----------+
| ID | Name | Status | Task State | Power State | Networks |
+----+------+--------+------------+-------------+----------+
+----+------+--------+------------+-------------+----------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;いきなりnovaコマンド使えます。&lt;/p&gt;

&lt;p&gt;なおproxy環境下では、/etc/apt/apt.conf、.bashrcやplaybookにproxy設定をするよう、provision.shとplaybook(site.yml)をいじれば動くと思います。まだやってませんが。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>