<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure &middot; re-imagine</title>

    <meta name="description" content="my life is the sum of my imagination">

    <meta name="generator" content="Hugo 0.15" />
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="tmak_tw" />
    <meta name="twitter:title" content="Azure &middot; re-imagine">
    <meta name="twitter:description" content="my life is the sum of my imagination">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Azure &middot; re-imagine">
    <meta property="og:description" content="my life is the sum of my imagination">

    <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Oxygen:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-old-ie-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css">
    <!--<![endif]-->

    <link rel="stylesheet" href="http://torumakabe.github.io//css/all.min.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

    <link rel="alternate" type="application/rss+xml" title="re-imagine" href="http://torumakabe.github.io//index.xml" />
</head>
<body>


<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
    <div class="header">
        <hgroup>
            <h1 class="brand-title"><a href="http://torumakabe.github.io/">re-imagine</a></h1>
            <h2 class="brand-tagline"> my life is the sum of my imagination </h2>
        </hgroup>

        <nav class="nav">
            <ul class="nav-list">
                
                <li class="nav-item">
                    <a class="pure-button" href="https://twitter.com/tmak_tw"><i class="fa fa-twitter"></i> Twitter</a>
                </li>
                
                
                <li class="nav-item">
                    <a class="pure-button" href="https://github.com/ToruMakabe "><i class="fa fa-github-alt"></i> github</a>
                </li>
                
                <li class="nav-item">
                    <a class="pure-button" href="http://torumakabe.github.io//index.xml"><i class="fa fa-rss"></i> rss</a>
                </li>
            </ul>
        </nav>
    </div>
</div>


    <div class="content pure-u-1 pure-u-md-3-4">
        <div>
            
            <div class="posts">
                
                <h1 class="content-subhead">08 May 2016, 14:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_functions_fbmsgapi/" class="post-title">Azure FunctionsとFacebook Messenger APIで好みなんて聞いてないBotを作る</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="まだ好みなんて聞いてないぜ:99ec2e7c4c63926799149ef94c45b73e">まだ好みなんて聞いてないぜ</h2>

<p>Build 2016で、<a href="https://azure.microsoft.com/ja-jp/services/functions/">Azure Functions</a>が発表されました。</p>

<p>Azure Functionsは、</p>

<ol>
<li>アプリを放り込めば動く。サーバの管理が要らない。サーバレス。  #でもこれは従来のPaaSもそう</li>
<li>利用メモリ単位での、粒度の細かい課金。  #現在プレビュー中にて、詳細は今後発表</li>
<li>Azure内外機能との、容易なイベント連動。</li>
</ol>

<p>が特徴です。AWSのLambdaと似てるっちゃ似ています。</p>

<p>何が新しいかというと、特に3つ目の特徴、イベント連動です。触ってみなければわからん、ということで、流行りのBotでも作ってみたいと思います。</p>

<h3 id="基本方針:99ec2e7c4c63926799149ef94c45b73e">基本方針</h3>

<ul>
<li>FunctionsはAzure内の様々な機能と<a href="https://azure.microsoft.com/ja-jp/documentation/articles/functions-reference/#bindings">イベント連動</a>できるが、あえてサンプルの少ないAzure外とつないでみる</li>
<li>Facebook Messenger APIを使って、webhook連動する</li>
<li>Facebook Messenger向けに書き込みがあると、ランダムでビールの種類と参考URLを返す</li>
<li>ビールは<a href="http://beertaster.org/beerstyle/web/beerstyle_main_j.html">Craft Beer Association</a>の分類に従い、協会のビアスタイル・ガイドライン参考ページの該当URLを返す</li>
<li>Botらしく、それらしい文末表現をランダムで返す</li>
<li>好みとか文脈は全く聞かないぜSorry</li>
<li>アプリはNodeで書く。C#のサンプルは増えてきたので</li>
<li>静的データをランダムに返す、かつ少量なのでメモリ上に広げてもいいが、せっかくなのでNodeと相性のいいDocumentDBを使う</li>
<li>DocumentDBではSQLでいうORDER BY RAND()のようなランダムな問い合わせを書けないため、ストアドプロシージャで実装する  #<a href="https://gist.github.com/murdockcrc/12266f9d844be416a6a0">サンプル</a></li>
<li>FunctionsとGithubを連携し、GithubへのPush -&gt; Functionsへのデプロイというフローを作る</li>
<li>拡張性はひとまず目をつぶる  #<a href="http://qiita.com/yoichiro@github/items/6d4c7309210af20a5c8f">この辺の話</a></li>
</ul>

<p>ひとまずFunctionsとBotの枠組みの理解をゴールとします。ロジックをたくさん書けばそれなりに文脈を意識した返事はできるのですが、書かずに済む仕組みがこれからいろいろ出てきそうなので、書いたら負けの精神でぐっと堪えます。</p>

<h2 id="必要な作業:99ec2e7c4c63926799149ef94c45b73e">必要な作業</h2>

<p>以下が必要な作業の流れです。</p>

<ul>
<li>Azureで

<ul>
<li>Function Appの作成  #1</li>
<li>Bot用Functionの作成 #2</li>
<li>Facebook Messenger APIとの接続検証  #6</li>
<li>Facebook Messenger API接続用Tokenの設定  #8</li>
<li>DocumentDBのデータベース、コレクション作成、ドキュメント投入  #9</li>
<li>DocumentDBのストアドプロシージャ作成  #10</li>
<li>Function Appを書く  #11</li>
<li>FunctionsのサイトにDocumentDB Node SDKを導入 #12</li>
<li>Function AppのGithub連携設定  #13</li>
<li>Function Appのデプロイ (GithubへのPush)  #14</li>
</ul></li>
<li>Facebookで

<ul>
<li>Facebook for Developersへの登録  #3</li>
<li>Botをひも付けるFacebook Pageの作成  #4</li>
<li>Bot用マイアプリの作成  #5</li>
<li>Azure Functionsからのcallback URLを登録、接続検証  #6</li>
<li>Azure Functions向けTokenを生成 #7</li>
</ul></li>
</ul>

<p>アプリのコード書きの他はそれほど重くない作業ですが、すべての手順を書くと本ができそうです。Function Appの作りにポイントを絞りたいので、以下、参考になるサイトをご紹介します。</p>

<ul>
<li>Function Appを書くまで、#1〜2、#5〜8は、<a href="http://oauth.jp/blog/2016/04/19/fb-message-callback-with-azure-function/">こちらのブログエントリ</a>がとても参考になります。</li>
<li>Facebook for Developersへの登録、#3は、<a href="https://developers.facebook.com/">https://developers.facebook.com/</a> から。いきなり迷子の人は、<a href="http://qiita.com/k_kuni/items/3d7176ee4e3009b45dd8">こちら</a>も参考に。</li>
<li>Facebook Pageの作成は、<a href="http://allabout.co.jp/gm/gc/387840/">ここ</a>を。Botで楽しむだけなら細かい設定は後回しでいいです。</li>
<li>DocumentDBについては、<a href="https://azure.microsoft.com/ja-jp/documentation/articles/documentdb-introduction/">公式</a>を。

<ul>
<li><a href="https://azure.microsoft.com/ja-jp/documentation/articles/documentdb-create-account/">DBアカウント〜コレクション作成</a></li>
<li><a href="https://azure.microsoft.com/ja-jp/documentation/articles/documentdb-import-data/">ドキュメントインポート</a></li>
<li><a href="https://azure.microsoft.com/ja-jp/documentation/articles/documentdb-programming/">ストアドプロシージャ</a></li>
</ul></li>
<li>FunctionsのサイトにDocumentDB Node SDKを導入する#12は、<a href="http://tech.guitarrapc.com/entry/2016/04/05/043723">こちら</a>を。コンソールからnpm installできます。<br /></li>
<li>Github連携設定、#13〜14は、<a href="http://tech.guitarrapc.com/entry/2016/04/03/051552">こちら</a>がとても参考になります。</li>
</ul>

<h2 id="function-appのサンプル:99ec2e7c4c63926799149ef94c45b73e">Function Appのサンプル</h2>

<p>Githubにソースを<a href="https://github.com/ToruMakabe/MakabeerBot">置いておきます</a>。</p>

<p>ちなみにこのディレクトリ階層はGithub連携を考慮し、Function Appサイトのそれと合わせています。以下がデプロイ後のサイト階層です。</p>

<pre><code>D:\home\site\wwwroot
├── fb-message-callback
│   ├── TestOutput.json
│   ├── function.json
│   └── index.js  #これが今回のアプリ
├── node_modules  #DocumentDB Node SDKが入っている
├── host.json
├── README.md
</code></pre>

<p>なお、DocumentDBのSDKパッケージは、なぜかfb-message-callbackローカルに置くと読み込まれないため、暫定的にルートへ配置しています。</p>

<p>ではFunction Appの実体、index.jsを見てみましょう。</p>

<pre><code>var https = require('https');
var documentClient = require(&quot;documentdb&quot;).DocumentClient;
const databaseUrl = &quot;dbs/&quot; + process.env.APPSETTING_DOCDB_DB_ID;

var client = new documentClient(process.env.APPSETTING_DOCDB_ENDPOINT, { &quot;masterKey&quot;: process.env.APPSETTING_DOCDB_AUTHKEY });

function sendTextMessage(sender, text, context) {
  getDataFromDocDB().then(function (value) {
    var msgAll = value[0].randomDocument.beer + &quot; &quot; + value[1].randomDocument.msg;
    var postData = JSON.stringify({
      recipient: sender,
      message: {
        &quot;attachment&quot;:{
          &quot;type&quot;:&quot;template&quot;,
          &quot;payload&quot;:{
            &quot;template_type&quot;:&quot;button&quot;,
            &quot;text&quot;:msgAll,
            &quot;buttons&quot;:[
              {
                &quot;type&quot;:&quot;web_url&quot;,
                &quot;url&quot;:value[0].randomDocument.url,
                &quot;title&quot;:&quot;詳しく&quot;
              }
            ]
          }
        }
      }
    });
    var req = https.request({
      hostname: 'graph.facebook.com',
      port: 443,
      path: '/v2.6/me/messages',
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer ' + process.env.APPSETTING_FB_PAGE_TOKEN
      }
    });
    req.write(postData);
    req.end();
  }).catch(function(err){
    context.log(err);
  });  
}

function getRandomDoc(sprocUrl){
  return new Promise(function (resolve, reject) {
    const sprocParams = {};
    client.executeStoredProcedure(sprocUrl, sprocParams, function(err, result, responseHeaders) {
      if (err) {
        reject(err);
      }
      if (result) {
        resolve(result);
      }
    });
  });
}

var results = {
  beer: function getBeer() {
    var collectionUrl = databaseUrl + &quot;/colls/beer&quot;;
    var sprocUrl = collectionUrl + &quot;/sprocs/GetRandomDoc&quot;;
    return getRandomDoc(sprocUrl).then(function (result) {
      return result;
    });
  },
  eom: function getEom() {
    var collectionUrl = databaseUrl + &quot;/colls/eom&quot;;
    var sprocUrl = collectionUrl + &quot;/sprocs/GetRandomDoc&quot;;
    return getRandomDoc(sprocUrl).then(function (result) {
      return result;
    });
  }
}

function getDataFromDocDB() {
  return Promise.all([results.beer(), results.eom()]);
}

module.exports = function (context, req) {
  messaging_evts = req.body.entry[0].messaging;
  for (i = 0; i &lt; messaging_evts.length; i++) {
    evt = req.body.entry[0].messaging[i];
    sender = evt.sender;
    if (evt.message &amp;&amp; evt.message.text, context) {
      sendTextMessage(sender, evt.message.text, context);
    }
  }
  context.done();
};
</code></pre>

<ul>
<li>最下部のmodule.export以降のブロックで、webhookイベントを受け取ります</li>
<li>それがmessageイベントで、テキストが入っていれば、sendTextMessage関数を呼びます

<ul>
<li>好みは聞いてないので、以降、受け取ったテキストが読まれることはありませんが</li>
</ul></li>
<li>sendTextMessage関数内、getDataFromDocDB関数呼び出しでDocumentDBへ問い合わせてビールと文末表現をランダムに取り出します

<ul>
<li>コレクション&rdquo;beer&rdquo;、&rdquo;eom(end of message)&ldquo;の構造はそれぞれこんな感じ</li>
</ul></li>
</ul>

<pre><code>{
  &quot;url&quot;: &quot;http://beertaster.org/beerstyle/web/001A.html#japanese&quot;,
  &quot;beer&quot;: &quot;酵母なし、ライトアメリカン・ウィートビール&quot;,
  &quot;id&quot;: &quot;bf3636c5-4284-4e7a-b587-9002a771f214&quot;
}
</code></pre>

<pre><code>{
  &quot;msg&quot;: &quot;はウマい&quot;,
  &quot;id&quot;: &quot;acd63222-2138-4e19-894e-dc85a950be64&quot;
}
</code></pre>

<ul>
<li>DocumentDBの2つのコレクションへの問い合わせが終わった後、Facebookへメッセージを返すため、逐次処理目的でJavaScriptの<a href="http://azu.github.io/promises-book/">Promise</a>を使っています</li>
</ul>

<p>いかがでしょう。好みを聞かない気まぐれBotとはいえ、気軽に作れることがわかりました。ゼロからこの手のイベント処理を作るの、面倒ですものね。</p>

<p><em>&ldquo;なお、Facebook Messenger API連動アプリの外部公開には、審査が必要とのことです&rdquo;</em></p>

                    </div>
                </section>
                
                <h1 class="content-subhead">29 Apr 2016, 17:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_batch_docker/" class="post-title">Azure BatchとDockerで管理サーバレスバッチ環境を作る</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="サーバレスって言いたいだけじゃないです:1e958ca6820e4dcff939a22a84382ed3">サーバレスって言いたいだけじゃないです</h2>

<p>Linux向けAzure BatchのPreviewが<a href="https://azure.microsoft.com/ja-jp/blog/announcing-support-of-linux-vm-on-azure-batch-service/">はじまり</a>ました。地味ですが、なかなかのポテンシャルです。</p>

<p>クラウドでバッチを走らせる時にチャレンジしたいことの筆頭は「ジョブを走らせる時だけサーバ使う。待機時間は消しておいて、
節約」でしょう。</p>

<p>ですが、仕組み作りが意外に面倒なんですよね。管理サーバを作って、ジョブ管理ソフト入れて、Azure SDK/CLI入れて。クレデンシャルを安全に管理して。可用性確保して。バックアップして。で、管理サーバは消せずに常時起動。なんか中途半端です。</p>

<p>その課題、Azure Batchを使って解決しましょう。レッツ管理サーバレスバッチ処理。</p>

<h2 id="コンセプト:1e958ca6820e4dcff939a22a84382ed3">コンセプト</h2>

<ul>
<li>管理サーバを作らない</li>
<li>Azure Batchコマンドでジョブを投入したら、あとはスケジュール通りに定期実行される</li>
<li>ジョブ実行サーバ群(Pool)は必要な時に作成され、処理が終わったら削除される</li>
<li>サーバの迅速な作成とアプリ可搬性担保のため、dockerを使う</li>
<li>セットアップスクリプト、タスク実行ファイル、アプリ向け入力/出力ファイルはオブジェクトストレージに格納</li>
</ul>

<h2 id="サンプル:1e958ca6820e4dcff939a22a84382ed3">サンプル</h2>

<p>Githubにソースを<a href="https://github.com/ToruMakabe/Azure_Batch_Sample">置いておきます</a>。</p>

<h3 id="バッチアカウントとストレージアカウント-コンテナの作成とアプリ-データの配置:1e958ca6820e4dcff939a22a84382ed3">バッチアカウントとストレージアカウント、コンテナの作成とアプリ、データの配置</h3>

<p><a href="https://azure.microsoft.com/ja-jp/documentation/articles/batch-technical-overview/">公式ドキュメント</a>で概要を確認しましょう。うっすら理解できたら、バッチアカウントとストレージアカウントを作成します。</p>

<p>ストレージアカウントに、Blobコンテナを作ります。サンプルの構成は以下の通り。</p>

<pre><code>.
├── blob
│   ├── application
│   │   ├── starttask.sh
│   │   └── task.sh
│   ├── input
│   │   └── the_star_spangled_banner.txt
│   └── output
</code></pre>

<p>applicationコンテナに、ジョブ実行サーバ作成時のスクリプト(starttask.sh)と、タスク実行時のスクリプト(task.sh)を配置します。</p>

<ul>
<li><a href="https://github.com/ToruMakabe/Azure_Batch_Sample/blob/master/blob/application/starttask.sh">starttask.sh</a> - docker engineをインストールします</li>
<li><a href="https://github.com/ToruMakabe/Azure_Batch_Sample/blob/master/blob/application/task.sh">task.sh</a> - docker hubからサンプルアプリが入ったコンテナを持ってきて実行します。<a href="https://github.com/ToruMakabe/Azure_Batch_Sample/tree/master/docker">サンプル</a>はPythonで書いたシンプルなWord Countアプリです</li>
</ul>

<p>また、アプリにデータをわたすinputコンテナと、実行結果を書き込むoutputコンテナも作ります。サンプルのinputデータはアメリカ国歌です。</p>

<p>コンテナ、ファイルには、適宜SASを生成しておいてください。inputではreadとlist、outputでは加えてwrite権限を。</p>

<p>さて、いよいよジョブをJSONで定義します。詳細は<a href="https://msdn.microsoft.com/en-us/library/azure/dn820158.aspx?f=255&amp;MSPPError=-2147217396">公式ドキュメント</a>を確認してください。ポイントだけまとめます。</p>

<ul>
<li>2016/04/29 05:30(UTC)から開始する - schedule/doNotRunUntil</li>
<li>4時間ごとに実行する - schedule/recurrenceInterval</li>
<li>ジョブ実行後にサーバプールを削除する - jobSpecification/poolInfo/autoPoolSpecification/poolLifetimeOption</li>
<li>ジョブ実行時にtask.shを呼び出す  - jobSpecification/jobManagerTask/commandLine</li>
<li>サーバはUbuntu 14.04とする - jobSpecification/poolInfo/autoPoolSpecification/virtualMachineConfiguration</li>
<li>サーバ数は1台とする - jobSpecification/poolInfo/autoPoolSpecification/pool/targetDedicated</li>
<li>サーバプール作成時にstarttask.shを呼び出す - jobSpecification/poolInfo/autoPoolSpecification/pool/startTask</li>
</ul>

<pre><code>  {
  &quot;odata.metadata&quot;:&quot;https://myaccount.myregion.batch.azure.com/$metadata#jobschedules/@Element&quot;,
  &quot;id&quot;:&quot;myjobschedule1&quot;,
  &quot;schedule&quot;: {
    &quot;doNotRunUntil&quot;:&quot;2016-04-29T05:30:00.000Z&quot;,
    &quot;recurrenceInterval&quot;:&quot;PT4H&quot;
  },
  &quot;jobSpecification&quot;: {
    &quot;priority&quot;:100,
    &quot;constraints&quot;: {
      &quot;maxWallClockTime&quot;:&quot;PT1H&quot;,
      &quot;maxTaskRetryCount&quot;:-1
    },
    &quot;jobManagerTask&quot;: {
      &quot;id&quot;:&quot;mytask1&quot;,
      &quot;commandLine&quot;:&quot;/bin/bash -c 'export LC_ALL=en_US.UTF-8; ./task.sh'&quot;,
      &quot;resourceFiles&quot;: [ {
        &quot;blobSource&quot;:&quot;yourbloburi&amp;sas&quot;,
        &quot;filePath&quot;:&quot;task.sh&quot;
      }], 
      &quot;environmentSettings&quot;: [ {
        &quot;name&quot;:&quot;VAR1&quot;,
        &quot;value&quot;:&quot;hello&quot;
      } ],
      &quot;constraints&quot;: {
        &quot;maxWallClockTime&quot;:&quot;PT1H&quot;,
        &quot;maxTaskRetryCount&quot;:0,
        &quot;retentionTime&quot;:&quot;PT1H&quot;
      },
      &quot;killJobOnCompletion&quot;:false,
      &quot;runElevated&quot;:true,
      &quot;runExclusive&quot;:true
      },
      &quot;poolInfo&quot;: {
        &quot;autoPoolSpecification&quot;: {
          &quot;autoPoolIdPrefix&quot;:&quot;mypool&quot;,
          &quot;poolLifetimeOption&quot;:&quot;job&quot;,
          &quot;pool&quot;: {
            &quot;vmSize&quot;:&quot;STANDARD_D1&quot;,
            &quot;virtualMachineConfiguration&quot;: {
              &quot;imageReference&quot;: {
                &quot;publisher&quot;:&quot;Canonical&quot;,
                &quot;offer&quot;:&quot;UbuntuServer&quot;,
                &quot;sku&quot;:&quot;14.04.4-LTS&quot;,
                &quot;version&quot;:&quot;latest&quot;
              },
              &quot;nodeAgentSKUId&quot;:&quot;batch.node.ubuntu 14.04&quot;
            },
            &quot;resizeTimeout&quot;:&quot;PT15M&quot;,
            &quot;targetDedicated&quot;:1,
            &quot;maxTasksPerNode&quot;:1,
            &quot;taskSchedulingPolicy&quot;: {
              &quot;nodeFillType&quot;:&quot;Spread&quot;
            },
            &quot;enableAutoScale&quot;:false,
            &quot;enableInterNodeCommunication&quot;:false,
            &quot;startTask&quot;: {
              &quot;commandLine&quot;:&quot;/bin/bash -c 'export LC_ALL=en_US.UTF-8; ./starttask.sh'&quot;,
              &quot;resourceFiles&quot;: [ {
                &quot;blobSource&quot;:&quot;yourbloburi&amp;sas&quot;,
                &quot;filePath&quot;:&quot;starttask.sh&quot;
              } ],
              &quot;environmentSettings&quot;: [ {
                &quot;name&quot;:&quot;VAR2&quot;,
                &quot;value&quot;:&quot;Chao&quot;
              } ],
              &quot;runElevated&quot;:true,
              &quot;waitForSuccess&quot;:true
            },
            &quot;metadata&quot;: [ {
              &quot;name&quot;:&quot;myproperty&quot;,
              &quot;value&quot;:&quot;myvalue&quot;
            } ]
          }
        }
      }
    }
  }
</code></pre>

<p>そろそろ人類はJSONに変わるやり口を発明すべきですが、XMLよりはいいですね。</p>

<p>それはさておき、面白そうなパラメータたち。並列バッチやジョブリリース時のタスクなど、今回使っていないものもまだまだあります。応用版はまたの機会に。</p>

<p>ではスケジュールジョブをAzure BatchにCLIで送り込みます。</p>

<pre><code>azure batch job-schedule create -f ./create_jobsched.json -u https://yourendpoint.location.batch.azure.com -a yourbatchaccount -k yourbatchaccountkey
</code></pre>

<p>以上です。あとはAzureにお任せです。4時間に1回、アメリカ国歌の単語を数える刺身タンポポなジョブですが、コツコツいきましょう。</p>

<h2 id="azure-automationとの使い分け:1e958ca6820e4dcff939a22a84382ed3">Azure Automationとの使い分け</h2>

<p>Azure Automationを使っても、ジョブの定期実行はできます。大きな違いは、PowerShellの要否と並列実行フレームワークの有無です。Azure AutomationはPowerShell前提ですが、Azure BatchはPowerShellに馴染みのない人でも使うことができます。また、今回は触れませんでしたが、Azure Batchは並列バッチ、オートスケールなど、バッチ処理に特化した機能を提供していることが特長です。うまく使い分けましょう。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">21 Apr 2016, 21:30</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_pageblob_billable_linux/" class="post-title">Azure Linux VMのディスク利用料節約Tips</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="定義領域全てが課金されるわけではありません:73b15a413c7cb87e88f45a7aaba2eebd">定義領域全てが課金されるわけではありません</h2>

<p>AzureのIaaSでは、VMに接続するディスクとしてAzure StorageのPage Blobを使います。Page Blobは作成時に容量を定義しますが、課金対象となるのは、実際に書き込んだ領域分のみです。たとえば10GBytesのVHD Page Blobを作ったとしても、1GBytesしか書き込んでいなければ、課金対象は1GBytesです。</p>

<p>なお、Premium Storageは例外です。<a href="https://azure.microsoft.com/ja-jp/pricing/details/storage/">FAQ</a>を確認してみましょう。</p>

<pre><code>仮想マシンに空の 100 GB ディスクを接続した場合、100 GB 全体に対する料金が請求されますか? それとも使用したストレージ領域の分だけが請求されますか?

空の 100 GB ディスクが Premium Storage アカウントによって保持されている場合、P10 (128 GB) ディスクの料金が課金されます。その他の種類の Storage アカウントが使用されている場合、割り当てられたディスク サイズに関わらず、ディスクに書き込まれたデータを保存するために使用しているストレージ領域分のみ請求されます。
</code></pre>

<p>詳細な定義は、以下で。</p>

<p><a href="https://blogs.msdn.microsoft.com/windowsazurestorage/2010/07/08/understanding-windows-azure-storage-billing-bandwidth-transactions-and-capacity/">Understanding Windows Azure Storage Billing – Bandwidth, Transactions, and Capacity</a></p>

<h2 id="書き込み方はosやファイルシステム次第:73b15a413c7cb87e88f45a7aaba2eebd">書き込み方はOSやファイルシステム次第</h2>

<p>じゃあ、OSなりファイルシステムが、実際にどのタイミングでディスクに書き込むのか、気になりますね。実データの他に管理情報、メタデータがあるので、特徴があるはずです。Linuxで検証してみましょう。</p>

<ul>
<li>RHEL 7.2 on Azure</li>
<li>XFS &amp; Ext4</li>
<li>10GBytesのPage Blobの上にファイルシステムを作成</li>
<li>mkfsはデフォルト</li>
<li>mountはデフォルトとdiscardオプションありの2パターン</li>
<li>MD、LVM構成にしない</li>
<li>以下のタイミングで課金対象容量を確認

<ul>
<li>Page BlobのVMアタッチ時</li>
<li>ファイルシステム作成時</li>
<li>マウント時</li>
<li>約5GBytesのデータ書き込み時 (ddで/dev/zeroをbs=1M、count=5000で書き込み)</li>
<li>5GBytesのファイル削除時</li>
</ul></li>
</ul>

<p>課金対象容量は、以下のPowerShellで取得します。リファレンスは<a href="https://gallery.technet.microsoft.com/scriptcenter/Get-Billable-Size-of-32175802">ここ</a>。</p>

<pre><code>$Blob = Get-AzureStorageBlob yourDataDisk.vhd -Container vhds -Context $Ctx

$blobSizeInBytes = 124 + $Blob.Name.Length * 2

$metadataEnumerator = $Blob.ICloudBlob.Metadata.GetEnumerator()
while ($metadataEnumerator.MoveNext())
{
    $blobSizeInBytes += 3 + $metadataEnumerator.Current.Key.Length + $metadataEnumerator.Current.Value.Length
}

$Blob.ICloudBlob.GetPageRanges() | 
    ForEach-Object { $blobSizeInBytes += 12 + $_.EndOffset - $_.StartOffset }

return $blobSizeInBytes
</code></pre>

<p>ストレージコンテキストの作り方は<a href="https://azure.microsoft.com/ja-jp/documentation/articles/storage-powershell-guide-full/">ここ</a>を参考にしてください。</p>

<h2 id="結果:73b15a413c7cb87e88f45a7aaba2eebd">結果</h2>

<h3 id="xfs:73b15a413c7cb87e88f45a7aaba2eebd">XFS</h3>

<table>
<thead>
<tr>
<th align="left">　確認タイミング　</th>
<th align="right">　課金対象容量(Bytes)　</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Page BlobのVMアタッチ時</td>
<td align="right">960</td>
</tr>

<tr>
<td align="left">ファイルシステム作成時</td>
<td align="right">10,791,949</td>
</tr>

<tr>
<td align="left">マウント時</td>
<td align="right">10,791,949</td>
</tr>

<tr>
<td align="left">5GBytesのデータ書き込み時</td>
<td align="right">5,253,590,051</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時</td>
<td align="right">5,253,590,051</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時 (discard)</td>
<td align="right">10,710,029</td>
</tr>
</tbody>
</table>

<h3 id="ext4:73b15a413c7cb87e88f45a7aaba2eebd">Ext4</h3>

<table>
<thead>
<tr>
<th align="left">　確認タイミング　</th>
<th align="right">　課金対象容量(Bytes)　</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Page BlobのVMアタッチ時</td>
<td align="right">960</td>
</tr>

<tr>
<td align="left">ファイルシステム作成時</td>
<td align="right">138,683,592</td>
</tr>

<tr>
<td align="left">マウント時</td>
<td align="right">306,451,689</td>
</tr>

<tr>
<td align="left">5GBytesのデータ書き込み時</td>
<td align="right">5,549,470,887</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時</td>
<td align="right">5,549,470,887</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時 (discard)</td>
<td align="right">306,586,780</td>
</tr>
</tbody>
</table>

<p>この結果から、以下のことがわかります。</p>

<ul>
<li>10GBytesのBlobを作成しても、全てが課金対象ではない</li>
<li>当然だが、ファイルシステムによってメタデータの書き方が違う、よって書き込み容量も異なる</li>
<li>discardオプションなしでマウントすると、ファイルを消しても課金対象容量は減らない

<ul>
<li>OSがPage Blobに&rdquo;消した&rdquo;と伝えないから</li>
<li>discardオプションにてSCSI UNMAPがPage Blobに伝えられ、領域は解放される(課金対象容量も減る)</li>
<li>discardオプションはリアルタイムであるため便利。でも性能影響があるため、実運用ではバッチ適用(fstrim)が<a href="https://access.redhat.com/documentation/ja-JP/Red_Hat_Enterprise_Linux/7/html/Storage_Administration_Guide/ch02s05.html">おすすめ</a></li>
</ul></li>
</ul>

<p>知っているとコスト削減に役立つTipsでした。ぜひ運用前には、利用予定のファイルシステムやオプションで、事前に検証してみてください。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">17 Apr 2016, 10:30</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_docker_cntk/" class="post-title">AzureとDockerでDeep Learning(CNTK)環境をサク作する</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="気軽に作って壊せる環境を作る:7c419a069d08019c3093e0308a68c463">気軽に作って壊せる環境を作る</h2>

<p>Deep Learning環境設計のお手伝いをする機会に恵まれまして。インフラおじさんはDeep Learningであれこれする主役ではないのですが、ちょっとは中身を理解しておきたいなと思い、環境作ってます。</p>

<p>試行錯誤するでしょうから、萎えないようにデプロイは自動化します。</p>

<h2 id="方針:7c419a069d08019c3093e0308a68c463">方針</h2>

<ul>
<li>インフラはAzure Resource Manager Templateでデプロイする

<ul>
<li>Linux (Ubuntu 14.04) VM, 仮想ネットワーク/ストレージ関連リソース</li>
</ul></li>
<li>CNTKをビルド済みのdockerリポジトリをDocker Hubに置いておく

<ul>
<li>Dockerfileの元ネタは<a href="https://github.com/Microsoft/CNTK/tree/master/Tools/docker">ここ</a>

<ul>
<li>GPUむけもあるけどグッと我慢、今回はCPUで</li>
</ul></li>
<li>Docker Hub上のリポジトリは <a href="https://hub.docker.com/r/torumakabe/cntk-cpu/">torumakabe/cntk-cpu</a></li>
</ul></li>
<li>ARM TemplateデプロイでVM Extensionを仕込んで、上物のセットアップもやっつける

<ul>
<li>docker extensionでdocker engineを導入</li>
<li>custom script extensionでdockerリポジトリ(torumakabe/cntk-cpu)をpull</li>
</ul></li>
<li>VMにログインしたら即CNTKを使える、幸せ</li>
</ul>

<h2 id="使い方:7c419a069d08019c3093e0308a68c463">使い方</h2>

<p>Azure CLIでARM Templateデプロイします。WindowsでもMacでもLinuxでもOK。</p>

<p>リソースグループを作ります。</p>

<pre><code>C:\Work&gt; azure group create CNTK -l &quot;Japan West&quot;
</code></pre>

<p>ARMテンプレートの準備をします。テンプレートはGithubに置いておきました。</p>

<ul>
<li><a href="https://github.com/ToruMakabe/CNTK/blob/master/deploy_singlenode/azuredeploy.json">azuredeploy.json</a>

<ul>
<li>編集不要です</li>
</ul></li>
<li><a href="https://github.com/ToruMakabe/CNTK/blob/master/deploy_singlenode/azuredeploy.parameters.sample.json">azuredeploy.parameters.json</a>

<ul>
<li>テンプレートに直で書かきたくないパラメータです</li>
<li>fileUris、commandToExecute以外は、各々で</li>
<li>fileUris、commandToExecuteもGist読んでdocker pullしているだけなので、お好みで変えてください</li>
<li>ファイル名がazuredeploy.parameters.&ldquo;sample&rdquo;.jsonなので、以降の手順では&rdquo;sample&rdquo;を外して読み替えてください</li>
</ul></li>
</ul>

<p>うし、デプロイ。</p>

<pre><code>C:\Work&gt; azure group deployment create CNTK dep01 -f .\azuredeploy.json -e .\azuredeploy.parameters.json
</code></pre>

<p>10分くらい待つと、できあがります。VMのパブリックIPを確認し、sshしましょう。</p>

<p>docker engine入ってますかね。</p>

<pre><code>yourname@yournamecntkr0:~$ docker -v
Docker version 1.11.0, build 4dc5990
</code></pre>

<p>CNTKビルド済みのdockerイメージ、pullできてますかね。</p>

<pre><code>yourname@yournamecntkr0:~$ docker images
REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
yournamebe/cntk-cpu   latest              9abab8a76543        9 hours ago         2.049 GB
</code></pre>

<p>問題なし。ではエンジョイ Deep Learning。</p>

<pre><code>yourname@yournamecntkr0:~$ docker run -it torumakabe/cntk-cpu
root@a1234bc5d67d:/cntk#
</code></pre>

<p>CNTKの利用例は、<a href="https://github.com/Microsoft/CNTK/tree/master/Examples">Github</a>にあります。</p>

<h2 id="今後の展開:7c419a069d08019c3093e0308a68c463">今後の展開</h2>

<p>インフラおじさんは、最近Linuxむけに<a href="https://azure.microsoft.com/ja-jp/blog/announcing-support-of-linux-vm-on-azure-batch-service/">Previewがはじまった</a>Azure Batchと、このエントリで使った仕掛けを組み合わせて、大規模並列Deep Learning環境の自動化と使い捨て化を企んでいます。</p>

<p>これだけ簡単に再現性ある環境を作れるなら、常時インフラ起動しておく必要ないですものね。使い捨てでいいです。</p>

<p>もちろんdockerやGPUまわりの性能など別の課題にぶつかりそうですが、人間がどれだけ楽できるかとのトレードオフかと。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">06 Apr 2016, 17:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_auditlog_alert/" class="post-title">Azureの監査ログアラートからWebhookの流れで楽をする</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="監査ログからアラートを上げられるようになります:aafd9305d99be4ae8d2b9c3fb4887452">監査ログからアラートを上げられるようになります</h2>

<p>Azureの監査ログからアラートを上げる機能のプレビューが<a href="https://azure.microsoft.com/ja-jp/blog/new-features-for-azure-alerts-and-autoscale/">はじまりました</a>。これ、地味ですが便利な機能です。日々の運用に効きます。</p>

<h2 id="どんな風に使えるか:aafd9305d99be4ae8d2b9c3fb4887452">どんな風に使えるか</h2>

<p>ルールに合致した監査ログが生成された場合、メール通知とWebhookによる自動アクションができます。可能性無限大です。</p>

<p>たとえば、「特定のリソースグループにVMが生成された場合、そのVMに対し強制的にログ収集エージェントをインストールし、ログを集める」なんてことができます。</p>

<p>これは「生産性を上げるため、アプリ開発チームにVMの生成は委任したい。でもセキュリティなどの観点から、ログは集めておきたい」なんてインフラ担当/Opsの課題に効きます。開発チームに「VM生成時には必ず入れてね」とお願いするのも手ですが、やはり人間は忘れる生き物ですので、自動で適用できる仕組みがあるとうれしい。</p>

<p>これまでは監視用のVMを立てて、「新しいVMがあるかどうか定期的にチェックして、あったらエージェントを叩き込む」なんてことをしていたわけですが、もうそのVMは不要です。定期的なチェックも要りません。アラートからアクションを実現する仕組みを、Azureがマネージドサービスとして提供します。</p>

<h2 id="実装例:aafd9305d99be4ae8d2b9c3fb4887452">実装例</h2>

<p>例としてこんな仕組みを作ってみましょう。</p>

<ul>
<li>西日本リージョンのリソースグループ&rdquo;dev&rdquo;にVMが作成されたら、自動的にメール通知とWebhookを実行</li>
<li>WebhookでAzure AutomationのRunbook Jobを呼び出し、OMS(Operations Management Suite)エージェントを該当のVMにインストール、接続先OMSを設定する</li>
<li>OMSでログ分析</li>
</ul>

<h2 id="準備:aafd9305d99be4ae8d2b9c3fb4887452">準備</h2>

<p>以下の準備ができているか確認します。</p>

<ul>
<li>Azure Automation向けADアプリ、サービスプリンシパル作成</li>
<li>サービスプリンシパルへのロール割り当て</li>
<li>Azure Automationのアカウント作成</li>
<li>Azure Automation Runbook実行時ログインに必要な証明書や資格情報などの資産登録</li>
<li>Azure Automation Runbookで使う変数資産登録 (Runbook内でGet-AutomationVariableで取得できます。暗号化もできますし、コードに含めるべきでない情報は、登録しましょう。後述のサンプルではログイン関連情報、OMS関連情報を登録しています)</li>
<li>OMSワークスペースの作成</li>
</ul>

<p>もしAutomationまわりの作業がはじめてであれば、下記記事を参考にしてください。とてもわかりやすい。</p>

<p><strong><a href="http://qiita.com/sengoku/items/1c3994ac8a2f0f0e88c5">勤務時間中だけ仮想マシンを動かす（スケジュールによる自動起動・停止）</a></strong></p>

<h2 id="azure-automation側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452">Azure Automation側の仕掛け</h2>

<p>先にAutomationのRunbookを作ります。アラート設定をする際、RunbookのWebhook URLが必要になるので。</p>

<p>ちなみにわたしは証明書を使ってログインしています。資格情報を使う場合はログインまわりのコードを読み替えてください。</p>

<pre><code>param ( 
    [object]$WebhookData          
)

if ($WebhookData -ne $null) {  
    $WebhookName    =   $WebhookData.WebhookName
    $WebhookBody    =   $WebhookData.RequestBody  
    $WebhookBody = (ConvertFrom-Json -InputObject $WebhookBody)

    $AlertContext = [object]$WebhookBody.context

    $SPAppID = Get-AutomationVariable -Name 'SPAppID'
    $Tenant = Get-AutomationVariable -Name 'TenantID'
    $OMSWorkspaceId = Get-AutomationVariable -Name 'OMSWorkspaceId'
    $OMSWorkspaceKey = Get-AutomationVariable -Name 'OMSWorkspaceKey'
    $CertificationName = Get-AutomationVariable -Name 'CertificationName'
    $Certificate = Get-AutomationCertificate -Name $CertificationName
    $CertThumbprint = ($Certificate.Thumbprint).ToString()    

    $null = Login-AzureRmAccount -ServicePrincipal -TenantId $Tenant -CertificateThumbprint $CertThumbprint -ApplicationId $SPAppID   

    $resourceObj = Get-AzureRmResource -ResourceId $AlertContext.resourceId
    $VM = Get-AzureRmVM -Name $resourceObj.Name -ResourceGroupName $resourceObj.ResourceGroupName

    $Settings = @{&quot;workspaceId&quot; = &quot;$OMSWorkspaceId&quot;}
    $ProtectedSettings = @{&quot;workspaceKey&quot; = &quot;$OMSWorkspaceKey&quot;}

    if ($VM.StorageProfile.OsDisk.OsType -eq &quot;Linux&quot;) {  
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &quot;OmsAgentForLinux&quot; -Publisher &quot;Microsoft.EnterpriseCloud.Monitoring&quot; -ExtensionType &quot;OmsAgentForLinux&quot; -TypeHandlerVersion &quot;1.0&quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    elseif ($VM.StorageProfile.OsDisk.OsType -eq &quot;Windows&quot;)
    {
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &quot;MicrosoftMonitoringAgent&quot; -Publisher &quot;Microsoft.EnterpriseCloud.Monitoring&quot; -ExtensionType &quot;MicrosoftMonitoringAgent&quot; -TypeHandlerVersion &quot;1.0&quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    else
    {
        Write-Error &quot;Unknown OS Type.&quot;
    }
}
else 
{
    Write-Error &quot;This runbook is meant to only be started from a webhook.&quot; 
}
</code></pre>

<p>Runbookができたら、Webhookを作ります。詳しくは<a href="https://azure.microsoft.com/ja-jp/documentation/articles/automation-webhooks/">こちら</a>。</p>

<p>WebhookのURLを控えておいてください。</p>

<h2 id="azure-監査ログアラート側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452">Azure 監査ログアラート側の仕掛け</h2>

<p>Powershellでアラートルールを作ります。実行アカウントの権限に気をつけてください。</p>

<pre><code>PS C:\work&gt; $actionEmail = New-AzureRmAlertRuleEmail -CustomEmail yourname@example.com

PS C:\work&gt; $actionWebhook = New-AzureRmAlertRuleWebhook -ServiceUri https://abcdefgh.azure-automation.net/webhooks?token=your_token

PS C:\work&gt; Add-AzureRmLogAlertRule -Name createdVM -Location &quot;Japan West&quot; -ResourceGroup dev -OperationName Microsoft.Compute/virtualMachines/write -Status Succeeded  -SubStatus Created -TargetResourceGroup dev -Actions $actionEmail,$actionWebhook
</code></pre>

<p>以上。これで&rdquo;dev&rdquo;リソースグループにVMが作られた場合、自動でOMSエージェントがインストールされ、ログ収集がはじまります。</p>

<p>なお、メールも飛んできますので、うっとおしくなったらメール通知はアクションから外すか、ルールでさばいてくださいね。</p>

                    </div>
                </section>
                
            </div>
            
<div class="pagination">
  <nav role="pagination" class="post-list-pagination">
      
      <a href="/categories/azure/" class="post-list-pagination-item pure-button post-list-pagination-item-prev">
        <i class="fa fa-angle-double-left"></i>&nbsp;Newer
      </a>
      
    <span class="post-list-pagination-item post-list-pagination-item-current">Page 2 of 5</span>
    
      <a href="/categories/azure/page/3/" class="post-list-pagination-item pure-button post-list-pagination-item-next">
        Older&nbsp;<i class="fa fa-angle-double-right"></i>
      </a>
    
  </nav>
</div>


            <div class="footer">
    <div class="pure-menu pure-menu-horizontal pure-menu-open">
        <ul>
            <li>Powered by <a class="hugo" href="http://hugo.spf13.com/" target="_blank">hugo</a></li>
        </ul>
    </div>
</div>
<script src="http://torumakabe.github.io//js/all.min.js"></script>
        </div>
    </div>
</div>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');

</script>

</body>
</html>
