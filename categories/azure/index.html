<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure &middot; re-imagine</title>

    <meta name="description" content="my life is the sum of my imagination">

    <meta name="generator" content="Hugo 0.17" />
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="tmak_tw" />
    <meta name="twitter:title" content="Azure &middot; re-imagine">
    <meta name="twitter:description" content="my life is the sum of my imagination">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Azure &middot; re-imagine">
    <meta property="og:description" content="my life is the sum of my imagination">

    <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Oxygen:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-old-ie-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css">
    <!--<![endif]-->

    <link rel="stylesheet" href="http://torumakabe.github.io//css/all.min.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

    <link rel="alternate" type="application/rss+xml" title="re-imagine" href="http://torumakabe.github.io//index.xml" />
</head>
<body>


<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
    <div class="header">
        <hgroup>
            <h1 class="brand-title"><a href="http://torumakabe.github.io/">re-imagine</a></h1>
            <h2 class="brand-tagline"> my life is the sum of my imagination </h2>
        </hgroup>

        <nav class="nav">
            <ul class="nav-list">
                
                <li class="nav-item">
                    <a class="pure-button" href="https://twitter.com/tmak_tw"><i class="fa fa-twitter"></i> Twitter</a>
                </li>
                
                
                <li class="nav-item">
                    <a class="pure-button" href="https://github.com/ToruMakabe "><i class="fa fa-github-alt"></i> github</a>
                </li>
                
                <li class="nav-item">
                    <a class="pure-button" href="http://torumakabe.github.io//index.xml"><i class="fa fa-rss"></i> rss</a>
                </li>
            </ul>
        </nav>
    </div>
</div>


    <div class="content pure-u-1 pure-u-md-3-4">
        <div>
            
            <div class="posts">
                
                <h1 class="content-subhead">30 Mar 2018, 16:30</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_msi_terraform/" class="post-title">Azure MarketplaceからMSI対応でセキュアなTerraform環境を整える</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="terraformのプロビジョニングがmarketplaceから可能に">TerraformのプロビジョニングがMarketplaceから可能に</h2>

<p>Terraform使ってますか。Azureのリソースプロビジョニングの基本はAzure Resource Manager Template Deployである、がわたしの持論ですが、Terraformを使う/併用する方がいいな、というケースは結構あります。使い分けは<a href="https://www.slideshare.net/ToruMakabe/azure-infrastructure-as-code">この資料</a>も参考に。</p>

<p>さて、先日Azure Marketplaceから<a href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps/azure-oss.terraform">Terraform入りの仮想マシン</a>をプロビジョニングできるようになりました。Ubuntuに以下のアプリが導入、構成されます。</p>

<ul>
<li>Terraform (latest)</li>
<li>Azure CLI 2.0</li>
<li>Managed Service Identity (MSI) VM Extension</li>
<li>Unzip</li>
<li>JQ</li>
<li>apt-transport-https</li>
</ul>

<p>いろいろセットアップしてくれるのでしみじみ便利なのですが、ポイントはManaged Service Identity (MSI)です。</p>

<h2 id="シークレットをコードにベタ書きする問題">シークレットをコードにベタ書きする問題</h2>

<p>MSIの何がうれしいいのでしょう。分かりやすい例を挙げると「GitHubにシークレットを書いたコードをpushする、お漏らし事案」を避ける仕組みです。もちそんそれだけではありませんが。</p>

<p><a href="https://docs.microsoft.com/ja-jp/azure/active-directory/managed-service-identity/overview">Azure リソースの管理対象サービス ID (MSI)</a></p>

<p>詳細の説明は公式ドキュメントに譲りますが、ざっくり説明すると</p>

<p><strong>アプリに認証・認可用のシークレットを書かなくても、アプリの動く仮想マシン上にあるローカルエンドポイントにアクセスすると、Azureのサービスを使うためのトークンが得られるよ</strong></p>

<p>です。</p>

<p>GitHub上に疑わしいシークレットがないかスキャンする<a href="https://azure.microsoft.com/ja-jp/blog/managing-azure-secrets-on-github-repositories/">取り組み</a>もはじまっているのですが、できればお世話になりなくない。MSIを活用しましょう。</p>

<h2 id="terraformはmsiに対応している">TerraformはMSIに対応している</h2>

<p>TerraformでAzureのリソースをプロビジョニングするには、もちろん認証・認可が必要です。従来はサービスプリンシパルを作成し、そのIDやシークレットをTerraformの実行環境に配布していました。でも、できれば配布したくないですよね。実行環境を特定の仮想マシンに限定し、MSIを使えば、解決できます。</p>

<p>ところでMSIを使うには、ローカルエンドポイントにトークンを取りに行くよう、アプリを作らなければいけません。</p>

<p><a href="https://www.terraform.io/docs/providers/azurerm/authenticating_via_msi.html">Authenticating to Azure Resource Manager using Managed Service Identity</a></p>

<p>Terraformは対応済みです。環境変数 ARM_USE_MSI をtrueにしてTerraformを実行すればOK。</p>

<h2 id="試してみよう">試してみよう</h2>

<p>実は、すでに使い方を解説した公式ドキュメントがあります。</p>

<p><a href="https://docs.microsoft.com/ja-jp/azure/terraform/terraform-vm-msi">Azure Marketplace イメージを使用して管理対象サービス ID を使用する Terraform Linux 仮想マシンを作成する</a></p>

<p>手順は十分なのですが、理解を深めるための補足情報が、もうちょっと欲しいところです。なので補ってみましょう。</p>

<h3 id="marketplaceからterraform入り仮想マシンを作る">MarketplaceからTerraform入り仮想マシンを作る</h3>

<p>まず、Marketplaceからのデプロイでどんな仮想マシンが作られたのか、気になります。デプロイに利用されたテンプレートをのぞいてみましょう。注目は以下3つのリソースです。抜き出します。</p>

<ul>
<li>MSI VM拡張の導入</li>
<li>VMに対してリソースグループスコープでContributorロールを割り当て</li>
<li>スクリプト実行 VM拡張でTerraform関連のプロビジョニング</li>
</ul>

<pre><code>[snip]
        {
            &quot;type&quot;: &quot;Microsoft.Compute/virtualMachines/extensions&quot;,
            &quot;name&quot;: &quot;[concat(parameters('vmName'),'/MSILinuxExtension')]&quot;,
            &quot;apiVersion&quot;: &quot;2017-12-01&quot;,
            &quot;location&quot;: &quot;[parameters('location')]&quot;,
            &quot;properties&quot;: {
                &quot;publisher&quot;: &quot;Microsoft.ManagedIdentity&quot;,
                &quot;type&quot;: &quot;ManagedIdentityExtensionForLinux&quot;,
                &quot;typeHandlerVersion&quot;: &quot;1.0&quot;,
                &quot;autoUpgradeMinorVersion&quot;: true,
                &quot;settings&quot;: {
                    &quot;port&quot;: 50342
                },
                &quot;protectedSettings&quot;: {}
            },
            &quot;dependsOn&quot;: [
                &quot;[concat('Microsoft.Compute/virtualMachines/', parameters('vmName'))]&quot;
            ]
        },
        {
            &quot;type&quot;: &quot;Microsoft.Authorization/roleAssignments&quot;,
            &quot;name&quot;: &quot;[variables('resourceGuid')]&quot;,
            &quot;apiVersion&quot;: &quot;2017-09-01&quot;,
            &quot;properties&quot;: {
                &quot;roleDefinitionId&quot;: &quot;[variables('contributor')]&quot;,
                &quot;principalId&quot;: &quot;[reference(concat(resourceId('Microsoft.Compute/virtualMachines/', parameters('vmName')),'/providers/Microsoft.ManagedIdentity/Identities/default'),'2015-08-31-PREVIEW').principalId]&quot;,
                &quot;scope&quot;: &quot;[concat('/subscriptions/', subscription().subscriptionId, '/resourceGroups/', resourceGroup().name)]&quot;
            },
            &quot;dependsOn&quot;: [
                &quot;[resourceId('Microsoft.Compute/virtualMachines/extensions/', parameters('vmName'),'MSILinuxExtension')]&quot;
            ]
        },
        {
            &quot;type&quot;: &quot;Microsoft.Compute/virtualMachines/extensions&quot;,
            &quot;name&quot;: &quot;[concat(parameters('vmName'),'/customscriptextension')]&quot;,
            &quot;apiVersion&quot;: &quot;2017-03-30&quot;,
            &quot;location&quot;: &quot;[parameters('location')]&quot;,
            &quot;properties&quot;: {
                &quot;publisher&quot;: &quot;Microsoft.Azure.Extensions&quot;,
                &quot;type&quot;: &quot;CustomScript&quot;,
                &quot;typeHandlerVersion&quot;: &quot;2.0&quot;,
                &quot;autoUpgradeMinorVersion&quot;: true,
                &quot;settings&quot;: {
                    &quot;fileUris&quot;: [
                        &quot;[concat(parameters('artifactsLocation'), '/scripts/infra.sh', parameters('artifactsLocationSasToken'))]&quot;,
                        &quot;[concat(parameters('artifactsLocation'), '/scripts/install.sh', parameters('artifactsLocationSasToken'))]&quot;,
                        &quot;[concat(parameters('artifactsLocation'), '/scripts/azureProviderAndCreds.tf', parameters('artifactsLocationSasToken'))]&quot;
                    ]
                },
                &quot;protectedSettings&quot;: {
                    &quot;commandToExecute&quot;: &quot;[concat('bash infra.sh &amp;&amp; bash install.sh ', variables('installParm1'), variables('installParm2'), variables('installParm3'), variables('installParm4'), ' -k ', listKeys(resourceId('Microsoft.Storage/storageAccounts', variables('stateStorageAccountName')), '2017-10-01').keys[0].value, ' -l ', reference(concat(resourceId('Microsoft.Compute/virtualMachines/', parameters('vmName')),'/providers/Microsoft.ManagedIdentity/Identities/default'),'2015-08-31-PREVIEW').principalId)]&quot;
                }
            },
            &quot;dependsOn&quot;: [
                &quot;[resourceId('Microsoft.Authorization/roleAssignments', variables('resourceGuid'))]&quot;
            ]
        }
[snip]
</code></pre>

<h3 id="vmにログインし-環境を確認">VMにログインし、環境を確認</h3>

<p>では出来上がったVMにsshし、いろいろのぞいてみましょう。</p>

<pre><code>$ ssh your-vm-public-ip
</code></pre>

<p>Terraformのバージョンは、現時点で最新の0.11.5が入っています。</p>

<pre><code>$ terraform -v
Terraform v0.11.5
</code></pre>

<p>環境変数ARM_USE_MSIはtrueに設定されています。</p>

<pre><code>$ echo $ARM_USE_MSI
true
</code></pre>

<p>MSIも有効化されています(SystemAssigned)。</p>

<pre><code>$ az vm identity show -g tf-msi-poc-ejp-rg -n tfmsipocvm01
{
  &quot;additionalProperties&quot;: {},
  &quot;identityIds&quot;: null,
  &quot;principalId&quot;: &quot;aaaa-aaaa-aaaa-aaaa-aaaa&quot;,
  &quot;tenantId&quot;: &quot;tttt-tttt-tttt-tttt&quot;,
  &quot;type&quot;: &quot;SystemAssigned&quot;
}
</code></pre>

<p>さて、このVMはMSIが使えるようになったわけですが、操作できるリソースのスコープは、このVMが属するリソースグループに限定されてます。新たなリソースグループを作成したい場合は、ロールを付与し、スコープを広げます。~/にtfEnv.shというスクリプトが用意されています。用意されたスクリプトを実行すると、サブスクリプションスコープのContributorがVMに割り当てられます。必要に応じて変更しましょう。</p>

<pre><code>$ ls
tfEnv.sh  tfTemplate

$ cat tfEnv.sh
az login
az role assignment create  --assignee &quot;aaaa-aaaa-aaaa-aaaa-aaaa&quot; --role 'b24988ac-6180-42a0-ab88-20f7382dd24c'  --scope /subscriptions/&quot;cccc-cccc-cccc-cccc&quot;

$ . ~/tfEnv.sh
To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code HOGEHOGE to authenticate.
[snip]
{
  &quot;additionalProperties&quot;: {},
  &quot;canDelegate&quot;: null,
  &quot;id&quot;: &quot;/subscriptions/cccc-cccc-cccc-cccc/providers/Microsoft.Authorization/roleAssignments/ffff-ffff-ffff-ffff&quot;,
  &quot;name&quot;: &quot;ffff-ffff-ffff-ffff&quot;,
  &quot;principalId&quot;: &quot;aaaa-aaaa-aaaa-aaaa-aaaa&quot;,
  &quot;roleDefinitionId&quot;: &quot;/subscriptions/cccc-cccc-cccc-cccc/providers/Microsoft.Authorization/roleDefinitions/b24988ac-6180-42a0-ab88-20f7382dd24c&quot;,
  &quot;scope&quot;: &quot;/subscriptions/cccc-cccc-cccc-cccc&quot;,
  &quot;type&quot;: &quot;Microsoft.Authorization/roleAssignments&quot;
}
</code></pre>

<p>ちなみに、role id &ldquo;b24988ac-6180-42a0-ab88-20f7382dd24c&rdquo;はContributorを指します。</p>

<p>tfTemplateというディレクトリも用意されているようです。2つのファイルがあります。</p>

<pre><code>$ ls tfTemplate/
azureProviderAndCreds.tf  remoteState.tf
</code></pre>

<p>azureProviderAndCreds.tfは、tfファイルのテンプレートです。コメントアウトと説明のとおり、MSIを使う場合には、このテンプレートは必要ありません。subscription_idとtenant_idは、VMのプロビジョニング時に環境変数にセットされています。そしてclient_idとclient_secretは、MSIを通じて取得されます。明示的に変えたい時のみ指定しましょう。</p>

<pre><code>$ cat tfTemplate/azureProviderAndCreds.tf
#
#
# Provider and credential snippet to add to configurations
# Assumes that there's a terraform.tfvars file with the var values
#
# Uncomment the creds variables if using service principal auth
# Leave them commented to use MSI auth
#
#variable subscription_id {}
#variable tenant_id {}
#variable client_id {}
#variable client_secret {}

provider &quot;azurerm&quot; {
#    subscription_id = &quot;${var.subscription_id}&quot;
#    tenant_id = &quot;${var.tenant_id}&quot;
#    client_id = &quot;${var.client_id}&quot;
#    client_secret = &quot;${var.client_secret}&quot;
}
</code></pre>

<p>remoteState.tfは、TerraformのstateをAzureのBlob上に置く場合に使います。Blobの<a href="https://azure.microsoft.com/en-us/blog/soft-delete-for-azure-storage-blobs-now-in-public-preview/">soft delete</a>が使えるようになったこともあり、事件や事故を考慮すると、できればstateはローカルではなくBlobで管理したいところです。</p>

<pre><code>$ cat tfTemplate/remoteState.tf
terraform {
 backend &quot;azurerm&quot; {
  storage_account_name = &quot;storestaterandomid&quot;
  container_name       = &quot;terraform-state&quot;
  key                  = &quot;prod.terraform.tfstate&quot;
  access_key           = &quot;KYkCz88z+7yoyoyoiyoyoyoiyoyoyoiyoiTDZRbrwAWIPWD+rU6g==&quot;
  }
}
</code></pre>

<p>soft delete設定は、別途 <a href="https://docs.microsoft.com/en-us/cli/azure/storage/blob/service-properties/delete-policy?view=azure-cli-latest#az-storage-blob-service-properties-delete-policy-update">az storage blob service-properties delete-policy update</a> コマンドで行ってください。</p>

<h3 id="プロビジョニングしてみる">プロビジョニングしてみる</h3>

<p>ではTerraformを動かしてみましょう。サブディレクトリsampleを作り、そこで作業します。</p>

<pre><code>$ mkdir sample
$ cd sample/
</code></pre>

<p>stateはBlobで管理しましょう。先ほどのremoteState.tfを実行ディレクトリにコピーします。アクセスキーが入っていますので、このディレクトリをコード管理システム配下に置くのであれば、.gitignoreなどで除外をお忘れなく。</p>

<pre><code>$ cp ../tfTemplate/remoteState.tf ./
</code></pre>

<p>ここのキーが残ってしまうのが現時点での課題。ストレージのキー問題は<a href="https://feedback.azure.com/forums/217298-storage/suggestions/14831712-allow-user-based-access-to-blob-containers-for-su">対応がはじまったので</a>、いずれ解決するはずです。</p>

<p>ではTerraformで作るリソースを書きます。さくっとACI上にnginxコンテナーを作りましょう。</p>

<pre><code>$ vim main.tf
resource &quot;azurerm_resource_group&quot; &quot;tf-msi-poc&quot; {
    name     = &quot;tf-msi-poc-aci-wus-rg&quot;
    location = &quot;West US&quot;
}

resource &quot;random_integer&quot; &quot;random_int&quot; {
    min = 100
    max = 999
}

resource &quot;azurerm_container_group&quot; &quot;aci-example&quot; {
    name                = &quot;aci-cg-${random_integer.random_int.result}&quot;
    location            = &quot;${azurerm_resource_group.tf-msi-poc.location}&quot;
    resource_group_name = &quot;${azurerm_resource_group.tf-msi-poc.name}&quot;
    ip_address_type     = &quot;public&quot;
    dns_name_label      = &quot;tomakabe-aci-cg-${random_integer.random_int.result}&quot;
    os_type             = &quot;linux&quot;

    container {
        name    = &quot;nginx&quot;
        image   = &quot;nginx&quot;
        cpu     = &quot;0.5&quot;
        memory  = &quot;1.0&quot;
        port    = &quot;80&quot;
    }
}
</code></pre>

<p>init、plan、アプラーイ。アプライ王子。</p>

<pre><code>$ terraform init
$ terraform plan
$ terraform apply -auto-approve
[snip]
Apply complete! Resources: 3 added, 0 changed, 0 destroyed.
</code></pre>

<p>できたか確認。</p>

<pre><code>$ az container show -g tf-msi-poc-aci-wus-rg -n aci-cg-736 -o table
Name        ResourceGroup          ProvisioningState    Image    IP:ports         CPU/Memory       OsType    Location
----------  ---------------------  -------------------  -------  ---------------  ---------------  --------  ----------
aci-cg-736  tf-msi-poc-aci-wus-rg  Succeeded            nginx    13.91.90.117:80  0.5 core/1.0 gb  Linux     westus
$ curl 13.91.90.117
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
[snip]
</code></pre>

<h2 id="おまけ">おまけ</h2>

<p>サービスプリンシパルは、アプリに対して権限を付与するために必要な仕組みなのですが、使わなくなった際に消し忘れることが多いです。意識して消さないと、散らかり放題。</p>

<p>MSIの場合、対象のVMを消すとそのプリンシパルも消えます。爽快感ほとばしる。</p>

<pre><code>$ az ad sp show --id aaaa-aaaa-aaaa-aaaa-aaaa
Resource 'aaaa-aaaa-aaaa-aaaa-aaaa' does not exist or one of its queried reference-property objects are not present.
</code></pre>

                    </div>
                </section>
                
                <h1 class="content-subhead">27 Mar 2018, 00:10</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_private_dns_preview/" class="post-title">Azure DNS Private Zonesの動きを確認する</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="プライベートゾーンのパブリックプレビュー開始">プライベートゾーンのパブリックプレビュー開始</h2>

<p>Azure DNSのプライベートゾーン対応が、全リージョンでパブリックプレビューとなりました。ゾーンとプレビューのプライベートとパブリックが入り混じって、なにやら紛らわしいですが。</p>

<p>さて、このプライベートゾーン対応ですが、名前のとおりAzure DNSをプライベートな仮想ネットワーク(VNet)で使えるようになります。加えて、しみじみと嬉しい便利機能がついています。</p>

<ul>
<li>Split-Horizonに対応します。VNet内からの問い合わせにはプライベートゾーン、それ以外からはパブリックゾーンのレコードを返します。</li>
<li>仮想マシンの作成時、プライベートゾーンへ自動でホスト名を追加します。</li>
<li>プライベートゾーンとVNetをリンクして利用します。複数のVNetをリンクすることが可能です。</li>
<li>リンクの種類として、仮想マシンホスト名の自動登録が行われるVNetをRegistration VNet、名前解決(正引き)のみ可能なResolution VNetがあります。</li>
<li>プライベートゾーンあたり、Registration VNetの現時点の上限数は1、Resolution VNetは10です。</li>
</ul>

<p>公式ドキュメントは<a href="https://docs.microsoft.com/en-us/azure/dns/private-dns-overview">こちら</a>。現時点の<a href="https://docs.microsoft.com/en-us/azure/dns/private-dns-overview#limitations">制約もまとまっている</a>ので、目を通しておきましょう。</p>

<h2 id="動きを見てみよう">動きを見てみよう</h2>

<p>公式ドキュメントには<a href="https://docs.microsoft.com/en-us/azure/dns/private-dns-scenarios">想定シナリオ</a>があり、これを読めばできることがだいたい分かります。ですが、名前解決は呼吸のようなもの、体に叩き込みたいお気持ちです。手を動かして確認します。</p>

<h3 id="事前に準備する環境">事前に準備する環境</h3>

<p>下記リソースを先に作っておきます。手順は割愛。ドメイン名はexample.comとしましたが、適宜読み替えてください。</p>

<ul>
<li>VNet *2

<ul>
<li>vnet01</li>
<li>subnet01

<ul>
<li>subnet01-nsg (allow ssh)</li>
</ul></li>
<li>vnet02</li>
<li>subnet01

<ul>
<li>subnet01-nsg (allow ssh)</li>
</ul></li>
</ul></li>
<li>Azure DNS Public Zone

<ul>
<li>example.com</li>
</ul></li>
</ul>

<h3 id="azure-cliへdns拡張を導入">Azure CLIへDNS拡張を導入</h3>

<p>プレビュー機能をCLIに導入します。いずれ要らなくなるかもしれませんので、要否は<a href="https://docs.microsoft.com/en-us/azure/dns/private-dns-getstarted-cli#to-installuse-azure-dns-private-zones-feature-public-preview">公式ドキュメント</a>で確認してください。</p>

<pre><code>$ az extension add --name dns
</code></pre>

<h3 id="プライベートゾーンの作成">プライベートゾーンの作成</h3>

<p>既存のゾーンを確認します。パブリックゾーンがあります。</p>

<pre><code>$ az network dns zone list -o table
ZoneName      ResourceGroup             RecordSets    MaxRecordSets
------------  ----------------------  ------------  ---------------
example.com   common-global-rg                   2             5000
</code></pre>

<p>プライベートゾーンを作成します。Registration VNetとしてvnet01をリンクします。<a href="https://docs.microsoft.com/en-us/azure/dns/private-dns-overview#limitations">現時点の制約</a>で、リンク時にはVNet上にVMが無い状態にする必要があります。</p>

<pre><code>$ az network dns zone create -g private-dns-poc-ejp-rg -n example.com --zone-type Private --registration-vnets vnet01
</code></pre>

<p>同じ名前のゾーンが2つになりました。</p>

<pre><code>$ az network dns zone list -o table
ZoneName      ResourceGroup             RecordSets    MaxRecordSets
------------  ----------------------  ------------  ---------------
example.com   common-global-rg                   2             5000
example.com   private-dns-poc-ejp-rg             1             5000
</code></pre>

<h3 id="registration-vnetへvmを作成">Registration VNetへVMを作成</h3>

<p>VMを2つ作ります。1つにはインターネット経由でsshするので、パブリックIPを割り当てます。</p>

<pre><code>$ BASE_NAME=&quot;private-dns-poc-ejp&quot;
$ az network public-ip create -n vm01-pip -g ${BASE_NAME}-rg
$ az network nic create -g ${BASE_NAME}-rg -n vm01-nic --public-ip-address vm01-pip --vnet vnet01 --subnet subnet01
$ az vm create -g ${BASE_NAME}-rg -n vm01 --image Canonical:UbuntuServer:16.04.0-LTS:latest --size Standard_B1s --nics vm01-nic
$ az network nic create -g ${BASE_NAME}-rg -n vm02-nic --vnet vnet01 --subnet subnet01
$ az vm create -g ${BASE_NAME}-rg -n vm02 --image Canonical:UbuntuServer:16.04.0-LTS:latest --size Standard_B1s --nics vm02-nic
</code></pre>

<h3 id="パブリックipをパブリックゾーンへ登録">パブリックIPをパブリックゾーンへ登録</h3>

<p>Split-Horizonの動きを確認したいので、パブリックIPをパブリックゾーンへ登録します。</p>

<pre><code>$ az network public-ip show -g private-dns-poc-ejp-rg -n vm01-pip --query ipAddress
&quot;13.78.84.84&quot;
$ az network dns record-set a add-record -g common-global-rg -z example.com -n vm01 -a 13.78.84.84
</code></pre>

<p>パブリックゾーンで名前解決できることを確認します。</p>

<pre><code>$ nslookup vm01.example.com
Server:         103.5.140.1
Address:        103.5.140.1#53

Non-authoritative answer:
Name:   vm01.example.com
Address: 13.78.84.84
</code></pre>

<h3 id="registration-vnetの動きを確認">Registration VNetの動きを確認</h3>

<p>vnet01のvm01へ、パブリックIP経由でsshします。</p>

<pre><code>$ ssh vm01.example.com
</code></pre>

<p>同じRegistration VNet上のvm02を正引きします。ドメイン名無し、ホスト名だけでnslookupすると、VNetの内部ドメイン名がSuffixになります。</p>

<pre><code>vm01:~$ nslookup vm02
Server:         168.63.129.16
Address:        168.63.129.16#53

Non-authoritative answer:
Name:   vm02.aioh0amlfdze5drhlpb1ktqwxd.lx.internal.cloudapp.net
Address: 10.0.0.5
</code></pre>

<p>ドメイン名をつけてみましょう。Nameはvnet01にリンクしたプライベートゾーンのドメイン名になりました。</p>

<pre><code>vm01:~$ nslookup vm02.example.com
Server:         168.63.129.16
Address:        168.63.129.16#53

Non-authoritative answer:
Name:   vm02.example.com
Address: 10.0.0.5
</code></pre>

<p>逆引きもできます。</p>

<pre><code>vm01:~$ nslookup 10.0.0.5
Server:         168.63.129.16
Address:        168.63.129.16#53

Non-authoritative answer:
5.0.0.10.in-addr.arpa   name = vm02.example.com.

Authoritative answers can be found from:
</code></pre>

<h3 id="split-horizonの動きを確認">Split-Horizonの動きを確認</h3>

<p>さて、いま作業をしているvm01には、インターネット経由でパブリックゾーンで名前解決してsshしたわけですが、プライベートなVNet内でnslookupするとどうなるでしょう。</p>

<pre><code>vm01:~$ nslookup vm01.example.com
Server:         168.63.129.16
Address:        168.63.129.16#53

Non-authoritative answer:
Name:   vm01.example.com
Address: 10.0.0.4
</code></pre>

<p>プライベートゾーンで解決されました。Split-Horizonが機能していることが分かります。</p>

<p>あ、どうでもいいことですが、Split-Horizonって戦隊モノの必殺技みたいなネーミングですね。叫びながら地面に拳を叩きつけたい感じ。</p>

<h3 id="resolution-vnetの動きを確認">Resolution VNetの動きを確認</h3>

<p>vnet02を作成し、Resolution VNetとしてプライベートゾーンとリンクします。そして、vnet02にvm03を作ります。vm03へのsshまで一気に進めます。</p>

<pre><code>$ BASE_NAME=&quot;private-dns-poc-ejp&quot;
$ az network vnet create -g ${BASE_NAME}-rg -n vnet02 --address-prefix 10.1.0.0/16 --subnet-name subnet01
$ az network vnet subnet update -g ${BASE_NAME}-rg -n subnet01 --vnet-name vnet02 --network-security-group subnet01-nsg
$ az network public-ip create -n vm03-pip -g ${BASE_NAME}-rg
$ az network dns zone update -g private-dns-poc-ejp-rg -n example.com --resolution-vnets vnet02
$ az network nic create -g ${BASE_NAME}-rg -n vm03-nic --public-ip-address vm03-pip --vnet vnet02 --subnet subnet01
$ az vm create -g ${BASE_NAME}-rg -n vm03 --image Canonical:UbuntuServer:16.04.0-LTS:latest --size Standard_B1s --nics vm03-nic
$ az network public-ip show -g private-dns-poc-ejp-rg -n vm03-pip --query ipAddress
&quot;13.78.54.133&quot;
$ ssh 13.78.54.133
</code></pre>

<p>名前解決の確認が目的なので、vnet01/02間はPeeringしません。</p>

<p>では、vnet01上のvm01を正引きします。ドメイン名を指定しないと、解決できません。vnet02上にvm01がある、と指定されたと判断するからです。</p>

<pre><code>vm03:~$ nslookup vm01
Server:         168.63.129.16
Address:        168.63.129.16#53

** server can't find vm01: SERVFAIL
</code></pre>

<p>ではプライベートゾーンのドメイン名をつけてみます。解決できました。</p>

<pre><code>vm03:~$ nslookup vm01.example.com
Server:         168.63.129.16
Address:        168.63.129.16#53

Non-authoritative answer:
Name:   vm01.example.com
Address: 10.0.0.4
</code></pre>

<p>Resolution VNetからは、逆引きできません。</p>

<pre><code>vm03:~$ nslookup 10.0.0.4
Server:         168.63.129.16
Address:        168.63.129.16#53

** server can't find 4.0.0.10.in-addr.arpa: NXDOMAIN
</code></pre>

<p>ところでRegistration VNetからResolution VNetのホスト名をnslookupするとどうなるでしょう。</p>

<pre><code>$ ssh vm01.example.com
vm01:~$ nslookup vm03
Server:         168.63.129.16
Address:        168.63.129.16#53

** server can't find vm03: SERVFAIL

vm01:~$ nslookup vm03.example.com
Server:         168.63.129.16
Address:        168.63.129.16#53

** server can't find vm03.example.com: NXDOMAIN
</code></pre>

<p>ドメイン名あり、なしに関わらず、名前解決できません。VNetが別なのでVNetの内部DNSで解決できない、また、Resolution VNetのVMはレコードがプライベートゾーンに自動登録されないことが分かります。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">26 Mar 2018, 00:08</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/az_vmss_terraform/" class="post-title">AzureのAvailability Zonesへ分散するVMSSをTerraformで作る</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="動機">動機</h2>

<p>Terraform Azure Provider 1.3.0で、VMSSを作る際にAvailability Zonesを指定できるように<a href="https://github.com/terraform-providers/terraform-provider-azurerm/pull/811">なりました</a>。Availability Zonesはインフラの根っこの仕組みなので、現在(<sup>2018</sup>&frasl;<sub>3</sub>)限定されたリージョンで長めのプレビュー期間がとられています。ですが、GAやグローバル展開を見据え、素振りしておきましょう。</p>

<h2 id="前提条件">前提条件</h2>

<ul>
<li>Availability Zones対応リージョンを選びます。現在は<a href="https://docs.microsoft.com/en-us/azure/availability-zones/az-overview#regions-that-support-availability-zones">5リージョン</a>です。この記事ではEast US 2とします。</li>
<li>Availability Zonesのプレビューに<a href="https://docs.microsoft.com/ja-jp/azure/availability-zones/az-overview">サインアップ</a>済みとします。</li>
<li>bashでsshの公開鍵が~/.ssh/id_rsa.pubにあると想定します。</li>
<li>動作確認した環境は以下です。

<ul>
<li>Terraform 0.11.2</li>
<li>Terraform Azure Provider 1.3.0</li>
<li>WSL (ubuntu 16.04)</li>
<li>macos (High Sierra 10.13.3)</li>
</ul></li>
</ul>

<h2 id="コード">コード</h2>

<p>以下のファイルを同じディレクトリに作成します。</p>

<h3 id="terraform-メインコード">Terraform メインコード</h3>

<p>VMSSと周辺リソースを作ります。</p>

<ul>
<li>最終行近くの &ldquo;zones = [1, 2, 3]&rdquo; がポイントです。これだけで、インスタンスを散らす先のゾーンを指定できます。</li>
<li>クロスゾーン負荷分散、冗長化するため、Load BalancerとパブリックIPのSKUをStandardにします。</li>
</ul>

<p>[main.tf]</p>

<pre><code>resource &quot;azurerm_resource_group&quot; &quot;poc&quot; {
  name     = &quot;${var.resource_group_name}&quot;
  location = &quot;East US 2&quot;
}

resource &quot;azurerm_virtual_network&quot; &quot;poc&quot; {
  name                = &quot;vnet01&quot;
  resource_group_name = &quot;${azurerm_resource_group.poc.name}&quot;
  location            = &quot;${azurerm_resource_group.poc.location}&quot;
  address_space       = [&quot;10.0.0.0/16&quot;]
}

resource &quot;azurerm_subnet&quot; &quot;poc&quot; {
  name                      = &quot;subnet01&quot;
  resource_group_name       = &quot;${azurerm_resource_group.poc.name}&quot;
  virtual_network_name      = &quot;${azurerm_virtual_network.poc.name}&quot;
  address_prefix            = &quot;10.0.2.0/24&quot;
  network_security_group_id = &quot;${azurerm_network_security_group.poc.id}&quot;
}

resource &quot;azurerm_network_security_group&quot; &quot;poc&quot; {
  name                = &quot;nsg01&quot;
  resource_group_name = &quot;${azurerm_resource_group.poc.name}&quot;
  location            = &quot;${azurerm_resource_group.poc.location}&quot;

  security_rule = [
    {
      name                       = &quot;allow_http&quot;
      priority                   = 100
      direction                  = &quot;Inbound&quot;
      access                     = &quot;Allow&quot;
      protocol                   = &quot;Tcp&quot;
      source_port_range          = &quot;*&quot;
      destination_port_range     = &quot;80&quot;
      source_address_prefix      = &quot;*&quot;
      destination_address_prefix = &quot;*&quot;
    },
    {
      name                       = &quot;allow_ssh&quot;
      priority                   = 101
      direction                  = &quot;Inbound&quot;
      access                     = &quot;Allow&quot;
      protocol                   = &quot;Tcp&quot;
      source_port_range          = &quot;*&quot;
      destination_port_range     = &quot;22&quot;
      source_address_prefix      = &quot;*&quot;
      destination_address_prefix = &quot;*&quot;
    },
  ]
}

resource &quot;azurerm_public_ip&quot; &quot;poc&quot; {
  name                         = &quot;pip01&quot;
  resource_group_name          = &quot;${azurerm_resource_group.poc.name}&quot;
  location                     = &quot;${azurerm_resource_group.poc.location}&quot;
  public_ip_address_allocation = &quot;static&quot;
  domain_name_label            = &quot;${var.scaleset_name}&quot;

  sku = &quot;Standard&quot;
}

resource &quot;azurerm_lb&quot; &quot;poc&quot; {
  name                = &quot;lb01&quot;
  resource_group_name = &quot;${azurerm_resource_group.poc.name}&quot;
  location            = &quot;${azurerm_resource_group.poc.location}&quot;

  frontend_ip_configuration {
    name                 = &quot;fipConf01&quot;
    public_ip_address_id = &quot;${azurerm_public_ip.poc.id}&quot;
  }

  sku = &quot;Standard&quot;
}

resource &quot;azurerm_lb_backend_address_pool&quot; &quot;poc&quot; {
  name                = &quot;bePool01&quot;
  resource_group_name = &quot;${azurerm_resource_group.poc.name}&quot;
  loadbalancer_id     = &quot;${azurerm_lb.poc.id}&quot;
}

resource &quot;azurerm_lb_rule&quot; &quot;poc&quot; {
  name                           = &quot;lbRule&quot;
  resource_group_name            = &quot;${azurerm_resource_group.poc.name}&quot;
  loadbalancer_id                = &quot;${azurerm_lb.poc.id}&quot;
  protocol                       = &quot;Tcp&quot;
  frontend_port                  = 80
  backend_port                   = 80
  frontend_ip_configuration_name = &quot;fipConf01&quot;
  backend_address_pool_id        = &quot;${azurerm_lb_backend_address_pool.poc.id}&quot;
  probe_id                       = &quot;${azurerm_lb_probe.poc.id}&quot;
}

resource &quot;azurerm_lb_probe&quot; &quot;poc&quot; {
  name                = &quot;http-probe&quot;
  resource_group_name = &quot;${azurerm_resource_group.poc.name}&quot;
  loadbalancer_id     = &quot;${azurerm_lb.poc.id}&quot;
  port                = 80
}

resource &quot;azurerm_lb_nat_pool&quot; &quot;poc&quot; {
  count                          = 3
  name                           = &quot;ssh&quot;
  resource_group_name            = &quot;${azurerm_resource_group.poc.name}&quot;
  loadbalancer_id                = &quot;${azurerm_lb.poc.id}&quot;
  protocol                       = &quot;Tcp&quot;
  frontend_port_start            = 50000
  frontend_port_end              = 50119
  backend_port                   = 22
  frontend_ip_configuration_name = &quot;fipConf01&quot;
}

data &quot;template_cloudinit_config&quot; &quot;poc&quot; {
  gzip          = true
  base64_encode = true

  part {
    content_type = &quot;text/cloud-config&quot;
    content      = &quot;${file(&quot;${path.module}/cloud-config.yaml&quot;)}&quot;
  }
}

resource &quot;azurerm_virtual_machine_scale_set&quot; &quot;poc&quot; {
  name                = &quot;${var.scaleset_name}&quot;
  resource_group_name = &quot;${azurerm_resource_group.poc.name}&quot;
  location            = &quot;${azurerm_resource_group.poc.location}&quot;
  upgrade_policy_mode = &quot;Manual&quot;

  sku {
    name     = &quot;Standard_B1s&quot;
    tier     = &quot;Standard&quot;
    capacity = 3
  }

  storage_profile_image_reference {
    publisher = &quot;Canonical&quot;
    offer     = &quot;UbuntuServer&quot;
    sku       = &quot;16.04-LTS&quot;
    version   = &quot;latest&quot;
  }

  storage_profile_os_disk {
    name              = &quot;&quot;
    caching           = &quot;ReadWrite&quot;
    create_option     = &quot;FromImage&quot;
    managed_disk_type = &quot;Standard_LRS&quot;
  }

  os_profile {
    computer_name_prefix = &quot;pocvmss&quot;
    admin_username       = &quot;${var.admin_username}&quot;
    admin_password       = &quot;&quot;
    custom_data          = &quot;${data.template_cloudinit_config.poc.rendered}&quot;
  }

  os_profile_linux_config {
    disable_password_authentication = true

    ssh_keys {
      path     = &quot;/home/${var.admin_username}/.ssh/authorized_keys&quot;
      key_data = &quot;${file(&quot;~/.ssh/id_rsa.pub&quot;)}&quot;
    }
  }

  network_profile {
    name    = &quot;terraformnetworkprofile&quot;
    primary = true

    ip_configuration {
      name                                   = &quot;PoCIPConfiguration&quot;
      subnet_id                              = &quot;${azurerm_subnet.poc.id}&quot;
      load_balancer_backend_address_pool_ids = [&quot;${azurerm_lb_backend_address_pool.poc.id}&quot;]
      load_balancer_inbound_nat_rules_ids    = [&quot;${element(azurerm_lb_nat_pool.poc.*.id, count.index)}&quot;]
    }
  }

  zones = [1, 2, 3]
}
</code></pre>

<h3 id="cloud-init-configファイル">cloud-init configファイル</h3>

<p>各インスタンスがどのゾーンで動いているか確認したいので、インスタンス作成時にcloud-initでWebサーバーを仕込みます。メタデータからインスタンス名と実行ゾーンを引っ張り、nginxのドキュメントルートに書きます。</p>

<p>[cloud-config.yaml]</p>

<pre><code>#cloud-config
package_upgrade: true
packages:
  - nginx
runcmd:
  - 'echo &quot;[Instance Name]: `curl -H Metadata:true &quot;http://169.254.169.254/metadata/instance/compute/name?api-version=2017-12-01&amp;format=text&quot;`    [Zone]: `curl -H Metadata:true &quot;http://169.254.169.254/metadata/instance/compute/zone?api-version=2017-12-01&amp;format=text&quot;`&quot; &gt; /var/www/html/index.nginx-debian.html'
</code></pre>

<p>インスタンス作成時、パッケージの導入やアップデートに時間をかけたくない場合は、Packerなどで前もってカスタムイメージを作っておくのも手です。</p>

<ul>
<li><a href="https://docs.microsoft.com/ja-jp/azure/virtual-machines/linux/build-image-with-packer">Packer を使用して Azure に Linux 仮想マシンのイメージを作成する方法</a></li>
<li><a href="https://docs.microsoft.com/ja-jp/azure/terraform/terraform-create-vm-scaleset-network-disks-using-packer-hcl">Terraform を使用して Packer カスタム イメージから Azure 仮想マシン スケール セットを作成する</a></li>
</ul>

<h3 id="terraform-変数ファイル">Terraform 変数ファイル</h3>

<p>変数は別ファイルへ。</p>

<p>[variables.tf]</p>

<pre><code>variable &quot;resource_group_name&quot; {
  default = &quot;your-rg&quot;
}

variable &quot;scaleset_name&quot; {
  default = &quot;yourvmss01&quot;
}

variable &quot;admin_username&quot; {
  default = &quot;yourname&quot;
}
</code></pre>

<h2 id="実行">実行</h2>

<p>では実行。</p>

<pre><code>$ terraform init
$ terraform plan
$ terraform apply
</code></pre>

<p>5分くらいで完了しました。このサンプルでは、この後のcloud-initのパッケージ処理に時間がかかります。待てない場合は前述の通り、カスタムイメージを使いましょう。</p>

<p>インスタンスへのsshを通すよう、Load BalancerにNATを設定していますので、cloud-initの進捗は確認できます。</p>

<pre><code>$ ssh -p 50000 yourname@yourvmss01.eastus2.cloudapp.azure.com
$ tail -f /var/log/cloud-init-output.log
Cloud-init v. 17.1 finished at Sun, 25 Mar 2018 10:41:40 +0000. Datasource DataSourceAzure [seed=/dev/sr0].  Up 611.51 seconds
</code></pre>

<p>ではWebサーバーにアクセスしてみましょう。</p>

<pre><code>$ while true; do curl yourvmss01.eastus2.cloudapp.azure.com; sleep 1; done;
[Instance Name]: yourvmss01_2    [Zone]: 3
[Instance Name]: yourvmss01_0    [Zone]: 1
[Instance Name]: yourvmss01_2    [Zone]: 3
[Instance Name]: yourvmss01_1    [Zone]: 2
</code></pre>

<p>VMSSのインスタンスがゾーンに分散されたことが分かります。</p>

<p>では、このままスケールアウトしてみましょう。main.tfのazurerm_virtual_machine_scale_set.poc.sku.capacityを3から4にし、再度applyします。</p>

<pre><code>[Instance Name]: yourvmss01_1    [Zone]: 2
[Instance Name]: yourvmss01_3    [Zone]: 1
[Instance Name]: yourvmss01_3    [Zone]: 1
[Instance Name]: yourvmss01_1    [Zone]: 2
[Instance Name]: yourvmss01_3    [Zone]: 1
</code></pre>

<p>ダウンタイムなしに、yourvmss01_3が追加されました。すこぶる簡単。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">12 Mar 2018, 00:21</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/aks_dns/" class="post-title">AKSのService作成時にホスト名を付ける</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="2つのやり口">2つのやり口</h2>

<p>Azure Container Service(AKS)はServiceを公開する際、パブリックIPを割り当てられます。でもIPだけじゃなく、ホスト名も同時に差し出して欲しいケースがありますよね。</p>

<p>わたしの知る限り、2つの方法があります。</p>

<ul>
<li>AKS(k8s) 1.9で対応した<a href="https://github.com/kubernetes/kubernetes/pull/47849">DNSラベル名付与機能</a>を使う</li>
<li><a href="https://github.com/kubernetes-incubator/external-dns">Kubenetes ExternalDNS</a>を使ってAzure DNSへAレコードを追加する</li>
</ul>

<p>以下、AKS 1.9.2での実現手順です。</p>

<h2 id="dnsラベル名付与機能">DNSラベル名付与機能</h2>

<p>簡単です。Serviceのannotationsに定義するだけ。試しにnginxをServiceとして公開し、確認してみましょう。</p>

<p>[nginx-label.yaml]</p>

<pre><code>apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: nginx
spec:
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: hogeginx
  annotations:
    service.beta.kubernetes.io/azure-dns-label-name: hogeginx
spec:
  selector:
    app: nginx
  type: LoadBalancer
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
</code></pre>

<p>デプロイ。</p>

<pre><code>$ kubectl create -f nginx-label.yaml
</code></pre>

<p>パブリックIP(EXTERNAL-IP)が割り当てられた後、ラベル名が使えます。ルールは [ラベル名].[リージョン].cloudapp.azure.com です。</p>

<pre><code>$ curl hogeginx.eastus.cloudapp.azure.com
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
[snip]
</code></pre>

<p>ドメイン名は指定しなくていいから、Service毎にホスト名を固定したいんじゃ、という場合にはこれでOK。</p>

<h2 id="kubenetes-externaldns">Kubenetes ExternalDNS</h2>

<p>任意のドメイン名を使いたい場合は、Incubatorプロジェクトのひとつ、Kubenetes ExternalDNSを使ってAzure DNSへAレコードを追加する手があります。本家の説明は<a href="https://github.com/kubernetes-incubator/external-dns/blob/master/docs/tutorials/azure.md">こちら</a>。</p>

<p>Kubenetes ExternalDNSは、Azure DNSなどAPIを持つDNSサービスを操作するアプリです。k8sのDeploymentとして動かせます。Route 53などにも対応。</p>

<p>さて動かしてみましょう。前提として、すでにAzure DNSにゾーンがあるものとします。</p>

<p>ExternalDNSがDNSゾーンを操作できるよう、サービスプリンシパルを作成しましょう。スコープはDNSゾーンが置かれているリソースグループ、ロールはContributorとします。</p>

<pre><code>$ az ad sp create-for-rbac --role=&quot;Contributor&quot; --scopes=&quot;/subscriptions/your-subscription-id/resourceGroups/hoge-dns-rg&quot; -n hogeExtDnsSp
</code></pre>

<p>appId、password、tenantを控えておいてください。次でsecretに使います。</p>

<p>ではExteralDNSに渡すsecretを作ります。まずJSONファイルに書きます。</p>

<p>[azure.json]</p>

<pre><code>{
    &quot;tenantId&quot;: &quot;your-tenant&quot;,
    &quot;subscriptionId&quot;: &quot;your-subscription-id&quot;,
    &quot;aadClientId&quot;: &quot;your-appId&quot;,
    &quot;aadClientSecret&quot;: &quot;your-password&quot;,
    &quot;resourceGroup&quot;: &quot;hoge-dns-rg&quot;
}
</code></pre>

<p>JSONファイルを元に、secretを作ります。</p>

<pre><code>$ kubectl create secret generic azure-config-file --from-file=azure.json
</code></pre>

<p>ExteralDNSのマニフェストを作ります。ドメイン名はexmaple.comとしていますが、使うDNSゾーンに合わせてください。以下はRBACを使っていない環境での書き方です。</p>

<p>[extdns.yaml]</p>

<pre><code>apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: external-dns
spec:
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: external-dns
    spec:
      containers:
      - name: external-dns
        image: registry.opensource.zalan.do/teapot/external-dns:v0.4.8
        args:
        - --source=service
        - --domain-filter=example.com # (optional) limit to only example.com domains; change to match the zone created above.
        - --provider=azure
        - --azure-resource-group=hoge-dns-rg # (optional) use the DNS zones from the tutorial's resource group
        volumeMounts:
        - name: azure-config-file
          mountPath: /etc/kubernetes
          readOnly: true
      volumes:
      - name: azure-config-file
        secret:
          secretName: azure-config-file
</code></pre>

<p>ExternalDNSをデプロイします。</p>

<pre><code>$ kubectl create -f extdns.yaml
</code></pre>

<p>ではホスト名を付与するServiceのマニフェストを作りましょう。先ほどのDNSラベル名付与機能と同様、annotationsへ定義します。</p>

<p>[nginx-extdns.yaml]</p>

<pre><code>apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: nginx-extdns
spec:
  template:
    metadata:
      labels:
        app: nginx-extdns
    spec:
      containers:
      - image: nginx
        name: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: hogeginx-extdns
  annotations:
    external-dns.alpha.kubernetes.io/hostname: hogeginx.example.com
spec:
  selector:
    app: nginx-extdns
  type: LoadBalancer
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
</code></pre>

<p>デプローイ。</p>

<pre><code>$ kubectl create -f nginx-extdns.yaml
</code></pre>

<p>パブリックIP(EXTERNAL-IP)が割り当てられた後、Aレコードが登録されます。確認してみましょう。</p>

<pre><code>$ az network dns record-set a list -g hoge-dns-rg -z example.com -o table
Name      ResourceGroup       Ttl  Type    Metadata
--------  ----------------  -----  ------  ----------
hogeginx  hoge-dns-rg         300  A
</code></pre>

<p>ゲッツ。</p>

<pre><code>$ curl hogeginx.example.com
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
[snip]
</code></pre>

<p>Incubatorプロジェクトなので今後大きく変化する可能性がありますが、ご参考になれば。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">11 Feb 2018, 00:20</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/aks_tls_autorenewal/" class="post-title">AKSのIngress TLS証明書を自動更新する</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="カジュアルな証明書管理方式が欲しい">カジュアルな証明書管理方式が欲しい</h2>

<p>ChromeがHTTPサイトに対する警告を<a href="https://japan.cnet.com/article/35100589/">強化するそうです</a>。非HTTPSサイトには、生きづらい世の中になりました。</p>

<p>さてそうなると、TLS証明書の入手と更新、めんどくさいですね。ガチなサイトでは証明書の維持管理を計画的に行うべきですが、検証とかちょっとした用途で立てるサイトでは、とにかくめんどくさい。カジュアルな方式が望まれます。</p>

<p>そこで、Azure Container Service(AKS)で使える気軽な方法をご紹介します。</p>

<ul>
<li>TLSはIngress(NGINX Ingress Controller)でまとめて終端</li>
<li><a href="https://letsencrypt.org/">Let&rsquo;s Encypt</a>から証明書を入手</li>
<li>Kubenetesのアドオンである<a href="https://github.com/jetstack/cert-manager/">cert-manager</a>で証明書の入手、更新とIngressへの適用を自動化

<ul>
<li>ACME(Automatic Certificate Management Environment)対応</li>
<li>cert-managerはまだ歴史の浅いプロジェクトだが、<a href="https://github.com/jetstack/cert-manager/">kube-lego</a>の後継として期待</li>
</ul></li>
</ul>

<p>なおKubernetes/AKSは開発ペースやエコシステムの変化が速いので要注意。この記事は2018/2/10に書いています。</p>

<h2 id="使い方">使い方</h2>

<p>AKSクラスターと、Azure DNS上に利用可能なゾーンがあることを前提にします。ない場合、それぞれ公式ドキュメントを参考にしてください。</p>

<ul>
<li><a href="https://docs.microsoft.com/ja-jp/azure/aks/kubernetes-walkthrough">Azure Container Service (AKS) クラスターのデプロイ</a></li>
<li><a href="https://docs.microsoft.com/ja-jp/azure/dns/dns-getstarted-cli">Azure CLI 2.0 で Azure DNS の使用を開始する</a></li>
</ul>

<p>まずAKSにNGINX Ingress Controllerを導入します。helmで入れるのが楽でしょう。<a href="http://torumakabe.github.io/post/aks_ingress_quickdeploy/">この記事</a>も参考に。</p>

<pre><code>$ helm install stable/nginx-ingress --name my-nginx
</code></pre>

<p>サービスの状況を確認します。NGINX Ingress ControllerにEXTERNAL-IPが割り当てられるまで、待ちます。</p>

<pre><code>$ kubectl get svc
NAME                                     TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                     AGE
kubernetes                               ClusterIP      10.0.0.1       &lt;none&gt;           443/TCP                     79d
my-nginx-nginx-ingress-controller        LoadBalancer   10.0.2.105     52.234.148.138   80:30613/TCP,443:30186/TCP   6m
my-nginx-nginx-ingress-default-backend   ClusterIP      10.0.102.246   &lt;none&gt;           80/TCP                     6m
</code></pre>

<p>EXTERNAL-IPが割り当てられたら、Azure DNSで名前解決できるようにします。Azure CLIを使います。Ingressのホスト名をwww.example.comとする例です。このホスト名で、後ほどLet&rsquo;s Encryptから証明書を取得します。</p>

<pre><code>$ az network dns record-set a add-record -z example.com -g your-dnszone-rg -n www -a 52.234.148.138
</code></pre>

<p>cert-managerのソースをGitHubから取得し、contribからhelm installします。いずれstableを使えるようになるでしょう。なお、このAKSクラスターはまだRBACを使っていないので、&rdquo;&ndash;set rbac.create=false&rdquo;オプションを指定しています。</p>

<pre><code>$ git clone https://github.com/jetstack/cert-manager
$ cd cert-manager/
$ helm install --name cert-manager --namespace kube-system contrib/charts/cert-manager --set rbac.create=false
</code></pre>

<p>では任意の作業ディレクトリに移動し、以下の内容でマニフェストを作ります。cm-issuer-le-staging-sample.yamlとします。</p>

<pre><code>apiVersion: certmanager.k8s.io/v1alpha1
kind: Issuer
metadata:
  name: letsencrypt-staging
  namespace: default
spec:
  acme:
    # The ACME server URL
    server: https://acme-staging.api.letsencrypt.org/directory
    # Email address used for ACME registration
    email: hoge@example.com
    # Name of a secret used to store the ACME account private key
    privateKeySecretRef:
      name: letsencrypt-staging
    # Enable the HTTP-01 challenge provider
    http01: {}
</code></pre>

<p>証明書を発行してもらうLet&rsquo;s EncryptをIssuerとして登録するわけですが、まずはステージングのAPIエンドポイントを指定しています。Let&rsquo;s Encryptには<a href="https://letsencrypt.org/docs/rate-limits/">Rate Limit</a>があり、失敗した時に痛いからです。Let&rsquo;s EncryptのステージングAPIを使うとフェイクな証明書(Fake LE Intermediate X1)が発行されますが、流れの確認やマニフェストの検証は、できます。</p>

<p>なお、Let&rsquo;s Encryptとのチャレンジには今回、HTTPを使います。DNSチャレンジも<a href="https://github.com/jetstack/cert-manager/pull/246">いずれ対応する見込み</a>です。</p>

<p>では、Issuerを登録します。</p>

<pre><code>$ kubectl apply -f cm-issuer-le-staging-sample.yaml
</code></pre>

<p>次は証明書の設定です。マニフェストはcm-cert-le-staging-sample.yamlとします。acme節にACME構成を書きます。チャレンジはHTTP、ingressClassはnginxです。</p>

<pre><code>apiVersion: certmanager.k8s.io/v1alpha1
kind: Certificate
metadata:
  name: example-com
  namespace: default
spec:
  secretName: example-com-tls
  issuerRef:
    name: letsencrypt-staging
  commonName: www.example.com
  dnsNames:
  - www.example.com
  acme:
    config:
    - http01:
        ingressClass: nginx
      domains:
      - www.example.com
</code></pre>

<p>証明書設定をデプロイします。</p>

<pre><code>$ kubectl apply -f cm-cert-le-staging-sample.yaml
</code></pre>

<p>証明書の発行状況を確認します。</p>

<pre><code>$ kubectl describe certificate example-com
Name:         example-com
Namespace:    default
[snip]
Events:
  Type     Reason                 Age              From                     Message
  ----     ------                 ----             ----                     -------
  Warning  ErrorCheckCertificate  8m               cert-manager-controller  Error checking existing TLS certificate: secret &quot;example-com-tls&quot; not found
  Normal   PrepareCertificate     8m               cert-manager-controller  Preparing certificate with issuer
  Normal   PresentChallenge       8m               cert-manager-controller  Presenting http-01 challenge for domain www.example.com
  Normal   SelfCheck              8m               cert-manager-controller  Performing self-check for domain www.example.com
  Normal   ObtainAuthorization    7m               cert-manager-controller  Obtained authorization for domain www.example.com
  Normal   IssueCertificate       7m               cert-manager-controller  Issuing certificate...
  Normal   CeritifcateIssued      7m               cert-manager-controller  Certificated issuedsuccessfully
  Normal   RenewalScheduled       7m (x2 over 7m)  cert-manager-controller  Certificate scheduled for renewal in 1438 hours
</code></pre>

<p>無事に証明書が発行され、更新もスケジュールされました。手順やマニフェストの書きっぷりは問題なさそうです。これをもってステージング完了としましょう。</p>

<p>ではLet&rsquo;s EncryptのAPIエンドポイントをProduction向けに変更し、新たにIssuer登録します。cm-issuer-le-prod-sample.yamlとします。</p>

<pre><code>apiVersion: certmanager.k8s.io/v1alpha1
kind: Issuer
metadata:
  name: letsencrypt-prod
  namespace: default
spec:
  acme:
    # The ACME server URL
    server: https://acme-v01.api.letsencrypt.org/directory
    # Email address used for ACME registration
    email: hoge@example.com
    # Name of a secret used to store the ACME account private key
    privateKeySecretRef:
      name: letsencrypt-prod
    # Enable the HTTP-01 challenge provider
    http01: {}
</code></pre>

<p>デプロイします。</p>

<pre><code>$ kubectl apply -f cm-issuer-le-prod-sample.yaml
</code></pre>

<p>同様に、Production向けの証明書設定をします。cm-cert-le-prod-sample.yamlとします。</p>

<pre><code>apiVersion: certmanager.k8s.io/v1alpha1
kind: Certificate
metadata:
  name: prod-example-com
  namespace: default
spec:
  secretName: prod-example-com-tls
  issuerRef:
    name: letsencrypt-prod
  commonName: www.example.com
  dnsNames:
  - www.example.com
  acme:
    config:
    - http01:
        ingressClass: nginx
      domains:
      - www.example.com
</code></pre>

<p>デプロイします。</p>

<pre><code>$ kubectl apply -f cm-cert-le-prod-sample.yaml
</code></pre>

<p>発行状況を確認します。</p>

<pre><code>$ kubectl describe certificate prod-example-com
Name:         prod-example-com
Namespace:    default
[snip]
Events:
  Type     Reason                 Age              From                     Message
  ----     ------                 ----             ----                     -------
  Warning  ErrorCheckCertificate  27s              cert-manager-controller  Error checking existing TLS certificate: secret &quot;prod-example-com-tls&quot; not found
  Normal   PrepareCertificate     27s              cert-manager-controller  Preparing certificate with issuer
  Normal   PresentChallenge       26s              cert-manager-controller  Presenting http-01 challenge for domain www.example.com
  Normal   SelfCheck              26s              cert-manager-controller  Performing self-check for domain www.example.com
  Normal   IssueCertificate       7s               cert-manager-controller  Issuing certificate...
  Normal   ObtainAuthorization    7s               cert-manager-controller  Obtained authorization for domain www.example.com
  Normal   RenewalScheduled       6s (x3 over 5m)  cert-manager-controller  Certificate scheduled for renewal in 1438 hours
  Normal   CeritifcateIssued      6s               cert-manager-controller  Certificated issuedsuccessfully
</code></pre>

<p>証明書が発行され、1438時間(約60日)内の更新がスケジュールされました。</p>

<p>ではバックエンドを設定して確認してみましょう。バックエンドにNGINXを立て、exposeします。</p>

<pre><code>$ kubectl run nginx --image nginx --port 80
$ kubectl expose deployment nginx --type NodePort
</code></pre>

<p>Ingressを設定します。ファイル名はingress-nginx-sample.yamlとします。</p>

<pre><code>apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/rewrite-target: /
  name: ingress-nginx-sample
spec:
  rules:
    - host: www.example.com
      http:
        paths:
          - path: /
            backend:
              serviceName: nginx
              servicePort: 80
  tls:
    - hosts:
      - www.example.com
      secretName: prod-example-com-tls
</code></pre>

<p>デプロイします。</p>

<pre><code>$ kubectl apply -f ingress-nginx-sample.yaml
</code></pre>

<p>いざ確認。</p>

<pre><code>$ curl https://www.example.com/
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
[snip]
</code></pre>

<p>便利ですね。Let&rsquo;s Encryptをはじめ、関連プロジェクトに感謝です。</p>

                    </div>
                </section>
                
            </div>
            
<div class="pagination">
  <nav role="pagination" class="post-list-pagination">
      
    <span class="post-list-pagination-item post-list-pagination-item-current">Page 1 of 9</span>
    
      <a href="/categories/azure/page/2/" class="post-list-pagination-item pure-button post-list-pagination-item-next">
        Older&nbsp;<i class="fa fa-angle-double-right"></i>
      </a>
    
  </nav>
</div>


            <div class="footer">
    <div class="pure-menu pure-menu-horizontal pure-menu-open">
        <ul>
            <li>Powered by <a class="hugo" href="http://hugo.spf13.com/" target="_blank">hugo</a></li>
        </ul>
    </div>
</div>
<script src="http://torumakabe.github.io//js/all.min.js"></script>
        </div>
    </div>
</div>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');

</script>

</body>
</html>
