<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>re-imagine &middot; re-imagine</title>

    <meta name="description" content="my life is the sum of my imagination">

    <meta name="generator" content="Hugo 0.15" />
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="tmak_tw" />
    <meta name="twitter:title" content="re-imagine &middot; re-imagine">
    <meta name="twitter:description" content="my life is the sum of my imagination">

    <meta property="og:type" content="article">
    <meta property="og:title" content="re-imagine &middot; re-imagine">
    <meta property="og:description" content="my life is the sum of my imagination">

    <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Oxygen:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-old-ie-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css">
    <!--<![endif]-->

    <link rel="stylesheet" href="http://torumakabe.github.io//css/all.min.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

    <link rel="alternate" type="application/rss+xml" title="re-imagine" href="http://torumakabe.github.io//index.xml" />
</head>
<body>


<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
    <div class="header">
        <hgroup>
            <h1 class="brand-title"><a href="http://torumakabe.github.io/">re-imagine</a></h1>
            <h2 class="brand-tagline"> my life is the sum of my imagination </h2>
        </hgroup>

        <nav class="nav">
            <ul class="nav-list">
                
                <li class="nav-item">
                    <a class="pure-button" href="https://twitter.com/tmak_tw"><i class="fa fa-twitter"></i> Twitter</a>
                </li>
                
                
                <li class="nav-item">
                    <a class="pure-button" href="https://github.com/ToruMakabe "><i class="fa fa-github-alt"></i> github</a>
                </li>
                
                <li class="nav-item">
                    <a class="pure-button" href="http://torumakabe.github.io//index.xml"><i class="fa fa-rss"></i> rss</a>
                </li>
            </ul>
        </nav>
    </div>
</div>


    <div class="content pure-u-1 pure-u-md-3-4">
        <div>
            
            <div class="posts">
                
                <h1 class="content-subhead">29 Apr 2016, 17:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_batch_docker/" class="post-title">Azure BatchとDockerで管理サーバレスバッチ環境を作る</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="サーバレスって言いたいだけじゃないです:1e958ca6820e4dcff939a22a84382ed3">サーバレスって言いたいだけじゃないです</h2>

<p>Linux向けAzure BatchのPreviewが<a href="https://azure.microsoft.com/ja-jp/blog/announcing-support-of-linux-vm-on-azure-batch-service/">はじまり</a>ました。地味ですが、なかなかのポテンシャルです。</p>

<p>クラウドでバッチを走らせる時にチャレンジしたいことの筆頭は「ジョブを走らせる時だけサーバ使う。待機時間は消しておいて、
節約」でしょう。</p>

<p>ですが、仕組み作りが意外に面倒なんですよね。管理サーバを作って、ジョブ管理ソフト入れて、Azure SDK/CLI入れて。クレデンシャルを安全に管理して。可用性確保して。バックアップして。で、管理サーバは消せずに常時起動。なんか中途半端です。</p>

<p>その課題、Azure Batchを使って解決しましょう。レッツ管理サーバレスバッチ処理。</p>

<h2 id="コンセプト:1e958ca6820e4dcff939a22a84382ed3">コンセプト</h2>

<ul>
<li>管理サーバを作らない</li>
<li>Azure Batchコマンドでジョブを投入したら、あとはスケジュール通りに定期実行される</li>
<li>ジョブ実行サーバ群(Pool)は必要な時に作成され、処理が終わったら削除される</li>
<li>サーバの迅速な作成とアプリ可搬性担保のため、dockerを使う</li>
<li>セットアップスクリプト、タスク実行ファイル、アプリ向け入力/出力ファイルはオブジェクトストレージに格納</li>
</ul>

<h2 id="サンプル:1e958ca6820e4dcff939a22a84382ed3">サンプル</h2>

<p>Githubにソースを<a href="https://github.com/ToruMakabe/Azure_Batch_Sample">置いておきます</a>。</p>

<h3 id="バッチアカウントとストレージアカウント-コンテナの作成とアプリ-データの配置:1e958ca6820e4dcff939a22a84382ed3">バッチアカウントとストレージアカウント、コンテナの作成とアプリ、データの配置</h3>

<p><a href="https://azure.microsoft.com/ja-jp/documentation/articles/batch-technical-overview/">公式ドキュメント</a>で概要を確認しましょう。うっすら理解できたら、バッチアカウントとストレージアカウントを作成します。</p>

<p>ストレージアカウントに、Blobコンテナを作ります。サンプルの構成は以下の通り。</p>

<pre><code>.
├── blob
│   ├── application
│   │   ├── starttask.sh
│   │   └── task.sh
│   ├── input
│   │   └── the_star_spangled_banner.txt
│   └── output
</code></pre>

<p>applicationコンテナに、ジョブ実行サーバ作成時のスクリプト(starttask.sh)と、タスク実行時のスクリプト(task.sh)を配置します。</p>

<ul>
<li><a href="https://github.com/ToruMakabe/Azure_Batch_Sample/blob/master/blob/application/starttask.sh">starttask.sh</a> - docker engineをインストールします</li>
<li><a href="https://github.com/ToruMakabe/Azure_Batch_Sample/blob/master/blob/application/task.sh">task.sh</a> - docker hubからサンプルアプリが入ったコンテナを持ってきて実行します。<a href="https://github.com/ToruMakabe/Azure_Batch_Sample/tree/master/docker">サンプル</a>はPythonで書いたシンプルなWord Countアプリです</li>
</ul>

<p>また、アプリにデータをわたすinputコンテナと、実行結果を書き込むoutputコンテナも作ります。サンプルのinputデータはアメリカ国歌です。</p>

<p>コンテナ、ファイルには、適宜SASを生成しておいてください。inputではreadとlist、outputでは加えてwrite権限を。</p>

<p>さて、いよいよジョブをJSONで定義します。詳細は<a href="https://msdn.microsoft.com/en-us/library/azure/dn820158.aspx?f=255&amp;MSPPError=-2147217396">公式ドキュメント</a>を確認してください。ポイントだけまとめます。</p>

<ul>
<li>2016/04/29 05:30(UTC)から開始する - schedule/doNotRunUntil</li>
<li>4時間ごとに実行する - schedule/recurrenceInterval</li>
<li>ジョブ実行後にサーバプールを削除する - jobSpecification/poolInfo/autoPoolSpecification/poolLifetimeOption</li>
<li>ジョブ実行時にtask.shを呼び出す  - jobSpecification/jobManagerTask/commandLine</li>
<li>サーバはUbuntu 14.04とする - jobSpecification/poolInfo/autoPoolSpecification/virtualMachineConfiguration</li>
<li>サーバ数は1台とする - jobSpecification/poolInfo/autoPoolSpecification/pool/targetDedicated</li>
<li>サーバプール作成時にstarttask.shを呼び出す - jobSpecification/poolInfo/autoPoolSpecification/pool/startTask</li>
</ul>

<pre><code>  {
  &quot;odata.metadata&quot;:&quot;https://myaccount.myregion.batch.azure.com/$metadata#jobschedules/@Element&quot;,
  &quot;id&quot;:&quot;myjobschedule1&quot;,
  &quot;schedule&quot;: {
    &quot;doNotRunUntil&quot;:&quot;2016-04-29T05:30:00.000Z&quot;,
    &quot;recurrenceInterval&quot;:&quot;PT4H&quot;
  },
  &quot;jobSpecification&quot;: {
    &quot;priority&quot;:100,
    &quot;constraints&quot;: {
      &quot;maxWallClockTime&quot;:&quot;PT1H&quot;,
      &quot;maxTaskRetryCount&quot;:-1
    },
    &quot;jobManagerTask&quot;: {
      &quot;id&quot;:&quot;mytask1&quot;,
      &quot;commandLine&quot;:&quot;/bin/bash -c 'export LC_ALL=en_US.UTF-8; ./task.sh'&quot;,
      &quot;resourceFiles&quot;: [ {
        &quot;blobSource&quot;:&quot;yourbloburi&amp;sas&quot;,
        &quot;filePath&quot;:&quot;task.sh&quot;
      }], 
      &quot;environmentSettings&quot;: [ {
        &quot;name&quot;:&quot;VAR1&quot;,
        &quot;value&quot;:&quot;hello&quot;
      } ],
      &quot;constraints&quot;: {
        &quot;maxWallClockTime&quot;:&quot;PT1H&quot;,
        &quot;maxTaskRetryCount&quot;:0,
        &quot;retentionTime&quot;:&quot;PT1H&quot;
      },
      &quot;killJobOnCompletion&quot;:false,
      &quot;runElevated&quot;:true,
      &quot;runExclusive&quot;:true
      },
      &quot;poolInfo&quot;: {
        &quot;autoPoolSpecification&quot;: {
          &quot;autoPoolIdPrefix&quot;:&quot;mypool&quot;,
          &quot;poolLifetimeOption&quot;:&quot;job&quot;,
          &quot;pool&quot;: {
            &quot;vmSize&quot;:&quot;STANDARD_D1&quot;,
            &quot;virtualMachineConfiguration&quot;: {
              &quot;imageReference&quot;: {
                &quot;publisher&quot;:&quot;Canonical&quot;,
                &quot;offer&quot;:&quot;UbuntuServer&quot;,
                &quot;sku&quot;:&quot;14.04.4-LTS&quot;,
                &quot;version&quot;:&quot;latest&quot;
              },
              &quot;nodeAgentSKUId&quot;:&quot;batch.node.ubuntu 14.04&quot;
            },
            &quot;resizeTimeout&quot;:&quot;PT15M&quot;,
            &quot;targetDedicated&quot;:1,
            &quot;maxTasksPerNode&quot;:1,
            &quot;taskSchedulingPolicy&quot;: {
              &quot;nodeFillType&quot;:&quot;Spread&quot;
            },
            &quot;enableAutoScale&quot;:false,
            &quot;enableInterNodeCommunication&quot;:false,
            &quot;startTask&quot;: {
              &quot;commandLine&quot;:&quot;/bin/bash -c 'export LC_ALL=en_US.UTF-8; ./starttask.sh'&quot;,
              &quot;resourceFiles&quot;: [ {
                &quot;blobSource&quot;:&quot;yourbloburi&amp;sas&quot;,
                &quot;filePath&quot;:&quot;starttask.sh&quot;
              } ],
              &quot;environmentSettings&quot;: [ {
                &quot;name&quot;:&quot;VAR2&quot;,
                &quot;value&quot;:&quot;Chao&quot;
              } ],
              &quot;runElevated&quot;:true,
              &quot;waitForSuccess&quot;:true
            },
            &quot;metadata&quot;: [ {
              &quot;name&quot;:&quot;myproperty&quot;,
              &quot;value&quot;:&quot;myvalue&quot;
            } ]
          }
        }
      }
    }
  }
</code></pre>

<p>そろそろ人類はJSONに変わるやり口を発明すべきですが、XMLよりはいいですね。</p>

<p>それはさておき、面白そうなパラメータたち。並列バッチやジョブリリース時のタスクなど、今回使っていないものもまだまだあります。応用版はまたの機会に。</p>

<p>ではスケジュールジョブをAzure BatchにCLIで送り込みます。</p>

<pre><code>azure batch job-schedule create -f ./create_jobsched.json -u https://yourendpoint.location.batch.azure.com -a yourbatchaccount -k yourbatchaccountkey
</code></pre>

<p>以上です。あとはAzureにお任せです。4時間に1回、アメリカ国歌の単語を数える刺身タンポポなジョブですが、コツコツいきましょう。</p>

<h2 id="azure-automationとの使い分け:1e958ca6820e4dcff939a22a84382ed3">Azure Automationとの使い分け</h2>

<p>Azure Automationを使っても、ジョブの定期実行はできます。大きな違いは、PowerShellの要否と並列実行フレームワークの有無です。Azure AutomationはPowerShell前提ですが、Azure BatchはPowerShellに馴染みのない人でも使うことができます。また、今回は触れませんでしたが、Azure Batchは並列バッチ、オートスケールなど、バッチ処理に特化した機能を提供していることが特長です。うまく使い分けましょう。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">21 Apr 2016, 21:30</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_pageblob_billable_linux/" class="post-title">Azure Linux VMのディスク利用料節約Tips</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="定義領域全てが課金されるわけではありません:73b15a413c7cb87e88f45a7aaba2eebd">定義領域全てが課金されるわけではありません</h2>

<p>AzureのIaaSでは、VMに接続するディスクとしてAzure StorageのPage Blobを使います。Page Blobは作成時に容量を定義しますが、課金対象となるのは、実際に書き込んだ領域分のみです。たとえば10GBytesのVHD Page Blobを作ったとしても、1GBytesしか書き込んでいなければ、課金対象は1GBytesです。</p>

<p>なお、Premium Storageは例外です。<a href="https://azure.microsoft.com/ja-jp/pricing/details/storage/">FAQ</a>を確認してみましょう。</p>

<pre><code>仮想マシンに空の 100 GB ディスクを接続した場合、100 GB 全体に対する料金が請求されますか? それとも使用したストレージ領域の分だけが請求されますか?

空の 100 GB ディスクが Premium Storage アカウントによって保持されている場合、P10 (128 GB) ディスクの料金が課金されます。その他の種類の Storage アカウントが使用されている場合、割り当てられたディスク サイズに関わらず、ディスクに書き込まれたデータを保存するために使用しているストレージ領域分のみ請求されます。
</code></pre>

<p>詳細な定義は、以下で。</p>

<p><a href="https://blogs.msdn.microsoft.com/windowsazurestorage/2010/07/08/understanding-windows-azure-storage-billing-bandwidth-transactions-and-capacity/">Understanding Windows Azure Storage Billing – Bandwidth, Transactions, and Capacity</a></p>

<h2 id="書き込み方はosやファイルシステム次第:73b15a413c7cb87e88f45a7aaba2eebd">書き込み方はOSやファイルシステム次第</h2>

<p>じゃあ、OSなりファイルシステムが、実際にどのタイミングでディスクに書き込むのか、気になりますね。実データの他に管理情報、メタデータがあるので、特徴があるはずです。Linuxで検証してみましょう。</p>

<ul>
<li>RHEL 7.2 on Azure</li>
<li>XFS &amp; Ext4</li>
<li>10GBytesのPage Blobの上にファイルシステムを作成</li>
<li>mkfsはデフォルト</li>
<li>mountはデフォルトとdiscardオプションありの2パターン</li>
<li>MD、LVM構成にしない</li>
<li>以下のタイミングで課金対象容量を確認

<ul>
<li>Page BlobのVMアタッチ時</li>
<li>ファイルシステム作成時</li>
<li>マウント時</li>
<li>約5GBytesのデータ書き込み時 (ddで/dev/zeroをbs=1M、count=5000で書き込み)</li>
<li>5GBytesのファイル削除時</li>
</ul></li>
</ul>

<p>課金対象容量は、以下のPowerShellで取得します。リファレンスは<a href="https://gallery.technet.microsoft.com/scriptcenter/Get-Billable-Size-of-32175802">ここ</a>。</p>

<pre><code>$Blob = Get-AzureStorageBlob yourDataDisk.vhd -Container vhds -Context $Ctx

$blobSizeInBytes = 124 + $Blob.Name.Length * 2

$metadataEnumerator = $Blob.ICloudBlob.Metadata.GetEnumerator()
while ($metadataEnumerator.MoveNext())
{
    $blobSizeInBytes += 3 + $metadataEnumerator.Current.Key.Length + $metadataEnumerator.Current.Value.Length
}

$Blob.ICloudBlob.GetPageRanges() | 
    ForEach-Object { $blobSizeInBytes += 12 + $_.EndOffset - $_.StartOffset }

return $blobSizeInBytes
</code></pre>

<p>ストレージコンテキストの作り方は<a href="https://azure.microsoft.com/ja-jp/documentation/articles/storage-powershell-guide-full/">ここ</a>を参考にしてください。</p>

<h2 id="結果:73b15a413c7cb87e88f45a7aaba2eebd">結果</h2>

<h3 id="xfs:73b15a413c7cb87e88f45a7aaba2eebd">XFS</h3>

<table>
<thead>
<tr>
<th align="left">　確認タイミング　</th>
<th align="right">　課金対象容量(Bytes)　</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Page BlobのVMアタッチ時</td>
<td align="right">960</td>
</tr>

<tr>
<td align="left">ファイルシステム作成時</td>
<td align="right">10,791,949</td>
</tr>

<tr>
<td align="left">マウント時</td>
<td align="right">10,791,949</td>
</tr>

<tr>
<td align="left">5GBytesのデータ書き込み時</td>
<td align="right">5,253,590,051</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時</td>
<td align="right">5,253,590,051</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時 (discard)</td>
<td align="right">10,710,029</td>
</tr>
</tbody>
</table>

<h3 id="ext4:73b15a413c7cb87e88f45a7aaba2eebd">Ext4</h3>

<table>
<thead>
<tr>
<th align="left">　確認タイミング　</th>
<th align="right">　課金対象容量(Bytes)　</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Page BlobのVMアタッチ時</td>
<td align="right">960</td>
</tr>

<tr>
<td align="left">ファイルシステム作成時</td>
<td align="right">138,683,592</td>
</tr>

<tr>
<td align="left">マウント時</td>
<td align="right">306,451,689</td>
</tr>

<tr>
<td align="left">5GBytesのデータ書き込み時</td>
<td align="right">5,549,470,887</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時</td>
<td align="right">5,549,470,887</td>
</tr>

<tr>
<td align="left">5Gbytesのファイル削除時 (discard)</td>
<td align="right">306,586,780</td>
</tr>
</tbody>
</table>

<p>この結果から、以下のことがわかります。</p>

<ul>
<li>10GBytesのBlobを作成しても、全てが課金対象ではない</li>
<li>当然だが、ファイルシステムによってメタデータの書き方が違う、よって書き込み容量も異なる</li>
<li>discardオプションなしでマウントすると、ファイルを消しても課金対象容量は減らない

<ul>
<li>OSがPage Blobに&rdquo;消した&rdquo;と伝えないから</li>
<li>discardオプションにてSCSI UNMAPがPage Blobに伝えられ、領域は解放される(課金対象容量も減る)</li>
<li>discardオプションはリアルタイムであるため便利。でも性能影響があるため、実運用ではバッチ適用(fstrim)が<a href="https://access.redhat.com/documentation/ja-JP/Red_Hat_Enterprise_Linux/7/html/Storage_Administration_Guide/ch02s05.html">おすすめ</a></li>
</ul></li>
</ul>

<p>知っているとコスト削減に役立つTipsでした。ぜひ運用前には、利用予定のファイルシステムやオプションで、事前に検証してみてください。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">17 Apr 2016, 10:30</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_docker_cntk/" class="post-title">AzureとDockerでDeep Learning(CNTK)環境をサク作する</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="気軽に作って壊せる環境を作る:7c419a069d08019c3093e0308a68c463">気軽に作って壊せる環境を作る</h2>

<p>Deep Learning環境設計のお手伝いをする機会に恵まれまして。インフラおじさんはDeep Learningであれこれする主役ではないのですが、ちょっとは中身を理解しておきたいなと思い、環境作ってます。</p>

<p>試行錯誤するでしょうから、萎えないようにデプロイは自動化します。</p>

<h2 id="方針:7c419a069d08019c3093e0308a68c463">方針</h2>

<ul>
<li>インフラはAzure Resource Manager Templateでデプロイする

<ul>
<li>Linux (Ubuntu 14.04) VM, 仮想ネットワーク/ストレージ関連リソース</li>
</ul></li>
<li>CNTKをビルド済みのdockerリポジトリをDocker Hubに置いておく

<ul>
<li>Dockerfileの元ネタは<a href="https://github.com/Microsoft/CNTK/tree/master/Tools/docker">ここ</a>

<ul>
<li>GPUむけもあるけどグッと我慢、今回はCPUで</li>
</ul></li>
<li>Docker Hub上のリポジトリは <a href="https://hub.docker.com/r/torumakabe/cntk-cpu/">torumakabe/cntk-cpu</a></li>
</ul></li>
<li>ARM TemplateデプロイでVM Extensionを仕込んで、上物のセットアップもやっつける

<ul>
<li>docker extensionでdocker engineを導入</li>
<li>custom script extensionでdockerリポジトリ(torumakabe/cntk-cpu)をpull</li>
</ul></li>
<li>VMにログインしたら即CNTKを使える、幸せ</li>
</ul>

<h2 id="使い方:7c419a069d08019c3093e0308a68c463">使い方</h2>

<p>Azure CLIでARM Templateデプロイします。WindowsでもMacでもLinuxでもOK。</p>

<p>リソースグループを作ります。</p>

<pre><code>C:\Work&gt; azure group create CNTK -l &quot;Japan West&quot;
</code></pre>

<p>ARMテンプレートの準備をします。テンプレートはGithubに置いておきました。</p>

<ul>
<li><a href="https://github.com/ToruMakabe/CNTK/blob/master/deploy_singlenode/azuredeploy.json">azuredeploy.json</a>

<ul>
<li>編集不要です</li>
</ul></li>
<li><a href="https://github.com/ToruMakabe/CNTK/blob/master/deploy_singlenode/azuredeploy.parameters.sample.json">azuredeploy.parameters.json</a>

<ul>
<li>テンプレートに直で書かきたくないパラメータです</li>
<li>fileUris、commandToExecute以外は、各々で</li>
<li>fileUris、commandToExecuteもGist読んでdocker pullしているだけなので、お好みで変えてください</li>
<li>ファイル名がazuredeploy.parameters.&ldquo;sample&rdquo;.jsonなので、以降の手順では&rdquo;sample&rdquo;を外して読み替えてください</li>
</ul></li>
</ul>

<p>うし、デプロイ。</p>

<pre><code>C:\Work&gt; azure group deployment create CNTK dep01 -f .\azuredeploy.json -e .\azuredeploy.parameters.json
</code></pre>

<p>10分くらい待つと、できあがります。VMのパブリックIPを確認し、sshしましょう。</p>

<p>docker engine入ってますかね。</p>

<pre><code>yourname@yournamecntkr0:~$ docker -v
Docker version 1.11.0, build 4dc5990
</code></pre>

<p>CNTKビルド済みのdockerイメージ、pullできてますかね。</p>

<pre><code>yourname@yournamecntkr0:~$ docker images
REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
yournamebe/cntk-cpu   latest              9abab8a76543        9 hours ago         2.049 GB
</code></pre>

<p>問題なし。ではエンジョイ Deep Learning。</p>

<pre><code>yourname@yournamecntkr0:~$ docker run -it torumakabe/cntk-cpu
root@a1234bc5d67d:/cntk#
</code></pre>

<p>CNTKの利用例は、<a href="https://github.com/Microsoft/CNTK/tree/master/Examples">Github</a>にあります。</p>

<h2 id="今後の展開:7c419a069d08019c3093e0308a68c463">今後の展開</h2>

<p>インフラおじさんは、最近Linuxむけに<a href="https://azure.microsoft.com/ja-jp/blog/announcing-support-of-linux-vm-on-azure-batch-service/">Previewがはじまった</a>Azure Batchと、このエントリで使った仕掛けを組み合わせて、大規模並列Deep Learning環境の自動化と使い捨て化を企んでいます。</p>

<p>これだけ簡単に再現性ある環境を作れるなら、常時インフラ起動しておく必要ないですものね。使い捨てでいいです。</p>

<p>もちろんdockerやGPUまわりの性能など別の課題にぶつかりそうですが、人間がどれだけ楽できるかとのトレードオフかと。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">06 Apr 2016, 17:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/azure_auditlog_alert/" class="post-title">Azureの監査ログアラートからWebhookの流れで楽をする</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Azure" href="http://torumakabe.github.io//categories/azure">Azure</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="監査ログからアラートを上げられるようになります:aafd9305d99be4ae8d2b9c3fb4887452">監査ログからアラートを上げられるようになります</h2>

<p>Azureの監査ログからアラートを上げる機能のプレビューが<a href="https://azure.microsoft.com/ja-jp/blog/new-features-for-azure-alerts-and-autoscale/">はじまりました</a>。これ、地味ですが便利な機能です。日々の運用に効きます。</p>

<h2 id="どんな風に使えるか:aafd9305d99be4ae8d2b9c3fb4887452">どんな風に使えるか</h2>

<p>ルールに合致した監査ログが生成された場合、メール通知とWebhookによる自動アクションができます。可能性無限大です。</p>

<p>たとえば、「特定のリソースグループにVMが生成された場合、そのVMに対し強制的にログ収集エージェントをインストールし、ログを集める」なんてことができます。</p>

<p>これは「生産性を上げるため、アプリ開発チームにVMの生成は委任したい。でもセキュリティなどの観点から、ログは集めておきたい」なんてインフラ担当/Opsの課題に効きます。開発チームに「VM生成時には必ず入れてね」とお願いするのも手ですが、やはり人間は忘れる生き物ですので、自動で適用できる仕組みがあるとうれしい。</p>

<p>これまでは監視用のVMを立てて、「新しいVMがあるかどうか定期的にチェックして、あったらエージェントを叩き込む」なんてことをしていたわけですが、もうそのVMは不要です。定期的なチェックも要りません。アラートからアクションを実現する仕組みを、Azureがマネージドサービスとして提供します。</p>

<h2 id="実装例:aafd9305d99be4ae8d2b9c3fb4887452">実装例</h2>

<p>例としてこんな仕組みを作ってみましょう。</p>

<ul>
<li>西日本リージョンのリソースグループ&rdquo;dev&rdquo;にVMが作成されたら、自動的にメール通知とWebhookを実行</li>
<li>WebhookでAzure AutomationのRunbook Jobを呼び出し、OMS(Operations Management Suite)エージェントを該当のVMにインストール、接続先OMSを設定する</li>
<li>OMSでログ分析</li>
</ul>

<h2 id="準備:aafd9305d99be4ae8d2b9c3fb4887452">準備</h2>

<p>以下の準備ができているか確認します。</p>

<ul>
<li>Azure Automation向けADアプリ、サービスプリンシパル作成</li>
<li>サービスプリンシパルへのロール割り当て</li>
<li>Azure Automationのアカウント作成</li>
<li>Azure Automation Runbook実行時ログインに必要な証明書や資格情報などの資産登録</li>
<li>Azure Automation Runbookで使う変数資産登録 (Runbook内でGet-AutomationVariableで取得できます。暗号化もできますし、コードに含めるべきでない情報は、登録しましょう。後述のサンプルではログイン関連情報、OMS関連情報を登録しています)</li>
<li>OMSワークスペースの作成</li>
</ul>

<p>もしAutomationまわりの作業がはじめてであれば、下記記事を参考にしてください。とてもわかりやすい。</p>

<p><strong><a href="http://qiita.com/sengoku/items/1c3994ac8a2f0f0e88c5">勤務時間中だけ仮想マシンを動かす（スケジュールによる自動起動・停止）</a></strong></p>

<h2 id="azure-automation側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452">Azure Automation側の仕掛け</h2>

<p>先にAutomationのRunbookを作ります。アラート設定をする際、RunbookのWebhook URLが必要になるので。</p>

<p>ちなみにわたしは証明書を使ってログインしています。資格情報を使う場合はログインまわりのコードを読み替えてください。</p>

<pre><code>param ( 
    [object]$WebhookData          
)

if ($WebhookData -ne $null) {  
    $WebhookName    =   $WebhookData.WebhookName
    $WebhookBody    =   $WebhookData.RequestBody  
    $WebhookBody = (ConvertFrom-Json -InputObject $WebhookBody)

    $AlertContext = [object]$WebhookBody.context

    $SPAppID = Get-AutomationVariable -Name 'SPAppID'
    $Tenant = Get-AutomationVariable -Name 'TenantID'
    $OMSWorkspaceId = Get-AutomationVariable -Name 'OMSWorkspaceId'
    $OMSWorkspaceKey = Get-AutomationVariable -Name 'OMSWorkspaceKey'
    $CertificationName = Get-AutomationVariable -Name 'CertificationName'
    $Certificate = Get-AutomationCertificate -Name $CertificationName
    $CertThumbprint = ($Certificate.Thumbprint).ToString()    

    $null = Login-AzureRmAccount -ServicePrincipal -TenantId $Tenant -CertificateThumbprint $CertThumbprint -ApplicationId $SPAppID   

    $resourceObj = Get-AzureRmResource -ResourceId $AlertContext.resourceId
    $VM = Get-AzureRmVM -Name $resourceObj.Name -ResourceGroupName $resourceObj.ResourceGroupName

    $Settings = @{&quot;workspaceId&quot; = &quot;$OMSWorkspaceId&quot;}
    $ProtectedSettings = @{&quot;workspaceKey&quot; = &quot;$OMSWorkspaceKey&quot;}

    if ($VM.StorageProfile.OsDisk.OsType -eq &quot;Linux&quot;) {  
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &quot;OmsAgentForLinux&quot; -Publisher &quot;Microsoft.EnterpriseCloud.Monitoring&quot; -ExtensionType &quot;OmsAgentForLinux&quot; -TypeHandlerVersion &quot;1.0&quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    elseif ($VM.StorageProfile.OsDisk.OsType -eq &quot;Windows&quot;)
    {
        Set-AzureRmVMExtension -ResourceGroupName $AlertContext.resourceGroupName -Location $VM.Location -VMName $VM.Name -Name &quot;MicrosoftMonitoringAgent&quot; -Publisher &quot;Microsoft.EnterpriseCloud.Monitoring&quot; -ExtensionType &quot;MicrosoftMonitoringAgent&quot; -TypeHandlerVersion &quot;1.0&quot; -Settings $Settings -ProtectedSettings $ProtectedSettings;
    }
    else
    {
        Write-Error &quot;Unknown OS Type.&quot;
    }
}
else 
{
    Write-Error &quot;This runbook is meant to only be started from a webhook.&quot; 
}
</code></pre>

<p>Runbookができたら、Webhookを作ります。詳しくは<a href="https://azure.microsoft.com/ja-jp/documentation/articles/automation-webhooks/">こちら</a>。</p>

<p>WebhookのURLを控えておいてください。</p>

<h2 id="azure-監査ログアラート側の仕掛け:aafd9305d99be4ae8d2b9c3fb4887452">Azure 監査ログアラート側の仕掛け</h2>

<p>Powershellでアラートルールを作ります。実行アカウントの権限に気をつけてください。</p>

<pre><code>PS C:\work&gt; $actionEmail = New-AzureRmAlertRuleEmail -CustomEmail yourname@example.com

PS C:\work&gt; $actionWebhook = New-AzureRmAlertRuleWebhook -ServiceUri https://abcdefgh.azure-automation.net/webhooks?token=your_token

PS C:\work&gt; Add-AzureRmLogAlertRule -Name createdVM -Location &quot;Japan West&quot; -ResourceGroup dev -OperationName Microsoft.Compute/virtualMachines/write -Status Succeeded  -SubStatus Created -TargetResourceGroup dev -Actions $actionEmail,$actionWebhook
</code></pre>

<p>以上。これで&rdquo;dev&rdquo;リソースグループにVMが作られた場合、自動でOMSエージェントがインストールされ、ログ収集がはじまります。</p>

<p>なお、メールも飛んできますので、うっとおしくなったらメール通知はアクションから外すか、ルールでさばいてくださいね。</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">27 Mar 2016, 20:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="http://torumakabe.github.io/post/bookreview_site_reliability_engineering/" class="post-title">書評: Site Reliability Engineering</a>

                        <p class="post-meta">
                            
                            
                                under 
                                
                                <a class="post-category post-category-Book" href="http://torumakabe.github.io//categories/book">Book</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h2 id="英語だけどぜひ読んでほしい:85f39e44bed874d49c5c215a7c1e75f5">英語だけどぜひ読んでほしい</h2>

<p><strong><a href="http://www.amazon.co.jp/Site-Reliability-Engineering-Production-Systems-ebook/dp/B01DCPXKZ6/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=1459069692&amp;sr=8-1">Site Reliability Engineering: How Google Runs Production Systems</a></strong></p>

<p>参考になったのでご紹介。Googleのインフラ/Ops系技術チームの働き方や考え方を題材にした本です。GoogleのSREについては断片的に知っていたのですが、まとめて読むと違いますね。背景やストーリーがあって、理解しやすいです。</p>

<p>共感できるネタがどんどん繰り出されるので、一気読みしました。読み込みが浅いところもあったので、改めて読む予定。</p>

<p>以下、印象に残ったこと。</p>

<ul>
<li><p>Site Reliability Engineering teamは、インフラ/Ops担当であるが、Unix内部やネットワークなどインフラの知見を持つソフトウェアエンジニアの集団。自分たちのオペレーションを効率的に、迅速に、確実にするために、コードを書く。</p></li>

<li><p>インシデント対応、問い合わせ対応、手作業は仕事の50%に収まるように調整する。残りの時間は自分たちの仕事をより良く、楽にするために、コードを書く。</p></li>

<li><p>日々のリアクティブな活動に忙殺されるインフラ/Ops担当はどうしても減点評価になりがちだが、仕事の半分がプロアクティブな活動であり、成果を加点評価できる。昇格、昇給の根拠になりやすい。</p></li>

<li><p>アプリ/製品チームとSREチームは&rdquo;Error Budget&rdquo;を定義、共有する。これは四半期ごとに定義される、サービスレベル目標である。ユーザがサービスを使えなくなると、その時間が、このError Budgetから取り崩されていく。Budgetが残り少なくなると、リスクを伴うデプロイなどは控える。</p></li>

<li><p>インフラ/Ops担当は「サービスを少しでもダウンさせたら悪」となりがちだが、サービスごとにアプリ/製品チームとSREチームがError Budgetを共有することで、利害関係を一致できる。</p></li>

<li><p>Error Budgetの大きさはサービスごとに異なり、定義は製品チームの責任。当然Error Budgetが少ない = サービスレベルが高い = コストがかかる ので、製品チームはいたずらに高いサービスレベルを定義しない。Google Apps for WorkとYoutubeのError Budgetは異なる。Appsはサービスレベル重視であり、Youtubeは迅速で頻繁な機能追加を重視する。</p></li>

<li><p>SLA違反など、重大な障害では&rdquo;Postmortem(過激だが死体解剖の意)&ldquo;を作成し、失敗から学ぶ。客観的に、建設的に。誰かや何かを責めるためにやるわけではない。マサカリ投げない。</p></li>

<li><p>他の産業から学ぶ。製造業のビジネス継続プラン、国防のシミュレーションや演習、通信業の輻輳対策など。</p></li>
</ul>

<p>もう一回読んだら、また違う発見があるんじゃないかと。</p>

<h2 id="自分ごととして読みたい:85f39e44bed874d49c5c215a7c1e75f5">自分ごととして読みたい</h2>

<p>今後の働き方や所属組織に行き詰まりを感じているインフラ/Ops技術者に、参考になるネタが多いと思います。</p>

<p>DevOpsムーブメントが来るか来ないかという今、Opsとしてのスタンスを考え直すのにも、いいかもしれません。</p>

<p>もちろん、Googleの圧倒的物量、成長スピードゆえのミッションと働き方である事は否定しません。でも、自分とは無関係、と無視するにはもったいないです。</p>

<p>なお、このSREチーム、できてから10年以上たっているそうです。それだけ持続できるということは、そこに何か本質的な価値があるのではないでしょうか。</p>

<p>オススメです。</p>

                    </div>
                </section>
                
            </div>
            
<div class="pagination">
  <nav role="pagination" class="post-list-pagination">
      
      <a href="/" class="post-list-pagination-item pure-button post-list-pagination-item-prev">
        <i class="fa fa-angle-double-left"></i>&nbsp;Newer
      </a>
      
    <span class="post-list-pagination-item post-list-pagination-item-current">Page 2 of 8</span>
    
      <a href="/page/3/" class="post-list-pagination-item pure-button post-list-pagination-item-next">
        Older&nbsp;<i class="fa fa-angle-double-right"></i>
      </a>
    
  </nav>
</div>


            <div class="footer">
    <div class="pure-menu pure-menu-horizontal pure-menu-open">
        <ul>
            <li>Powered by <a class="hugo" href="http://hugo.spf13.com/" target="_blank">hugo</a></li>
        </ul>
    </div>
</div>
<script src="http://torumakabe.github.io//js/all.min.js"></script>
        </div>
    </div>
</div>


<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');

</script>

</body>
</html>
